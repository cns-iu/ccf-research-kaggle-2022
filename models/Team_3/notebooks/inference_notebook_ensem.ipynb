{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a4109-abc2-4892-bbdd-d4839334fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import torchvision\n",
    "import ttach as tta\n",
    "import gc\n",
    "import albumentations as A\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import chain\n",
    "from os.path import join as pjoin\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "from itertools import product\n",
    "from matplotlib.patches import Rectangle\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from code_base.models import SMPWrapper, TransformerWrapper\n",
    "from code_base.datasets import HubMapDataset\n",
    "from code_base.utils.mask import rle_decode, overlay_mask\n",
    "from code_base.inference import apply_avarage_weights_on_swa_path, HubMapInference\n",
    "from code_base.constants import CLASSES, PIXEL_SCALE\n",
    "from code_base.utils.metrics import dice_coeff\n",
    "from code_base.models import SegmentationTTAWrapperKwargs\n",
    "from code_base.models.denis_models.custom_unet import get_model\n",
    "from code_base.models.denis_models.upsample import (\n",
    "    UpsampleNearestAdditiveUpsample2x, \n",
    "    UpsampleBilinearAdditiveUpsample2x, \n",
    "    UpsampleResidualDeconvolutionUpsample,\n",
    "    BilinearUpsample4x, \n",
    "    BilinearUpsample2x, \n",
    "    PixelShuffle4x\n",
    ")\n",
    "from code_base.models.denis_models.unet_blocks import NestedInception\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcb75a0-dfa1-469f-b415-462e48051fc8",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc073448-ff29-4f78-ad63-71fe6b2dd2fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Possible exps:\\n\\n{}\".format(\"\\n\".join([el for el in os.listdir(\"../logdirs/\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc782f-f6a3-47b2-b302-46fed80a30bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"???\"\n",
    "print(\"Possible checkpoints:\\n\\n{}\".format(\"\\n\".join(set([os.path.basename(el) for el in glob(f\"../logdirs/{EXP_NAME}/*/checkpoints/*.pt*\") if \"train\" not in os.path.basename(el)]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7636758e-d51d-4778-a06b-6376ee8b0672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf_path = glob(f\"../logdirs/{EXP_NAME}/code/train_configs___*.py\")\n",
    "assert len(conf_path) == 1\n",
    "conf_path = conf_path[0]\n",
    "!cat {conf_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbccef2-12a3-4f8a-9d12-853d2cc531aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLIDING_CONFIG = {\n",
    "    \"roi_size\": (1024, 1024),\n",
    "    \"sw_batch_size\": 4,\n",
    "    \"overlap\": 0.75,\n",
    "    \"padding_mode\": \"reflect\"\n",
    "}\n",
    "\n",
    "CONFIG = {\n",
    "    # Main\n",
    "    \"sliding_window_config\":(\n",
    "        # Unet++ models\n",
    "        [None] * 5 +\n",
    "        # mitb3 models\n",
    "        [deepcopy(SLIDING_CONFIG) for _ in range(5)] + \n",
    "        # Unet models\n",
    "        [None] * 5 + \n",
    "        # Unet models\n",
    "        [None] * 5 \n",
    "    ),\n",
    "    \"fill_binary_holes\": True,\n",
    "    \"test_tresh\": 0.5,\n",
    "    \"use_amp\": True,\n",
    "    \"min_area\": [\n",
    "        0.001, 0.0005, 0.0001, \n",
    "        0.001, 1e-06\n",
    "    ],\n",
    "    # \"is_relative_min_area\": True,\n",
    "    # Data config\n",
    "    \"train_df_path\":\"data/train.csv\",\n",
    "    \"split_path\":\"data/cv_split5_v2.npy\",\n",
    "    \"n_folds\":5,\n",
    "    \"train_data_root\":\"data/train_images/\",\n",
    "    \"batch_size\": 1,\n",
    "    \"num_workers\": 1,\n",
    "    \"pad_config\": dict(\n",
    "        min_height=None, \n",
    "        min_width=None, \n",
    "        pad_height_divisor=32, \n",
    "        pad_width_divisor=32, \n",
    "    ),\n",
    "    \"use_one_channel_mask\": True,\n",
    "    \"to_rgb\": True,\n",
    "    \"additional_scalers\": {\n",
    "        'prostate': 0.15 * 2,\n",
    "        'spleen': 1 * 2,\n",
    "        'lung': 0.5 * 2,\n",
    "        'kidney': 1 * 2,\n",
    "        'largeintestine': 1 * 4\n",
    "    },\n",
    "    # Model config\n",
    "    \"exp_name\":EXP_NAME,\n",
    "    \"model_class\": SMPWrapper,\n",
    "    # \"model_class\": get_model,\n",
    "    # \"model_class\": TransformerWrapper,\n",
    "    \"model_config\": { \n",
    "        # \"backbone_name\": \"mit_b5\",\n",
    "        # \"backbone_name\": \"timm-efficientnet-b5\",\n",
    "        \"backbone_name\": \"timm-efficientnet-b7\",\n",
    "        # \"num_classes\": len(CLASSES),\n",
    "        \"num_classes\": 1,\n",
    "        # \"arch_name\": \"Unet\",\n",
    "        \"arch_name\": \"UnetPP\",\n",
    "        # \"arch_name\": \"FPN\",\n",
    "        # \"arch_name\": \"UnetAsymmetric\",\n",
    "        # \"arch_name\": \"UnetMultiHead\",\n",
    "        # \"arch_name\": \"UnetGC\",\n",
    "        \"pretrained\":False,\n",
    "        # \"use_slice_idx\": True,\n",
    "        # \"case_embedding_dim\": 64\n",
    "        # \"aux_params\": {\"classes\": len(CLASSES)},\n",
    "        # \"return_only_mask\": True\n",
    "    },\n",
    "    # \"model_config\": dict(\n",
    "    #     model_name=\"tf_efficientnetv2_l_in21k\", \n",
    "    #     in_channels=3, \n",
    "    #     out_channels=1,\n",
    "    #     channel_attention=False, \n",
    "    #     positional_attention=False,\n",
    "    #     norm=torch.nn.BatchNorm2d,\n",
    "    #     bias=False,\n",
    "    #     se='TRIPLET',\n",
    "    #     attn_unet=True, \n",
    "    #     layers=range(0,4), \n",
    "    #     DO=0.0,\n",
    "    #     multistage_upsample=True,\n",
    "    #     n_blocks=1, \n",
    "    #     block=NestedInception, \n",
    "    #     upsample=UpsampleBilinearAdditiveUpsample2x,\n",
    "    #     pretrained=False,\n",
    "    #     drop_rate=0.0\n",
    "    # ),\n",
    "    # \"model_config\": {\n",
    "    #     \"model_name\": \"nvidia/segformer-b5-finetuned-cityscapes-1024-1024\",\n",
    "    #     \"n_classes\": 1,  # len(CLASSES),\n",
    "    #     \"pretrained\": False\n",
    "    # },\n",
    "    \"tta_transforms\": tta.aliases.flip_transform(),\n",
    "    \"chkp_name\":\"swa_models_valid_dice_score.pt\",\n",
    "    \"swa_checkpoint\": None,\n",
    "    \"distributed_chkp\": True,\n",
    "    \"use_sigmoid\": True,\n",
    "}\n",
    "\n",
    "ORGANS_INCLUDE = None #['lung']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca454bf-ead8-49ca-8568-9e4cdb4a38e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADITIONAL_MODELS = [\n",
    "    {\n",
    "        \"exp_name\":\"???\",\n",
    "        \"model_config\": {\n",
    "            \"backbone_name\": \"mit_b5\",\n",
    "            \"num_classes\": 1, \n",
    "            \"arch_name\": \"Unet\",\n",
    "            \"pretrained\":False,\n",
    "        },\n",
    "        \"distributed_chkp\": True,\n",
    "        \"chkp_name\":\"swa_models_valid_dice_score.pt\",\n",
    "        \"tta_transforms\": tta.aliases.flip_transform()\n",
    "    },\n",
    "    {\n",
    "        \"exp_name\":\"???\",\n",
    "        \"model_config\": {\n",
    "            \"backbone_name\": \"timm-efficientnet-b7\",\n",
    "            \"num_classes\": 1, \n",
    "            \"arch_name\": \"Unet\",\n",
    "            \"pretrained\":False,\n",
    "            \"point_rand_config\": {\"in_ch\": 161, \"num_classes\": 1, \"backbone_type\": \"effnet\"},\n",
    "        },\n",
    "        \"distributed_chkp\": True,\n",
    "        \"chkp_name\":\"swa_models_valid_dice_score.pt\",\n",
    "        \"tta_transforms\": tta.aliases.flip_transform()\n",
    "    },\n",
    "    {\n",
    "        \"exp_name\":\"???\",\n",
    "        \"model_config\": {\n",
    "            \"backbone_name\": \"timm-efficientnet-b7\",\n",
    "            \"num_classes\": 1, \n",
    "            \"arch_name\": \"Unet\",\n",
    "            \"pretrained\":False,\n",
    "            \"point_rand_config\": {\"in_ch\": 161, \"num_classes\": 1, \"backbone_type\": \"effnet\"},\n",
    "        },\n",
    "        \"distributed_chkp\": True,\n",
    "        \"chkp_name\":\"swa_models_valid_dice_score.pt\",\n",
    "        \"tta_transforms\": tta.aliases.flip_transform()\n",
    "    },\n",
    "]\n",
    "\n",
    "# ADITIONAL_MODELS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc444be2-63a0-476f-9fc3-d85a43bdfeb8",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3969289-50d9-4aae-8a23-01726bc4cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CONFIG[\"train_df_path\"])\n",
    "split = np.load(CONFIG[\"split_path\"], allow_pickle=True)\n",
    "val_df = [df.iloc[split[i][1]].reset_index(drop=True) for i in range(len(split[:CONFIG[\"n_folds\"]]))]\n",
    "if ORGANS_INCLUDE is not None:\n",
    "    df = df[df[\"organ\"].isin(ORGANS_INCLUDE)].reset_index(drop=True)\n",
    "    print(f\"Considering organs: {set(df['organ'])}\")\n",
    "    val_df = [el[el[\"organ\"].isin(ORGANS_INCLUDE)].reset_index(drop=True) for el in val_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a4037-1d17-4317-86e1-c4c608958cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_config = {\n",
    "    \"batch_size\": CONFIG[\"batch_size\"],\n",
    "    \"drop_last\": False,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": CONFIG[\"num_workers\"],\n",
    "}\n",
    "ds_config = {\n",
    "    \"root\": CONFIG[\"train_data_root\"],\n",
    "    \"img_size\": None,\n",
    "    \"test_mode\": True,\n",
    "    \"precompute\": False,\n",
    "    \"dynamic_resize_mode\": \"scale_or\",\n",
    "    \"use_one_channel_mask\": CONFIG[\"use_one_channel_mask\"],\n",
    "    \"additional_scalers\": CONFIG.get(\"additional_scalers\", None),\n",
    "    \"to_rgb\": CONFIG[\"to_rgb\"],\n",
    "    \"transform\": A.Compose([\n",
    "        A.PadIfNeeded(\n",
    "            border_mode=4, \n",
    "            value=None, \n",
    "            mask_value=None, \n",
    "            always_apply=True,\n",
    "            **CONFIG[\"pad_config\"]\n",
    "        ),\n",
    "        A.Normalize(), ToTensorV2(transpose_mask=True)\n",
    "    ]),\n",
    "}\n",
    "ds_test = [HubMapDataset(df=df, **ds_config) for df in val_df]\n",
    "loader_test = [torch.utils.data.DataLoader(\n",
    "    ds,\n",
    "    **loader_config,\n",
    ")for ds in ds_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac35e19-6660-42f7-884f-1faba85ce626",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1f43d3-2048-4e46-8b73-8f72e2ea079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_and_upload_chkp(\n",
    "    model_class,\n",
    "    model_config,\n",
    "    model_device,\n",
    "    model_chkp,\n",
    "    use_distributed=False,\n",
    "    swa_checkpoint=None,\n",
    "    tta_transform=None,\n",
    "    tta_merge_mode=\"mean\"\n",
    "):\n",
    "    if \"swa\" in model_chkp:\n",
    "        print(\"swa by {}\".format(os.path.splitext(os.path.basename(model_chkp))[0]))\n",
    "        t_chkp = apply_avarage_weights_on_swa_path(model_chkp, use_distributed=use_distributed, take_best=swa_checkpoint)\n",
    "    else:\n",
    "        print(\"vanilla model\")\n",
    "        t_chkp = torch.load(model_chkp, map_location=\"cpu\")\n",
    "        \n",
    "    t_model = model_class(**model_config, device=model_device)\n",
    "    t_model.load_state_dict(t_chkp)\n",
    "    t_model.eval()\n",
    "    if tta_transform is not None:\n",
    "        print(\"Wrapping model in TTA\")\n",
    "        t_model = SegmentationTTAWrapperKwargs(t_model, tta_transform, merge_mode=tta_merge_mode)\n",
    "    return t_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4566293-1a95-4f42-93db-ac3019b69a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [[create_model_and_upload_chkp(\n",
    "        model_class=CONFIG[\"model_class\"],\n",
    "        model_config=CONFIG['model_config'],\n",
    "        model_device=\"cuda\",\n",
    "        model_chkp=f\"../logdirs/{CONFIG['exp_name']}/fold_{m_i}/checkpoints/{CONFIG['chkp_name']}\",\n",
    "        swa_checkpoint=CONFIG['swa_checkpoint'],\n",
    "        use_distributed=CONFIG['distributed_chkp'],\n",
    "        tta_transform=CONFIG.get(\"tta_transforms\", None),\n",
    ") for m_i in range(CONFIG[\"n_folds\"])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd561f3-fb84-4bf8-aac6-2dfa45288cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ADITIONAL_MODELS is not None:\n",
    "    for add_conf in ADITIONAL_MODELS:\n",
    "        model.append([create_model_and_upload_chkp(\n",
    "                model_class=CONFIG[\"model_class\"],\n",
    "                model_config=add_conf['model_config'],\n",
    "                model_device=\"cuda\",\n",
    "                model_chkp=f\"../logdirs/{add_conf['exp_name']}/fold_{m_i}/checkpoints/{add_conf['chkp_name']}\",\n",
    "                swa_checkpoint=CONFIG['swa_checkpoint'],\n",
    "                use_distributed=add_conf['distributed_chkp'],\n",
    "                tta_transform=add_conf.get(\"tta_transforms\", None),\n",
    "        ) for m_i in range(CONFIG[\"n_folds\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409a889-a3f2-458a-afaa-3787b2918b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Exps in Blend = {len(model)}\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c6147b-4f62-4524-a568-b138b845e750",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1f18a4-4d8b-4070-a6c9-7bd4b7d4e65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_class = HubMapInference(\n",
    "    device=\"cuda\",\n",
    "    verbose=True,\n",
    "    verbose_tqdm=True,\n",
    "    use_sigmoid=True,\n",
    "    use_amp=CONFIG[\"use_amp\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb76e94-27de-4cc8-8c77-6c7f27242c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG[\"exp_name\"], CONFIG[\"chkp_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ce7a4-34c0-4325-a8af-14315cbffd99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_pred = []\n",
    "for i in range(CONFIG[\"n_folds\"]):\n",
    "    test_pred_temp = inference_class.predict_test_loader(\n",
    "        # j - iterates over exps, i - over folds\n",
    "        nn_models=[model[j][i] for j in range(len(model))],\n",
    "        test_loader=loader_test[i],\n",
    "        tresh=CONFIG[\"test_tresh\"],\n",
    "        pad_config=CONFIG[\"pad_config\"],\n",
    "        min_area=CONFIG.get(\"min_area\", None),\n",
    "        is_relative_min_area=CONFIG.get(\"is_relative_min_area\", False),\n",
    "        use_rescaled=True,\n",
    "        scale_back=True,\n",
    "        fill_binary_holes=CONFIG[\"fill_binary_holes\"],\n",
    "        sliding_window_config=CONFIG[\"sliding_window_config\"],\n",
    "        print_input_shape=False,\n",
    "        save_mask_path=f\"./temp_1/fold_{i}\"\n",
    "    )\n",
    "    assert set(test_pred_temp[\"id\"]) == set(val_df[i][\"id\"])\n",
    "    test_pred.append(\n",
    "        test_pred_temp\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b8f23-088f-42f4-ba31-d443dfad3d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pd.concat(test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e31da6-f417-4bea-9546-159d64ca81cb",
   "metadata": {},
   "source": [
    "# Optimize tresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ef970-cc2f-4eca-956c-5b3c4bc57888",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(val_df)\n",
    "result_df = result_df[[\"id\", \"rle\", \"organ\", \"img_width\", \"img_height\"]].rename(columns={\"rle\":\"real\"}).merge(test_pred.rename(columns={\"rle\":\"pred\"}), on=\"id\").reset_index(drop=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc68f40-05f5-433c-a5ef-f6a570b400f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_masks_pathes = glob(\"temp_1/*/*.png\")\n",
    "pred_masks_pathes = pd.DataFrame({\n",
    "    \"path\": pred_masks_pathes,\n",
    "    \"id\": [int(os.path.basename(el)[:-4]) for el in pred_masks_pathes]\n",
    "}).set_index(\"id\")[\"path\"]\n",
    "pred_masks_pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461b859a-47cf-4657-a6d1-9b3791b7f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_masks = []\n",
    "real_organs = []\n",
    "pred_masks = []\n",
    "for id, rle_real, rle_pred, organ, w, h in tqdm(zip(result_df.id, result_df.real, result_df.pred, result_df.organ, result_df.img_width, result_df.img_height)):\n",
    "    real_masks.append(rle_decode(rle_real, shape=(w, h)))\n",
    "    pred_masks.append(cv2.imread(pred_masks_pathes.loc[id], 0).astype(float) / 255.0)\n",
    "    real_organs.append(organ)\n",
    "real_organs = np.array(real_organs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1307a-4d24-4785-a687-aa5f22e5d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_search_space = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "\n",
    "organ_scores_treshes = {}\n",
    "for organ in tqdm(set(real_organs)):\n",
    "    organ_scores_treshes[organ] = {\"thr\": [], \"score\": []}\n",
    "    organ_idxs = np.where(real_organs == organ)[0]\n",
    "    for thresh in thresh_search_space:\n",
    "        dice_coefs = []\n",
    "        for idx in organ_idxs:\n",
    "            dice_coefs.append(dice_coeff(\n",
    "                real_masks[idx] > 0.5, \n",
    "                pred_masks[idx] > thresh\n",
    "            ))\n",
    "        organ_scores_treshes[organ][\"thr\"].append(thresh)\n",
    "        organ_scores_treshes[organ][\"score\"].append(np.mean(dice_coefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13392a35-97fb-4975-b64e-63290088eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "organ_vc = result_df[\"organ\"].value_counts().to_dict()\n",
    "for organ, stats in organ_scores_treshes.items():\n",
    "    best_stat_id = np.argmax(stats[\"score\"])\n",
    "    print(\n",
    "        f\"For {organ} score reached {stats['score'][best_stat_id]} on tresh {stats['thr'][best_stat_id]}\"\n",
    "    )\n",
    "    best_score += organ_vc[organ] * stats['score'][best_stat_id]\n",
    "print(f\"With opt tresh Mean score = {best_score / len(result_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7985a0-3e05-4e7e-a8ce-18405771bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm temp_1 -rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2490569b-a8cf-45bf-b4e8-3127168a022c",
   "metadata": {},
   "source": [
    "# Compute Final Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ce066-76e6-4612-9148-3b7d1f4d83f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = pd.concat(val_df)\n",
    "# result_df = result_df[[\"id\", \"rle\", \"organ\", \"img_width\", \"img_height\"]].rename(columns={\"rle\":\"real\"}).merge(test_pred.rename(columns={\"rle\":\"pred\"}), on=\"id\").reset_index(drop=True)\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44506a4c-1ea8-4247-9599-4e85a1bf4f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_coefs = []\n",
    "for rle_real, rle_pred, organ, w, h in tqdm(zip(result_df.real, result_df.pred, result_df.organ, result_df.img_width, result_df.img_height)):\n",
    "    mask_real = rle_decode(rle_real, shape=(w, h))\n",
    "    mask_pred = rle_decode(rle_pred, shape=(w, h))\n",
    "    # mask_real = cv2.resize(\n",
    "    #     mask_real, \n",
    "    #     (int(w / PIXEL_SCALE[organ]), int(h / PIXEL_SCALE[organ])),\n",
    "    #     interpolation=cv2.INTER_NEAREST\n",
    "    # )\n",
    "    # mask_pred = rle_decode(\n",
    "    #     rle_pred, \n",
    "    #     shape=(int(w / PIXEL_SCALE[organ]), int(h / PIXEL_SCALE[organ]))\n",
    "    # )\n",
    "    dice_coefs.append(dice_coeff(mask_real > 0.5, mask_pred > 0.5))\n",
    "result_df[\"dice\"] = dice_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e0de7-19e3-495e-a1f7-287294840e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{EXP_NAME}\\nMean Dice = {result_df['dice'].mean()}\")\n",
    "result_df.groupby(\"organ\")['dice'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
