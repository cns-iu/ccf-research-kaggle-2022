{"cells":[{"cell_type":"markdown","source":["#Install MMSegmentation and Pytorch"],"metadata":{"id":"neRP3GM3ysfd"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18637,"status":"ok","timestamp":1665291306845,"user":{"displayName":"vov nanda","userId":"09231748423501225228"},"user_tz":-540},"id":"9NCETveqlIgi","outputId":"708413e0-6ab8-4b40-92be-05d8f1dc048f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Oct  9 04:54:47 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P0    49W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Mounted at /content/drive\n"]}],"source":["!nvidia-smi\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UWyLrLYaNEaL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665231841593,"user_tz":-540,"elapsed":416,"user":{"displayName":"vov nanda","userId":"09231748423501225228"}},"outputId":"93c73492-f426-40b8-d09d-92aec44a74ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2021 NVIDIA Corporation\n","Built on Sun_Feb_14_21:12:58_PST_2021\n","Cuda compilation tools, release 11.2, V11.2.152\n","Build cuda_11.2.r11.2/compiler.29618528_0\n","gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","Copyright (C) 2017 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n"]}],"source":["\"\"\"\n","Although I used Tesla V100 mainly, it's difficult now to use V100 because of policy change of Colab.\n","So the outputs of each cell come from Tesla A100.\n","\n","CUDA version seems to be different dependig on timing and which GPU you use.\n","So it's difficult to describe version dependencies.\n","Although I mainly used CUDA version 11.1, following combination of installation also work in this case.\n","\"\"\"\n","\n","# CUDA version:\n","!nvcc -V\n","# Check GCC version:\n","!gcc --version\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ki3WUBjKbutg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665232030709,"user_tz":-540,"elapsed":189120,"user":{"displayName":"vov nanda","userId":"09231748423501225228"}},"outputId":"b696ce6b-f5b5-4913-e10b-1afdfa73b752"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.10.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2137.6 MB)\n","\u001b[K     |████████████▌                   | 834.1 MB 1.2 MB/s eta 0:18:05tcmalloc: large alloc 1147494400 bytes == 0x3938a000 @  0x7f2c2fb7d615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n","\u001b[K     |███████████████▉                | 1055.7 MB 1.2 MB/s eta 0:14:46tcmalloc: large alloc 1434370048 bytes == 0x7d9e0000 @  0x7f2c2fb7d615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n","\u001b[K     |████████████████████            | 1336.2 MB 1.2 MB/s eta 0:11:24tcmalloc: large alloc 1792966656 bytes == 0x2812000 @  0x7f2c2fb7d615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n","\u001b[K     |█████████████████████████▎      | 1691.1 MB 113.4 MB/s eta 0:00:04tcmalloc: large alloc 2241208320 bytes == 0x6d5fa000 @  0x7f2c2fb7d615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n","\u001b[K     |████████████████████████████████| 2137.6 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 2137645056 bytes == 0xf2f5c000 @  0x7f2c2fb7c1e7 0x4b2150 0x4b21dc 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x58f2a7 0x517947 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5\n","tcmalloc: large alloc 2672058368 bytes == 0x1e6ab0000 @  0x7f2c2fb7d615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x58f2a7 0x517947 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x4ba899 0x4d29f9\n","\u001b[K     |████████████████████████████████| 2137.6 MB 360 bytes/s \n","\u001b[?25hCollecting torchvision==0.11.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.11.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (21.9 MB)\n","\u001b[K     |████████████████████████████████| 21.9 MB 32.9 MB/s \n","\u001b[?25hCollecting torchaudio==0.10.0\n","  Downloading https://download.pytorch.org/whl/rocm4.1/torchaudio-0.10.0%2Brocm4.1-cp37-cp37m-linux_x86_64.whl (2.7 MB)\n","\u001b[K     |████████████████████████████████| 2.7 MB 2.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0+cu111) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.0+cu111) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.0+cu111) (7.1.2)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.1+cu113\n","    Uninstalling torchvision-0.13.1+cu113:\n","      Successfully uninstalled torchvision-0.13.1+cu113\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.12.1+cu113\n","    Uninstalling torchaudio-0.12.1+cu113:\n","      Successfully uninstalled torchaudio-0.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.10.0+cu111 which is incompatible.\u001b[0m\n","Successfully installed torch-1.10.0+cu111 torchaudio-0.10.0+rocm4.1 torchvision-0.11.0+cu111\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.10/index.html\n","Collecting mmcv-full==1.6.0\n","  Downloading https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/mmcv_full-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (47.1 MB)\n","\u001b[K     |████████████████████████████████| 47.1 MB 7.5 MB/s \n","\u001b[?25hCollecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.6.0) (7.1.2)\n","Collecting yapf\n","  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n","\u001b[K     |████████████████████████████████| 190 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.6.0) (21.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.6.0) (6.0)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.6.0) (4.6.0.66)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.6.0) (1.21.6)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full==1.6.0) (3.0.9)\n","Installing collected packages: yapf, addict, mmcv-full\n","Successfully installed addict-2.4.0 mmcv-full-1.6.0 yapf-0.32.0\n"]}],"source":["\"\"\"\n","You don't need to reinstall pytorch depending on which CUDA and MMSegmentation(MMCV) version you use.\n","I reinstall pytorch libraries here because there were version conflict as of July 2022.\n","\"\"\"\n","\n","!pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html\n","\n","cu_version='cu111'\n","torch_version='torch1.10'\n","\n","!pip install mmcv-full==1.6.0 -f https://download.openmmlab.com/mmcv/dist/{cu_version}/{torch_version}/index.html\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nR-hHRvbNJJZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665232040092,"user_tz":-540,"elapsed":9392,"user":{"displayName":"vov nanda","userId":"09231748423501225228"}},"outputId":"abd2f283-5866-43ed-c23e-95e54ca4494e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Cloning into 'mmsegmentation'...\n","remote: Enumerating objects: 7834, done.\u001b[K\n","remote: Counting objects: 100% (60/60), done.\u001b[K\n","remote: Compressing objects: 100% (45/45), done.\u001b[K\n","remote: Total 7834 (delta 26), reused 38 (delta 15), pack-reused 7774\u001b[K\n","Receiving objects: 100% (7834/7834), 13.56 MiB | 48.05 MiB/s, done.\n","Resolving deltas: 100% (5790/5790), done.\n","/content/mmsegmentation\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Obtaining file:///content/mmsegmentation\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.28.0) (3.2.2)\n","Collecting mmcls>=0.20.1\n","  Downloading mmcls-0.24.0-py2.py3-none-any.whl (647 kB)\n","\u001b[K     |████████████████████████████████| 647 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.28.0) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.28.0) (21.3)\n","Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.28.0) (3.4.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.28.0) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.28.0) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.28.0) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.28.0) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmsegmentation==0.28.0) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mmsegmentation==0.28.0) (1.15.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable->mmsegmentation==0.28.0) (5.0.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->mmsegmentation==0.28.0) (0.2.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->mmsegmentation==0.28.0) (3.8.1)\n","Installing collected packages: mmcls, mmsegmentation\n","  Running setup.py develop for mmsegmentation\n","Successfully installed mmcls-0.24.0 mmsegmentation-0.28.0\n","sys.platform: linux\n","Python: 3.7.14 (default, Sep  8 2022, 00:06:44) [GCC 7.5.0]\n","CUDA available: True\n","GPU 0: A100-SXM4-40GB\n","CUDA_HOME: /usr/local/cuda\n","NVCC: Cuda compilation tools, release 11.2, V11.2.152\n","GCC: x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","PyTorch: 1.10.0+cu111\n","PyTorch compiling details: PyTorch built with:\n","  - GCC 7.3\n","  - C++ Version: 201402\n","  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n","  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n","  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n","  - LAPACK is enabled (usually provided by MKL)\n","  - NNPACK is enabled\n","  - CPU capability usage: AVX512\n","  - CUDA Runtime 11.1\n","  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n","  - CuDNN 8.0.5\n","  - Magma 2.5.2\n","  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n","\n","TorchVision: 0.11.0+cu111\n","OpenCV: 4.6.0\n","MMCV: 1.6.0\n","MMCV Compiler: GCC 7.3\n","MMCV CUDA Compiler: 11.1\n","MMSegmentation: 0.28.0+3fb9c77\n"]}],"source":["%cd /content\n","!rm -rf mmsegmentation\n","\n","# I customized mmsegmentation and it's in my repo.\n","!git clone https://github.com/ykawa2/mmsegmentation.git\n","%cd mmsegmentation\n","\n","# install mmsegmentation with editable mode to customize it easily.\n","!pip install -e .\n","\n","!python mmseg/utils/collect_env.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mAE_h7XhPT7d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665232042154,"user_tz":-540,"elapsed":2080,"user":{"displayName":"vov nanda","userId":"09231748423501225228"}},"outputId":"5e2ee0e5-e58c-49df-a30e-856f8e423551"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch version: 1.10.0+cu111 cuda_availabe: True\n","torchvision version: 0.11.0+cu111\n","mmseg version: 0.28.0\n","mmcv version: 1.6.0\n"]}],"source":["# Check Pytorch installation\n","import torch, torchvision\n","print('torch version:', torch.__version__, 'cuda_availabe:', torch.cuda.is_available())\n","print('torchvision version:', torchvision.__version__) \n","\n","import mmseg\n","print('mmseg version:', mmseg.__version__)\n","\n","import mmcv\n","print('mmcv version:', mmcv.__version__)"]},{"cell_type":"markdown","metadata":{"id":"y40sFkCPf_ff"},"source":["#Prepare Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H91XUYoitDKS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665232184708,"user_tz":-540,"elapsed":142558,"user":{"displayName":"vov nanda","userId":"09231748423501225228"}},"outputId":"30537aab-55c8-4e34-fcbd-dcd093fccca3"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["\"\"\"\n","This hubmap_2000x2000_aug_v5.tar is HPA datasets, which composed of:\n","\n","images: original images (no stain), 351 images\n","images_stained_with_hubmap1: stain from previous hubmap competition data, 351 images\n","images_stained_with_hubmap2: stain from previous hubmap competition data, 351 images\n","images_stained_with_pas: stain from pas stain image, 351 images\n","images_stained_with_pas2: stain from pas stain image, 351 images\n","images_stained_with_sample1: stain from pas stain image, 351 images\n","images_stained_with_test: stain from the single test image(spleen), 351 images\n","ImageSets: text files containing image indice\n","masks: original masks(6 classes with color palette)\n","lung_refined_masks: modified masks. prostate and largeintestine were relabed using pseudo label. Lung was hand-annotated.\n","\n","Although I named it \"refined_masks\", it doesn't necessarily mean it's annotated correctly.\n","The dataset size is about 16GB and it's huge.\n","If stain transfers were done in train pipeline, it would be ideal in terms of dataset size.\n","However, it costs a lot of time for training. So I stained HPA dataset in advance.\n","\"\"\"\n","\n","%cd /content\n","!tar -xvf /content/drive/MyDrive/hubmap+hpa_1st/multi_class_dataset/hubmap_2000x2000_aug_v5.tar > /dev/null\n","\n","# only for changing name\n","!mv /content/hubmap_2000x2000 /content/hubmap_multi_2000x2000"]},{"cell_type":"markdown","metadata":{"id":"kRqIHManj-Sh"},"source":["# Merge of mask patch (partial annotation)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XRyGg5YokBLq"},"outputs":[],"source":["!cp -r /content/drive/MyDrive/hubmap+hpa_1st/multi_class_dataset/converted_mask_patch_v3 /content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"edpkFAjqkJl8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665232192503,"user_tz":-540,"elapsed":1439,"user":{"displayName":"vov nanda","userId":"09231748423501225228"}},"outputId":"1dfefc5e-3336-42a1-f494-74619112fa3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/hubmap_multi_2000x2000/lung_refined_masks/3409.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/14183.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/12174.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/9231.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/676.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/8222.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/12471.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/4802.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/8402.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/5317.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/29180.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/32412.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/15732.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/203.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/24194.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/20247.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/17143.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/28622.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/5287.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/8388.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/29307.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/28318.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/16659.png\n","/content/hubmap_multi_2000x2000/lung_refined_masks/19569.png\n","24\n"]}],"source":["\"\"\"\n","converted_mask_patch_v3 is partial mask annotation and it's merged with \"lung_refined_masks\"\n","It's intended for complementing missing annotations.\n","\"\"\"\n","\n","import glob\n","import os\n","from PIL import Image\n","import numpy as np\n","\n","target_index=[203,676,3409,4802,5287,8222,8402,9231,12174,12471,14183,15732,16659,\n","            20247,24194,28318,28622,29180,32412,29307, 8388,17143, 19569, 5317]\n","replace_index=[]\n","\n","patch_dir='/content/converted_mask_patch_v3'\n","mask_dir='/content/hubmap_multi_2000x2000/lung_refined_masks'\n","\n","\n","files=glob.glob(patch_dir + '/*.png')\n","basename_without_ext=[os.path.basename(f).split('.')[0] for f in files ]\n","\n","cnt=0\n","for idx in basename_without_ext:\n","    if int(idx) in target_index:\n","        patch_path=os.path.join(patch_dir, idx + '.png')\n","        mask_path=os.path.join(mask_dir, idx + '.png')\n","\n","        mask=Image.open(mask_path)\n","        assert mask.mode=='P'\n","        palette=mask.getpalette()\n","        mask=np.array(mask)\n","\n","        patch=Image.open(patch_path)\n","        assert patch.mode=='P'\n","        patch=np.array(patch)\n","\n","        assert mask.shape==patch.shape\n","        \n","        mask[patch>0]=0\n","        mask+=patch\n","\n","        mask=Image.fromarray(mask)\n","        mask.putpalette(palette)\n","        mask.save(mask_path)\n","\n","    elif int(idx) in replace_index:\n","        patch_path=os.path.join(patch_dir, idx + '.png')\n","        mask_path=os.path.join(mask_dir, idx + '.png')\n","\n","        patch=Image.open(patch_path)\n","        assert patch.mode=='P'\n","        \n","        patch.save(mask_path)\n","    \n","    else:\n","        continue\n","\n","    cnt+=1\n","    print(mask_path)\n","\n","print(cnt)\n"]},{"cell_type":"markdown","metadata":{"id":"rMy0iYLFmxAW"},"source":["# Create 2 class dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yPbPZR7-mxWB"},"outputs":[],"source":["\"\"\"\n","I trained models with 2 classes(background and cells).\n","Originally masks are 6 classes because it's useful for training pipeline.\n","You can use different data augmentation among classes.\n","After that, 6 class mask are converted into 2 class mask.\n","\n","In case of validation, 6 class mask cannot be used because masks aren't used in pipeline.\n","So 2 class masks are prepared here.\n","\"\"\"\n","\n","!cp -r /content/hubmap_multi_2000x2000/lung_refined_masks /content/hubmap_multi_2000x2000/lung_refined_masks_2class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_QRJawaMm3c3","executionInfo":{"status":"ok","timestamp":1665232232285,"user_tz":-540,"elapsed":39785,"user":{"displayName":"vov nanda","userId":"09231748423501225228"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"471bfa71-49c4-4ca9-b514-042d669d3991"},"outputs":[{"output_type":"stream","name":"stdout","text":["0 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/127.png\n","1 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/3409.png\n","2 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/7359.png\n","3 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/24241.png\n","4 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/10044.png\n","5 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/32741.png\n","6 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/4658.png\n","7 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/28045.png\n","8 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/27879.png\n","9 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/19048.png\n","10 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/8450.png\n","11 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/2174.png\n","12 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/31406.png\n","13 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/4639.png\n","14 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/21129.png\n","15 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/14183.png\n","16 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/62.png\n","17 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/26174.png\n","18 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/30080.png\n","19 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/13396.png\n","20 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/21812.png\n","21 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/3054.png\n","22 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/4412.png\n","23 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/27587.png\n","24 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/2500.png\n","25 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/13260.png\n","26 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/9453.png\n","27 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/19997.png\n","28 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/10392.png\n","29 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/12174.png\n","30 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/9445.png\n","31 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/24782.png\n","32 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/9231.png\n","33 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/676.png\n","34 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/10274.png\n","35 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/32151.png\n","36 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/24222.png\n","37 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/7970.png\n","38 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/17187.png\n","39 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/16214.png\n","40 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/23959.png\n","41 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/32325.png\n","42 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/27861.png\n","43 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/22741.png\n","44 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/9407.png\n","45 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/8222.png\n","46 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/31898.png\n","47 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/31139.png\n","48 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/164.png\n","49 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/9904.png\n","50 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/27803.png\n","51 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/17828.png\n","52 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/16564.png\n","53 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/6121.png\n","54 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/12466.png\n","55 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/10912.png\n","56 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/16163.png\n","57 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/18426.png\n","58 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/4062.png\n","59 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/18449.png\n","60 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/31727.png\n","61 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/26319.png\n","62 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/1955.png\n","63 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/25689.png\n","64 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/31675.png\n","65 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/5552.png\n","66 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/22236.png\n","67 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/11448.png\n","68 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/23009.png\n","69 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/23760.png\n","70 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/12471.png\n","71 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/1123.png\n","72 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/8227.png\n","73 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/5785.png\n","74 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/26101.png\n","75 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/4802.png\n","76 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/7706.png\n","77 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/30250.png\n","78 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/29820.png\n","79 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/28436.png\n","80 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/17455.png\n","81 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/18422.png\n","82 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/15787.png\n","83 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/29223.png\n","84 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/18121.png\n","85 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/16711.png\n","86 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/17126.png\n","87 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/16362.png\n","88 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/23243.png\n","89 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/8876.png\n","90 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/16216.png\n","91 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/30294.png\n","92 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/22544.png\n","93 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/3083.png\n","94 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/1184.png\n","95 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/28823.png\n","96 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/8894.png\n","97 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/21195.png\n","98 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/28262.png\n","99 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/32126.png\n","100 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/8402.png\n","101 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/22310.png\n","102 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/5317.png\n","103 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/30876.png\n","104 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/14674.png\n","105 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/11662.png\n","106 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/2668.png\n","107 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/31698.png\n","108 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/2447.png\n","109 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/5777.png\n","110 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/29143.png\n","111 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/13942.png\n","112 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/22718.png\n","113 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/9358.png\n","114 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/29296.png\n","115 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/31733.png\n","116 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/14407.png\n","117 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/30201.png\n","118 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/9450.png\n","119 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/28126.png\n","120 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/4066.png\n","121 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/29610.png\n","122 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/32009.png\n","123 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/29809.png\n","124 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/12244.png\n","125 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/8231.png\n","126 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/30581.png\n","127 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/28052.png\n","128 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/9517.png\n","129 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/24833.png\n","130 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/11064.png\n","131 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/11629.png\n","132 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/9437.png\n","133 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/15842.png\n","134 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/5995.png\n","135 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/27616.png\n","136 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/29180.png\n","137 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/1850.png\n","138 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/6722.png\n","139 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/15499.png\n","140 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/10651.png\n","141 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/10610.png\n","142 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/27350.png\n","143 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/32412.png\n","144 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/30424.png\n","145 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/20302.png\n","146 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/4265.png\n","147 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/32231.png\n","148 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/11890.png\n","149 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/15192.png\n","150 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/24522.png\n","151 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/9387.png\n","152 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/4404.png\n","153 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/10971.png\n","154 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/15732.png\n","155 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/16890.png\n","156 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/19179.png\n","157 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/13034.png\n","158 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/23961.png\n","159 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/29690.png\n","160 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/1731.png\n","161 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/30765.png\n","162 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/7569.png\n","163 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/16149.png\n","164 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/31709.png\n","165 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/18792.png\n","166 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/12026.png\n","167 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/19360.png\n","168 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/12784.png\n","169 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/27781.png\n","170 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/10703.png\n","171 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/5932.png\n","172 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/6730.png\n","173 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/203.png\n","174 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/24097.png\n","175 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/27471.png\n","176 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/20563.png\n","177 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/21155.png\n","178 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/11497.png\n","179 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/8502.png\n","180 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/24194.png\n","181 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/18401.png\n","182 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/15124.png\n","183 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/15706.png\n","184 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/12452.png\n","185 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/26780.png\n","186 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/8343.png\n","187 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/11645.png\n","188 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/6120.png\n","189 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/12827.png\n","190 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/25430.png\n","191 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/8842.png\n","192 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/21021.png\n","193 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/2079.png\n","194 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/24269.png\n","195 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/14756.png\n","196 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/13189.png\n","197 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/28189.png\n","198 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/4301.png\n","199 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/6390.png\n","200 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/8638.png\n","201 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/25641.png\n","202 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/928.png\n","203 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/26886.png\n","204 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/18445.png\n","205 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/351.png\n","206 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/4777.png\n","207 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/4561.png\n","208 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/12233.png\n","209 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/22995.png\n","210 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/24961.png\n","211 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/20247.png\n","212 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/28940.png\n","213 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/18900.png\n","214 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/31958.png\n","215 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/4776.png\n","216 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/30394.png\n","217 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/23094.png\n","218 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/21321.png\n","219 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/32527.png\n","220 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/22016.png\n","221 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/7169.png\n","222 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/1229.png\n","223 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/21086.png\n","224 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/660.png\n","225 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/27298.png\n","226 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/8151.png\n","227 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/22953.png\n","228 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/15551.png\n","229 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/1690.png\n","230 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/2696.png\n","231 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/17143.png\n","232 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/9777.png\n","233 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/23828.png\n","234 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/23252.png\n","235 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/10611.png\n","236 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/9769.png\n","237 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/26480.png\n","238 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/10488.png\n","239 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/5832.png\n","240 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/20831.png\n","241 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/9470.png\n","242 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/15329.png\n","243 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/28622.png\n","244 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/2874.png\n","245 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/31800.png\n","246 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/1220.png\n","247 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/25620.png\n","248 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/10892.png\n","249 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/5287.png\n","250 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/5099.png\n","251 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/26982.png\n","252 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/24100.png\n","253 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/13507.png\n","254 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/2424.png\n","255 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/1878.png\n","256 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/22035.png\n","257 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/23880.png\n","258 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/27340.png\n","259 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/2793.png\n","260 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/2279.png\n","261 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/8752.png\n","262 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/19377.png\n","263 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/27468.png\n","264 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/29238.png\n","265 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/8388.png\n","266 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/31290.png\n","267 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/20794.png\n","268 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/7397.png\n","269 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/19507.png\n","270 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/29424.png\n","271 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/1157.png\n","272 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/18777.png\n","273 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/16609.png\n","274 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/6611.png\n","275 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/5583.png\n","276 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/15067.png\n","277 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/31571.png\n","278 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/28791.png\n","279 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/27232.png\n","280 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/435.png\n","281 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/17422.png\n","282 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/12483.png\n","283 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/16728.png\n","284 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/25298.png\n","285 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/25516.png\n","286 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/9791.png\n","287 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/19084.png\n","288 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/14396.png\n","289 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/21039.png\n","290 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/30500.png\n","291 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/20520.png\n","292 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/4944.png\n","293 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/29307.png\n","294 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/10666.png\n","295 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/30194.png\n","296 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/21501.png\n","297 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/8116.png\n","298 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/28748.png\n","299 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/144.png\n","300 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/14388.png\n","301 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/30414.png\n","302 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/21358.png\n","303 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/23665.png\n","304 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/30355.png\n","305 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/6318.png\n","306 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/3057.png\n","307 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/28657.png\n","308 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/6807.png\n","309 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/22133.png\n","310 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/13483.png\n","311 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/25472.png\n","312 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/28429.png\n","313 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/1500.png\n","314 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/1168.png\n","315 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/25945.png\n","316 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/6794.png\n","317 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/23640.png\n","318 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/12476.png\n","319 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/27128.png\n","320 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/20955.png\n","321 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/28318.png\n","322 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/16659.png\n","323 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/30474.png\n","324 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/29213.png\n","325 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/5102.png\n","326 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/30084.png\n","327 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/22059.png\n","328 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/3303.png\n","329 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/20478.png\n","330 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/28963.png\n","331 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/26664.png\n","332 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/6021.png\n","333 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/10992.png\n","334 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/7902.png\n","335 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/15005.png\n","336 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/2344.png\n","337 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/5086.png\n","338 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/21112.png\n","339 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/30224.png\n","340 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/31799.png\n","341 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/23051.png\n","342 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/19569.png\n","343 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/19533.png\n","344 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/20428.png\n","345 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/2943.png\n","346 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/15860.png\n","347 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/3959.png\n","348 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/737.png\n","349 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/686.png\n","350 /content/hubmap_multi_2000x2000/lung_refined_masks_2class/20440.png\n"]}],"source":["import glob\n","from PIL import Image\n","import numpy as np\n","\n","from mmseg.mylib.seg_utils import convert_rgb_to_voc_palette\n","\n","files=glob.glob('/content/hubmap_multi_2000x2000/lung_refined_masks_2class/*.png')\n","\n","for idx, f in enumerate(files):\n","    pil_mask=Image.open(f)\n","    assert pil_mask.mode=='P'\n","\n","    palette=pil_mask.getpalette()\n","\n","    mask=np.asarray(pil_mask)\n","    mask=np.where(mask>=1, 1, 0)\n","    mask=mask.astype(np.uint8)\n","\n","    new_mask=Image.fromarray(mask)\n","    new_mask.putpalette(palette)\n","    assert new_mask.mode=='P', new_mask.mode\n","    unique=list(np.unique(np.asarray(new_mask)))\n","    assert unique==[0,1] or unique==[0], unique\n","    new_mask.save(f)\n","\n","    print(idx, f)"]},{"cell_type":"markdown","metadata":{"id":"TRrZaFYmicJ3"},"source":["# External spleen dataset  \n","created by pseudo label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"amZgth88ibA_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665232250334,"user_tz":-540,"elapsed":18061,"user":{"displayName":"vov nanda","userId":"09231748423501225228"}},"outputId":"63ddede7-f09b-46bc-b376-639d21eb50a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","external_spleen_v2/\n","external_spleen_v2/image/\n","external_spleen_v2/image/stain4_24.png\n","external_spleen_v2/image/stain3_4.png\n","external_spleen_v2/image/stain4_17.png\n","external_spleen_v2/image/25.png\n","external_spleen_v2/image/stain4_14.png\n","external_spleen_v2/image/stain3_0.png\n","external_spleen_v2/image/stain3_22.png\n","external_spleen_v2/image/stain2_18.png\n","external_spleen_v2/image/stain1_15.png\n","external_spleen_v2/image/stain2_15.png\n","external_spleen_v2/image/stain1_1.png\n","external_spleen_v2/image/stain1_0.png\n","external_spleen_v2/image/stain3_31.png\n","external_spleen_v2/image/stain2_24.png\n","external_spleen_v2/image/stain3_29.png\n","external_spleen_v2/image/stain3_12.png\n","external_spleen_v2/image/stain1_18.png\n","external_spleen_v2/image/stain2_37.png\n","external_spleen_v2/image/stain2_2.png\n","external_spleen_v2/image/stain4_12.png\n","external_spleen_v2/image/stain3_7.png\n","external_spleen_v2/image/6.png\n","external_spleen_v2/image/stain2_20.png\n","external_spleen_v2/image/stain4_28.png\n","external_spleen_v2/image/33.png\n","external_spleen_v2/image/stain2_25.png\n","external_spleen_v2/image/stain4_1.png\n","external_spleen_v2/image/stain2_10078.png\n","external_spleen_v2/image/stain1_35.png\n","external_spleen_v2/image/stain3_35.png\n","external_spleen_v2/image/stain3_17.png\n","external_spleen_v2/image/stain1_28.png\n","external_spleen_v2/image/stain4_26.png\n","external_spleen_v2/image/stain2_33.png\n","external_spleen_v2/image/stain1_23.png\n","external_spleen_v2/image/stain2_0.png\n","external_spleen_v2/image/stain1_16.png\n","external_spleen_v2/image/stain2_28.png\n","external_spleen_v2/image/stain4_18.png\n","external_spleen_v2/image/stain3_8.png\n","external_spleen_v2/image/stain3_14.png\n","external_spleen_v2/image/1.png\n","external_spleen_v2/image/3.png\n","external_spleen_v2/image/stain4_32.png\n","external_spleen_v2/image/stain4_15.png\n","external_spleen_v2/image/stain4_3.png\n","external_spleen_v2/image/stain4_29.png\n","external_spleen_v2/image/stain3_34.png\n","external_spleen_v2/image/26.png\n","external_spleen_v2/image/stain1_30.png\n","external_spleen_v2/image/stain1_24.png\n","external_spleen_v2/image/stain1_25.png\n","external_spleen_v2/image/stain2_30.png\n","external_spleen_v2/image/stain4_2.png\n","external_spleen_v2/image/stain3_20.png\n","external_spleen_v2/image/0.png\n","external_spleen_v2/image/stain3_27.png\n","external_spleen_v2/image/stain2_21.png\n","external_spleen_v2/image/stain2_23.png\n","external_spleen_v2/image/stain4_9.png\n","external_spleen_v2/image/stain4_27.png\n","external_spleen_v2/image/stain3_37.png\n","external_spleen_v2/image/stain4_33.png\n","external_spleen_v2/image/8.png\n","external_spleen_v2/image/stain2_5.png\n","external_spleen_v2/image/stain1_19.png\n","external_spleen_v2/image/stain3_13.png\n","external_spleen_v2/image/stain4_31.png\n","external_spleen_v2/image/stain2_17.png\n","external_spleen_v2/image/stain4_7.png\n","external_spleen_v2/image/stain1_6.png\n","external_spleen_v2/image/stain4_35.png\n","external_spleen_v2/image/stain4_36.png\n","external_spleen_v2/image/37.png\n","external_spleen_v2/image/10.png\n","external_spleen_v2/image/11.png\n","external_spleen_v2/image/stain2_31.png\n","external_spleen_v2/image/14.png\n","external_spleen_v2/image/stain4_25.png\n","external_spleen_v2/image/9.png\n","external_spleen_v2/image/34.png\n","external_spleen_v2/image/stain4_20.png\n","external_spleen_v2/image/stain3_18.png\n","external_spleen_v2/image/stain1_2.png\n","external_spleen_v2/image/29.png\n","external_spleen_v2/image/stain2_36.png\n","external_spleen_v2/image/stain2_22.png\n","external_spleen_v2/image/stain1_9.png\n","external_spleen_v2/image/stain2_13.png\n","external_spleen_v2/image/stain4_19.png\n","external_spleen_v2/image/stain4_0.png\n","external_spleen_v2/image/stain2_32.png\n","external_spleen_v2/image/stain4_22.png\n","external_spleen_v2/image/stain1_20.png\n","external_spleen_v2/image/stain4_16.png\n","external_spleen_v2/image/stain4_37.png\n","external_spleen_v2/image/15.png\n","external_spleen_v2/image/stain4_5.png\n","external_spleen_v2/image/stain4_11.png\n","external_spleen_v2/image/stain1_5.png\n","external_spleen_v2/image/stain3_32.png\n","external_spleen_v2/image/stain4_4.png\n","external_spleen_v2/image/stain3_15.png\n","external_spleen_v2/image/stain3_10078.png\n","external_spleen_v2/image/stain4_23.png\n","external_spleen_v2/image/stain2_29.png\n","external_spleen_v2/image/stain1_29.png\n","external_spleen_v2/image/stain4_10.png\n","external_spleen_v2/image/stain3_24.png\n","external_spleen_v2/image/stain4_6.png\n","external_spleen_v2/image/stain2_19.png\n","external_spleen_v2/image/4.png\n","external_spleen_v2/image/stain1_11.png\n","external_spleen_v2/image/stain2_14.png\n","external_spleen_v2/image/stain2_35.png\n","external_spleen_v2/image/stain1_17.png\n","external_spleen_v2/image/32.png\n","external_spleen_v2/image/stain2_10.png\n","external_spleen_v2/image/stain1_14.png\n","external_spleen_v2/image/22.png\n","external_spleen_v2/image/19.png\n","external_spleen_v2/image/30.png\n","external_spleen_v2/image/stain3_23.png\n","external_spleen_v2/image/stain4_34.png\n","external_spleen_v2/image/10078.png\n","external_spleen_v2/image/stain1_3.png\n","external_spleen_v2/image/stain2_34.png\n","external_spleen_v2/image/16.png\n","external_spleen_v2/image/31.png\n","external_spleen_v2/image/stain2_9.png\n","external_spleen_v2/image/stain3_36.png\n","external_spleen_v2/image/21.png\n","external_spleen_v2/image/stain3_6.png\n","external_spleen_v2/image/stain3_10.png\n","external_spleen_v2/image/stain3_19.png\n","external_spleen_v2/image/stain3_2.png\n","external_spleen_v2/image/stain1_10.png\n","external_spleen_v2/image/stain1_26.png\n","external_spleen_v2/image/35.png\n","external_spleen_v2/image/12.png\n","external_spleen_v2/image/stain2_27.png\n","external_spleen_v2/image/stain2_8.png\n","external_spleen_v2/image/stain2_3.png\n","external_spleen_v2/image/stain1_27.png\n","external_spleen_v2/image/stain3_9.png\n","external_spleen_v2/image/stain3_28.png\n","external_spleen_v2/image/stain1_7.png\n","external_spleen_v2/image/stain1_33.png\n","external_spleen_v2/image/24.png\n","external_spleen_v2/image/stain4_8.png\n","external_spleen_v2/image/stain1_10078.png\n","external_spleen_v2/image/stain3_33.png\n","external_spleen_v2/image/stain3_3.png\n","external_spleen_v2/image/27.png\n","external_spleen_v2/image/17.png\n","external_spleen_v2/image/stain4_30.png\n","external_spleen_v2/image/stain4_21.png\n","external_spleen_v2/image/stain4_10078.png\n","external_spleen_v2/image/stain2_16.png\n","external_spleen_v2/image/stain1_36.png\n","external_spleen_v2/image/36.png\n","external_spleen_v2/image/stain1_32.png\n","external_spleen_v2/image/20.png\n","external_spleen_v2/image/stain3_11.png\n","external_spleen_v2/image/28.png\n","external_spleen_v2/image/stain3_30.png\n","external_spleen_v2/image/stain1_13.png\n","external_spleen_v2/image/2.png\n","external_spleen_v2/image/stain1_12.png\n","external_spleen_v2/image/stain3_16.png\n","external_spleen_v2/image/stain3_1.png\n","external_spleen_v2/image/23.png\n","external_spleen_v2/image/stain2_12.png\n","external_spleen_v2/image/stain2_11.png\n","external_spleen_v2/image/stain1_31.png\n","external_spleen_v2/image/stain3_5.png\n","external_spleen_v2/image/stain3_25.png\n","external_spleen_v2/image/stain1_34.png\n","external_spleen_v2/image/stain1_8.png\n","external_spleen_v2/image/stain3_26.png\n","external_spleen_v2/image/7.png\n","external_spleen_v2/image/stain2_6.png\n","external_spleen_v2/image/5.png\n","external_spleen_v2/image/13.png\n","external_spleen_v2/image/stain2_1.png\n","external_spleen_v2/image/stain4_13.png\n","external_spleen_v2/image/stain1_22.png\n","external_spleen_v2/image/stain2_7.png\n","external_spleen_v2/image/stain2_26.png\n","external_spleen_v2/image/stain2_4.png\n","external_spleen_v2/image/stain3_21.png\n","external_spleen_v2/image/stain1_37.png\n","external_spleen_v2/image/stain1_4.png\n","external_spleen_v2/image/18.png\n","external_spleen_v2/image/stain1_21.png\n","external_spleen_v2/mask/\n","external_spleen_v2/mask/stain4_24.png\n","external_spleen_v2/mask/stain3_4.png\n","external_spleen_v2/mask/stain4_17.png\n","external_spleen_v2/mask/25.png\n","external_spleen_v2/mask/stain4_14.png\n","external_spleen_v2/mask/stain3_0.png\n","external_spleen_v2/mask/stain3_22.png\n","external_spleen_v2/mask/stain2_18.png\n","external_spleen_v2/mask/stain1_15.png\n","external_spleen_v2/mask/stain2_15.png\n","external_spleen_v2/mask/stain1_1.png\n","external_spleen_v2/mask/stain1_0.png\n","external_spleen_v2/mask/stain3_31.png\n","external_spleen_v2/mask/stain2_24.png\n","external_spleen_v2/mask/stain3_29.png\n","external_spleen_v2/mask/stain3_12.png\n","external_spleen_v2/mask/stain1_18.png\n","external_spleen_v2/mask/stain2_37.png\n","external_spleen_v2/mask/stain2_2.png\n","external_spleen_v2/mask/stain4_12.png\n","external_spleen_v2/mask/stain3_7.png\n","external_spleen_v2/mask/6.png\n","external_spleen_v2/mask/stain2_20.png\n","external_spleen_v2/mask/stain4_28.png\n","external_spleen_v2/mask/33.png\n","external_spleen_v2/mask/stain2_25.png\n","external_spleen_v2/mask/stain4_1.png\n","external_spleen_v2/mask/stain2_10078.png\n","external_spleen_v2/mask/stain1_35.png\n","external_spleen_v2/mask/stain3_35.png\n","external_spleen_v2/mask/stain3_17.png\n","external_spleen_v2/mask/stain1_28.png\n","external_spleen_v2/mask/stain4_26.png\n","external_spleen_v2/mask/stain2_33.png\n","external_spleen_v2/mask/stain1_23.png\n","external_spleen_v2/mask/stain2_0.png\n","external_spleen_v2/mask/stain1_16.png\n","external_spleen_v2/mask/stain2_28.png\n","external_spleen_v2/mask/stain4_18.png\n","external_spleen_v2/mask/stain3_8.png\n","external_spleen_v2/mask/stain3_14.png\n","external_spleen_v2/mask/1.png\n","external_spleen_v2/mask/3.png\n","external_spleen_v2/mask/stain4_32.png\n","external_spleen_v2/mask/stain4_15.png\n","external_spleen_v2/mask/stain4_3.png\n","external_spleen_v2/mask/stain4_29.png\n","external_spleen_v2/mask/stain3_34.png\n","external_spleen_v2/mask/26.png\n","external_spleen_v2/mask/stain1_30.png\n","external_spleen_v2/mask/stain1_24.png\n","external_spleen_v2/mask/stain1_25.png\n","external_spleen_v2/mask/stain2_30.png\n","external_spleen_v2/mask/stain4_2.png\n","external_spleen_v2/mask/stain3_20.png\n","external_spleen_v2/mask/0.png\n","external_spleen_v2/mask/stain3_27.png\n","external_spleen_v2/mask/stain2_21.png\n","external_spleen_v2/mask/stain2_23.png\n","external_spleen_v2/mask/stain4_9.png\n","external_spleen_v2/mask/stain4_27.png\n","external_spleen_v2/mask/stain3_37.png\n","external_spleen_v2/mask/stain4_33.png\n","external_spleen_v2/mask/8.png\n","external_spleen_v2/mask/stain2_5.png\n","external_spleen_v2/mask/stain1_19.png\n","external_spleen_v2/mask/stain3_13.png\n","external_spleen_v2/mask/stain4_31.png\n","external_spleen_v2/mask/stain2_17.png\n","external_spleen_v2/mask/stain4_7.png\n","external_spleen_v2/mask/stain1_6.png\n","external_spleen_v2/mask/stain4_35.png\n","external_spleen_v2/mask/stain4_36.png\n","external_spleen_v2/mask/37.png\n","external_spleen_v2/mask/10.png\n","external_spleen_v2/mask/11.png\n","external_spleen_v2/mask/stain2_31.png\n","external_spleen_v2/mask/14.png\n","external_spleen_v2/mask/stain4_25.png\n","external_spleen_v2/mask/9.png\n","external_spleen_v2/mask/34.png\n","external_spleen_v2/mask/stain4_20.png\n","external_spleen_v2/mask/stain3_18.png\n","external_spleen_v2/mask/stain1_2.png\n","external_spleen_v2/mask/29.png\n","external_spleen_v2/mask/stain2_36.png\n","external_spleen_v2/mask/stain2_22.png\n","external_spleen_v2/mask/stain1_9.png\n","external_spleen_v2/mask/stain2_13.png\n","external_spleen_v2/mask/stain4_19.png\n","external_spleen_v2/mask/stain4_0.png\n","external_spleen_v2/mask/stain2_32.png\n","external_spleen_v2/mask/stain4_22.png\n","external_spleen_v2/mask/stain1_20.png\n","external_spleen_v2/mask/stain4_16.png\n","external_spleen_v2/mask/stain4_37.png\n","external_spleen_v2/mask/15.png\n","external_spleen_v2/mask/stain4_5.png\n","external_spleen_v2/mask/stain4_11.png\n","external_spleen_v2/mask/stain1_5.png\n","external_spleen_v2/mask/stain3_32.png\n","external_spleen_v2/mask/stain4_4.png\n","external_spleen_v2/mask/stain3_15.png\n","external_spleen_v2/mask/stain3_10078.png\n","external_spleen_v2/mask/stain4_23.png\n","external_spleen_v2/mask/stain2_29.png\n","external_spleen_v2/mask/stain1_29.png\n","external_spleen_v2/mask/stain4_10.png\n","external_spleen_v2/mask/stain3_24.png\n","external_spleen_v2/mask/stain4_6.png\n","external_spleen_v2/mask/stain2_19.png\n","external_spleen_v2/mask/4.png\n","external_spleen_v2/mask/stain1_11.png\n","external_spleen_v2/mask/stain2_14.png\n","external_spleen_v2/mask/stain2_35.png\n","external_spleen_v2/mask/stain1_17.png\n","external_spleen_v2/mask/32.png\n","external_spleen_v2/mask/stain2_10.png\n","external_spleen_v2/mask/stain1_14.png\n","external_spleen_v2/mask/22.png\n","external_spleen_v2/mask/19.png\n","external_spleen_v2/mask/30.png\n","external_spleen_v2/mask/stain3_23.png\n","external_spleen_v2/mask/stain4_34.png\n","external_spleen_v2/mask/10078.png\n","external_spleen_v2/mask/stain1_3.png\n","external_spleen_v2/mask/stain2_34.png\n","external_spleen_v2/mask/16.png\n","external_spleen_v2/mask/31.png\n","external_spleen_v2/mask/stain2_9.png\n","external_spleen_v2/mask/stain3_36.png\n","external_spleen_v2/mask/21.png\n","external_spleen_v2/mask/stain3_6.png\n","external_spleen_v2/mask/stain3_10.png\n","external_spleen_v2/mask/stain3_19.png\n","external_spleen_v2/mask/stain3_2.png\n","external_spleen_v2/mask/stain1_10.png\n","external_spleen_v2/mask/stain1_26.png\n","external_spleen_v2/mask/35.png\n","external_spleen_v2/mask/12.png\n","external_spleen_v2/mask/stain2_27.png\n","external_spleen_v2/mask/stain2_8.png\n","external_spleen_v2/mask/stain2_3.png\n","external_spleen_v2/mask/stain1_27.png\n","external_spleen_v2/mask/stain3_9.png\n","external_spleen_v2/mask/stain3_28.png\n","external_spleen_v2/mask/stain1_7.png\n","external_spleen_v2/mask/stain1_33.png\n","external_spleen_v2/mask/24.png\n","external_spleen_v2/mask/stain4_8.png\n","external_spleen_v2/mask/stain1_10078.png\n","external_spleen_v2/mask/stain3_33.png\n","external_spleen_v2/mask/stain3_3.png\n","external_spleen_v2/mask/27.png\n","external_spleen_v2/mask/17.png\n","external_spleen_v2/mask/stain4_30.png\n","external_spleen_v2/mask/stain4_21.png\n","external_spleen_v2/mask/stain4_10078.png\n","external_spleen_v2/mask/stain2_16.png\n","external_spleen_v2/mask/stain1_36.png\n","external_spleen_v2/mask/36.png\n","external_spleen_v2/mask/stain1_32.png\n","external_spleen_v2/mask/20.png\n","external_spleen_v2/mask/stain3_11.png\n","external_spleen_v2/mask/28.png\n","external_spleen_v2/mask/stain3_30.png\n","external_spleen_v2/mask/stain1_13.png\n","external_spleen_v2/mask/2.png\n","external_spleen_v2/mask/stain1_12.png\n","external_spleen_v2/mask/stain3_16.png\n","external_spleen_v2/mask/stain3_1.png\n","external_spleen_v2/mask/23.png\n","external_spleen_v2/mask/stain2_12.png\n","external_spleen_v2/mask/stain2_11.png\n","external_spleen_v2/mask/stain1_31.png\n","external_spleen_v2/mask/stain3_5.png\n","external_spleen_v2/mask/stain3_25.png\n","external_spleen_v2/mask/stain1_34.png\n","external_spleen_v2/mask/stain1_8.png\n","external_spleen_v2/mask/stain3_26.png\n","external_spleen_v2/mask/7.png\n","external_spleen_v2/mask/stain2_6.png\n","external_spleen_v2/mask/5.png\n","external_spleen_v2/mask/13.png\n","external_spleen_v2/mask/stain2_1.png\n","external_spleen_v2/mask/stain4_13.png\n","external_spleen_v2/mask/stain1_22.png\n","external_spleen_v2/mask/stain2_7.png\n","external_spleen_v2/mask/stain2_26.png\n","external_spleen_v2/mask/stain2_4.png\n","external_spleen_v2/mask/stain3_21.png\n","external_spleen_v2/mask/stain1_37.png\n","external_spleen_v2/mask/stain1_4.png\n","external_spleen_v2/mask/18.png\n","external_spleen_v2/mask/stain1_21.png\n","external_spleen_v2/trainval.txt\n","external_spleen_v2/.ipynb_checkpoints/\n"]}],"source":["%cd /content\n","!tar -xvf /content/drive/MyDrive/hubmap+hpa_1st/multi_class_dataset/external_spleen_v2.tar"]},{"cell_type":"markdown","metadata":{"id":"42-E-S7sB182"},"source":["# External lung dataset  \n","created by pseudo label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_134Rr2FB2G-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665232256661,"user_tz":-540,"elapsed":6339,"user":{"displayName":"vov nanda","userId":"09231748423501225228"}},"outputId":"9125d370-5fd3-475f-e55c-87eb0cd97258"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","external_lung_v1/\n","external_lung_v1/image/\n","external_lung_v1/image/lung_39.png\n","external_lung_v1/image/lung_77.png\n","external_lung_v1/image/lung_49.png\n","external_lung_v1/image/lung_81.png\n","external_lung_v1/image/lung_72.png\n","external_lung_v1/image/lung_73.png\n","external_lung_v1/image/lung_66.png\n","external_lung_v1/image/lung_32.png\n","external_lung_v1/image/lung_22.png\n","external_lung_v1/image/lung_46.png\n","external_lung_v1/image/lung_63.png\n","external_lung_v1/image/lung_60.png\n","external_lung_v1/image/lung_70.png\n","external_lung_v1/image/lung_0.png\n","external_lung_v1/image/lung_51.png\n","external_lung_v1/image/lung_59.png\n","external_lung_v1/image/lung_45.png\n","external_lung_v1/image/lung_36.png\n","external_lung_v1/image/lung_61.png\n","external_lung_v1/image/lung_31.png\n","external_lung_v1/image/lung_14.png\n","external_lung_v1/image/lung_37.png\n","external_lung_v1/image/lung_30.png\n","external_lung_v1/image/lung_20.png\n","external_lung_v1/image/lung_25.png\n","external_lung_v1/image/lung_56.png\n","external_lung_v1/image/lung_52.png\n","external_lung_v1/image/lung_4.png\n","external_lung_v1/image/lung_5.png\n","external_lung_v1/image/lung_65.png\n","external_lung_v1/image/lung_13.png\n","external_lung_v1/image/lung_67.png\n","external_lung_v1/image/lung_8.png\n","external_lung_v1/image/lung_24.png\n","external_lung_v1/image/lung_71.png\n","external_lung_v1/image/lung_18.png\n","external_lung_v1/image/lung_23.png\n","external_lung_v1/image/lung_33.png\n","external_lung_v1/image/lung_53.png\n","external_lung_v1/image/lung_74.png\n","external_lung_v1/image/lung_68.png\n","external_lung_v1/image/lung_69.png\n","external_lung_v1/image/lung_58.png\n","external_lung_v1/image/lung_2.png\n","external_lung_v1/image/lung_28.png\n","external_lung_v1/image/lung_80.png\n","external_lung_v1/image/lung_40.png\n","external_lung_v1/image/lung_35.png\n","external_lung_v1/image/lung_27.png\n","external_lung_v1/image/lung_29.png\n","external_lung_v1/image/lung_11.png\n","external_lung_v1/image/lung_1.png\n","external_lung_v1/image/lung_54.png\n","external_lung_v1/image/lung_44.png\n","external_lung_v1/image/lung_34.png\n","external_lung_v1/image/lung_26.png\n","external_lung_v1/image/lung_43.png\n","external_lung_v1/image/lung_12.png\n","external_lung_v1/image/lung_15.png\n","external_lung_v1/image/lung_7.png\n","external_lung_v1/image/lung_6.png\n","external_lung_v1/image/lung_41.png\n","external_lung_v1/image/lung_75.png\n","external_lung_v1/image/lung_38.png\n","external_lung_v1/image/lung_76.png\n","external_lung_v1/image/lung_55.png\n","external_lung_v1/image/lung_17.png\n","external_lung_v1/image/lung_64.png\n","external_lung_v1/image/lung_16.png\n","external_lung_v1/image/lung_10.png\n","external_lung_v1/image/lung_57.png\n","external_lung_v1/image/lung_21.png\n","external_lung_v1/image/lung_3.png\n","external_lung_v1/image/lung_47.png\n","external_lung_v1/image/lung_79.png\n","external_lung_v1/image/lung_62.png\n","external_lung_v1/image/lung_78.png\n","external_lung_v1/image/lung_42.png\n","external_lung_v1/image/lung_50.png\n","external_lung_v1/image/lung_9.png\n","external_lung_v1/image/lung_48.png\n","external_lung_v1/image/lung_19.png\n","external_lung_v1/external_lung.txt\n","external_lung_v1/mask_0.3/\n","external_lung_v1/mask_0.3/lung_39.png\n","external_lung_v1/mask_0.3/lung_77.png\n","external_lung_v1/mask_0.3/lung_49.png\n","external_lung_v1/mask_0.3/lung_81.png\n","external_lung_v1/mask_0.3/lung_72.png\n","external_lung_v1/mask_0.3/lung_73.png\n","external_lung_v1/mask_0.3/lung_66.png\n","external_lung_v1/mask_0.3/lung_32.png\n","external_lung_v1/mask_0.3/lung_46.png\n","external_lung_v1/mask_0.3/lung_63.png\n","external_lung_v1/mask_0.3/lung_60.png\n","external_lung_v1/mask_0.3/lung_70.png\n","external_lung_v1/mask_0.3/lung_0.png\n","external_lung_v1/mask_0.3/lung_51.png\n","external_lung_v1/mask_0.3/lung_59.png\n","external_lung_v1/mask_0.3/lung_45.png\n","external_lung_v1/mask_0.3/lung_36.png\n","external_lung_v1/mask_0.3/lung_61.png\n","external_lung_v1/mask_0.3/lung_31.png\n","external_lung_v1/mask_0.3/lung_22.png\n","external_lung_v1/mask_0.3/lung_14.png\n","external_lung_v1/mask_0.3/lung_37.png\n","external_lung_v1/mask_0.3/lung_30.png\n","external_lung_v1/mask_0.3/lung_20.png\n","external_lung_v1/mask_0.3/lung_25.png\n","external_lung_v1/mask_0.3/lung_56.png\n","external_lung_v1/mask_0.3/lung_52.png\n","external_lung_v1/mask_0.3/lung_4.png\n","external_lung_v1/mask_0.3/lung_5.png\n","external_lung_v1/mask_0.3/lung_65.png\n","external_lung_v1/mask_0.3/lung_13.png\n","external_lung_v1/mask_0.3/lung_67.png\n","external_lung_v1/mask_0.3/lung_8.png\n","external_lung_v1/mask_0.3/lung_24.png\n","external_lung_v1/mask_0.3/lung_71.png\n","external_lung_v1/mask_0.3/lung_18.png\n","external_lung_v1/mask_0.3/lung_23.png\n","external_lung_v1/mask_0.3/lung_33.png\n","external_lung_v1/mask_0.3/lung_53.png\n","external_lung_v1/mask_0.3/lung_74.png\n","external_lung_v1/mask_0.3/lung_68.png\n","external_lung_v1/mask_0.3/lung_69.png\n","external_lung_v1/mask_0.3/lung_58.png\n","external_lung_v1/mask_0.3/lung_2.png\n","external_lung_v1/mask_0.3/lung_28.png\n","external_lung_v1/mask_0.3/lung_80.png\n","external_lung_v1/mask_0.3/lung_40.png\n","external_lung_v1/mask_0.3/lung_35.png\n","external_lung_v1/mask_0.3/lung_27.png\n","external_lung_v1/mask_0.3/lung_29.png\n","external_lung_v1/mask_0.3/lung_11.png\n","external_lung_v1/mask_0.3/lung_1.png\n","external_lung_v1/mask_0.3/lung_54.png\n","external_lung_v1/mask_0.3/lung_44.png\n","external_lung_v1/mask_0.3/lung_34.png\n","external_lung_v1/mask_0.3/lung_26.png\n","external_lung_v1/mask_0.3/lung_43.png\n","external_lung_v1/mask_0.3/lung_12.png\n","external_lung_v1/mask_0.3/lung_15.png\n","external_lung_v1/mask_0.3/lung_7.png\n","external_lung_v1/mask_0.3/lung_6.png\n","external_lung_v1/mask_0.3/lung_41.png\n","external_lung_v1/mask_0.3/lung_75.png\n","external_lung_v1/mask_0.3/lung_38.png\n","external_lung_v1/mask_0.3/lung_76.png\n","external_lung_v1/mask_0.3/lung_55.png\n","external_lung_v1/mask_0.3/lung_17.png\n","external_lung_v1/mask_0.3/lung_64.png\n","external_lung_v1/mask_0.3/lung_16.png\n","external_lung_v1/mask_0.3/lung_10.png\n","external_lung_v1/mask_0.3/lung_57.png\n","external_lung_v1/mask_0.3/lung_21.png\n","external_lung_v1/mask_0.3/lung_3.png\n","external_lung_v1/mask_0.3/lung_47.png\n","external_lung_v1/mask_0.3/lung_79.png\n","external_lung_v1/mask_0.3/lung_62.png\n","external_lung_v1/mask_0.3/lung_78.png\n","external_lung_v1/mask_0.3/lung_42.png\n","external_lung_v1/mask_0.3/lung_50.png\n","external_lung_v1/mask_0.3/lung_9.png\n","external_lung_v1/mask_0.3/lung_48.png\n","external_lung_v1/mask_0.3/lung_19.png\n","external_lung_v1/.ipynb_checkpoints/\n"]}],"source":["%cd /content\n","!tar -xvf /content/drive/MyDrive/hubmap+hpa_1st/multi_class_dataset/external_lung_v1.tar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Zp4i_Izm-pf","colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"status":"ok","timestamp":1665232273599,"user_tz":-540,"elapsed":16950,"user":{"displayName":"vov nanda","userId":"09231748423501225228"}},"outputId":"79db076c-eb51-4167-c64b-a3976934ee98"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.9 MB 4.4 MB/s \n","\u001b[K     |████████████████████████████████| 182 kB 75.3 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 87.3 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n","\u001b[K     |████████████████████████████████| 162 kB 92.1 MB/s \n","\u001b[K     |████████████████████████████████| 158 kB 71.4 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 60.1 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 73.5 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 90.2 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 87.1 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 91.9 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 88.6 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 92.9 MB/s \n","\u001b[K     |████████████████████████████████| 156 kB 94.9 MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":13}],"source":["\"\"\"\n","wandb is useful tool. If you have its account, please uncomment here and related training configs of mmsegmentation listed below.\n","You can view not only traing logs and validation logs with mDice but also visualization of segmentation of validation.\n","\"\"\"\n","\n","# !pip install -q wandb\n","\n","# import wandb\n","# wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"D8ZWOUR2Yb_2"},"source":["# MMSegmentation mDice custom settings  \n","This code is for calculating mDice score in a similar way as this competition metrics.  \n","Original: calculated by total area  \n","Customized: calculated by average of mDice scores of all images  \n","\n","You can ignore this part if not needed.  \n","This code isn't reflected on my customized mmseg repository."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i4tS_ScxY655"},"outputs":[],"source":["%%bash\n","cat << EOF > /content/mmsegmentation/mmseg/core/evaluation/metrics.py\n","# Copyright (c) OpenMMLab. All rights reserved.\n","from collections import OrderedDict\n","\n","import mmcv\n","import numpy as np\n","import torch\n","\n","\n","def f_score(precision, recall, beta=1):\n","    \"\"\"calculate the f-score value.\n","\n","    Args:\n","        precision (float | torch.Tensor): The precision value.\n","        recall (float | torch.Tensor): The recall value.\n","        beta (int): Determines the weight of recall in the combined score.\n","            Default: False.\n","\n","    Returns:\n","        [torch.tensor]: The f-score value.\n","    \"\"\"\n","    score = (1 + beta**2) * (precision * recall) / (\n","        (beta**2 * precision) + recall)\n","    return score\n","\n","\n","def intersect_and_union(pred_label,\n","                        label,\n","                        num_classes,\n","                        ignore_index,\n","                        label_map=dict(),\n","                        reduce_zero_label=False):\n","    \"\"\"Calculate intersection and Union.\n","\n","    Args:\n","        pred_label (ndarray | str): Prediction segmentation map\n","            or predict result filename.\n","        label (ndarray | str): Ground truth segmentation map\n","            or label filename.\n","        num_classes (int): Number of categories.\n","        ignore_index (int): Index that will be ignored in evaluation.\n","        label_map (dict): Mapping old labels to new labels. The parameter will\n","            work only when label is str. Default: dict().\n","        reduce_zero_label (bool): Whether ignore zero label. The parameter will\n","            work only when label is str. Default: False.\n","\n","     Returns:\n","         torch.Tensor: The intersection of prediction and ground truth\n","            histogram on all classes.\n","         torch.Tensor: The union of prediction and ground truth histogram on\n","            all classes.\n","         torch.Tensor: The prediction histogram on all classes.\n","         torch.Tensor: The ground truth histogram on all classes.\n","    \"\"\"\n","\n","    if isinstance(pred_label, str):\n","        pred_label = torch.from_numpy(np.load(pred_label))\n","    else:\n","        pred_label = torch.from_numpy((pred_label))\n","\n","    if isinstance(label, str):\n","        label = torch.from_numpy(\n","            mmcv.imread(label, flag='unchanged', backend='pillow'))\n","    else:\n","        label = torch.from_numpy(label)\n","\n","    if label_map is not None:\n","        for old_id, new_id in label_map.items():\n","            label[label == old_id] = new_id\n","    if reduce_zero_label:\n","        label[label == 0] = 255\n","        label = label - 1\n","        label[label == 254] = 255\n","\n","    mask = (label != ignore_index)\n","    pred_label = pred_label[mask]\n","    label = label[mask]\n","\n","    intersect = pred_label[pred_label == label]\n","    area_intersect = torch.histc(\n","        intersect.float(), bins=(num_classes), min=0, max=num_classes - 1)\n","    area_pred_label = torch.histc(\n","        pred_label.float(), bins=(num_classes), min=0, max=num_classes - 1)\n","    area_label = torch.histc(\n","        label.float(), bins=(num_classes), min=0, max=num_classes - 1)\n","    area_union = area_pred_label + area_label - area_intersect\n","    return area_intersect, area_union, area_pred_label, area_label\n","\n","\n","def total_intersect_and_union(results,\n","                              gt_seg_maps,\n","                              num_classes,\n","                              ignore_index,\n","                              label_map=dict(),\n","                              reduce_zero_label=False,\n","                              ):\n","    \"\"\"Calculate Total Intersection and Union.\n","\n","    Args:\n","        results (list[ndarray] | list[str]): List of prediction segmentation\n","            maps or list of prediction result filenames.\n","        gt_seg_maps (list[ndarray] | list[str] | Iterables): list of ground\n","            truth segmentation maps or list of label filenames.\n","        num_classes (int): Number of categories.\n","        ignore_index (int): Index that will be ignored in evaluation.\n","        label_map (dict): Mapping old labels to new labels. Default: dict().\n","        reduce_zero_label (bool): Whether ignore zero label. Default: False.\n","\n","     Returns:\n","         ndarray: The intersection of prediction and ground truth histogram\n","             on all classes.\n","         ndarray: The union of prediction and ground truth histogram on all\n","             classes.\n","         ndarray: The prediction histogram on all classes.\n","         ndarray: The ground truth histogram on all classes.\n","    \"\"\"\n","\n","    print('excuting <total_intersect_and_union>')\n","    total_area_intersect = torch.zeros((num_classes, ), dtype=torch.float64)\n","    total_area_union = torch.zeros((num_classes, ), dtype=torch.float64)\n","    total_area_pred_label = torch.zeros((num_classes, ), dtype=torch.float64)\n","    total_area_label = torch.zeros((num_classes, ), dtype=torch.float64)\n","    per_img_mdice = torch.zeros((num_classes, ), dtype=torch.float64)\n","\n","    cnt = 0\n","    for result, gt_seg_map in zip(results, gt_seg_maps):\n","        area_intersect, area_union, area_pred_label, area_label = \\\n","            intersect_and_union(\n","                result, gt_seg_map, num_classes, ignore_index,\n","                label_map, reduce_zero_label)\n","        total_area_intersect += area_intersect\n","        total_area_union += area_union\n","        total_area_pred_label += area_pred_label\n","        total_area_label += area_label\n","\n","        dice_coefficient = 2 * area_intersect / (area_pred_label + area_label)\n","        per_img_mdice += dice_coefficient\n","        cnt += 1\n","\n","    per_img_mdice /= cnt\n","    return total_area_intersect, total_area_union, total_area_pred_label, \\\n","        total_area_label, per_img_mdice\n","\n","\n","def mean_iou(results,\n","             gt_seg_maps,\n","             num_classes,\n","             ignore_index,\n","             nan_to_num=None,\n","             label_map=dict(),\n","             reduce_zero_label=False):\n","    \"\"\"Calculate Mean Intersection and Union (mIoU)\n","\n","    Args:\n","        results (list[ndarray] | list[str]): List of prediction segmentation\n","            maps or list of prediction result filenames.\n","        gt_seg_maps (list[ndarray] | list[str]): list of ground truth\n","            segmentation maps or list of label filenames.\n","        num_classes (int): Number of categories.\n","        ignore_index (int): Index that will be ignored in evaluation.\n","        nan_to_num (int, optional): If specified, NaN values will be replaced\n","            by the numbers defined by the user. Default: None.\n","        label_map (dict): Mapping old labels to new labels. Default: dict().\n","        reduce_zero_label (bool): Whether ignore zero label. Default: False.\n","\n","     Returns:\n","        dict[str, float | ndarray]:\n","            <aAcc> float: Overall accuracy on all images.\n","            <Acc> ndarray: Per category accuracy, shape (num_classes, ).\n","            <IoU> ndarray: Per category IoU, shape (num_classes, ).\n","    \"\"\"\n","    iou_result = eval_metrics(\n","        results=results,\n","        gt_seg_maps=gt_seg_maps,\n","        num_classes=num_classes,\n","        ignore_index=ignore_index,\n","        metrics=['mIoU'],\n","        nan_to_num=nan_to_num,\n","        label_map=label_map,\n","        reduce_zero_label=reduce_zero_label)\n","    return iou_result\n","\n","\n","def mean_dice(results,\n","              gt_seg_maps,\n","              num_classes,\n","              ignore_index,\n","              nan_to_num=None,\n","              label_map=dict(),\n","              reduce_zero_label=False):\n","    \"\"\"Calculate Mean Dice (mDice)\n","\n","    Args:\n","        results (list[ndarray] | list[str]): List of prediction segmentation\n","            maps or list of prediction result filenames.\n","        gt_seg_maps (list[ndarray] | list[str]): list of ground truth\n","            segmentation maps or list of label filenames.\n","        num_classes (int): Number of categories.\n","        ignore_index (int): Index that will be ignored in evaluation.\n","        nan_to_num (int, optional): If specified, NaN values will be replaced\n","            by the numbers defined by the user. Default: None.\n","        label_map (dict): Mapping old labels to new labels. Default: dict().\n","        reduce_zero_label (bool): Whether ignore zero label. Default: False.\n","\n","     Returns:\n","        dict[str, float | ndarray]: Default metrics.\n","            <aAcc> float: Overall accuracy on all images.\n","            <Acc> ndarray: Per category accuracy, shape (num_classes, ).\n","            <Dice> ndarray: Per category dice, shape (num_classes, ).\n","    \"\"\"\n","\n","    dice_result = eval_metrics(\n","        results=results,\n","        gt_seg_maps=gt_seg_maps,\n","        num_classes=num_classes,\n","        ignore_index=ignore_index,\n","        metrics=['mDice'],\n","        nan_to_num=nan_to_num,\n","        label_map=label_map,\n","        reduce_zero_label=reduce_zero_label)\n","    return dice_result\n","\n","\n","def mean_fscore(results,\n","                gt_seg_maps,\n","                num_classes,\n","                ignore_index,\n","                nan_to_num=None,\n","                label_map=dict(),\n","                reduce_zero_label=False,\n","                beta=1):\n","    \"\"\"Calculate Mean F-Score (mFscore)\n","\n","    Args:\n","        results (list[ndarray] | list[str]): List of prediction segmentation\n","            maps or list of prediction result filenames.\n","        gt_seg_maps (list[ndarray] | list[str]): list of ground truth\n","            segmentation maps or list of label filenames.\n","        num_classes (int): Number of categories.\n","        ignore_index (int): Index that will be ignored in evaluation.\n","        nan_to_num (int, optional): If specified, NaN values will be replaced\n","            by the numbers defined by the user. Default: None.\n","        label_map (dict): Mapping old labels to new labels. Default: dict().\n","        reduce_zero_label (bool): Whether ignore zero label. Default: False.\n","        beta (int): Determines the weight of recall in the combined score.\n","            Default: False.\n","\n","\n","     Returns:\n","        dict[str, float | ndarray]: Default metrics.\n","            <aAcc> float: Overall accuracy on all images.\n","            <Fscore> ndarray: Per category recall, shape (num_classes, ).\n","            <Precision> ndarray: Per category precision, shape (num_classes, ).\n","            <Recall> ndarray: Per category f-score, shape (num_classes, ).\n","    \"\"\"\n","    fscore_result = eval_metrics(\n","        results=results,\n","        gt_seg_maps=gt_seg_maps,\n","        num_classes=num_classes,\n","        ignore_index=ignore_index,\n","        metrics=['mFscore'],\n","        nan_to_num=nan_to_num,\n","        label_map=label_map,\n","        reduce_zero_label=reduce_zero_label,\n","        beta=beta)\n","    return fscore_result\n","\n","\n","def eval_metrics(results,\n","                 gt_seg_maps,\n","                 num_classes,\n","                 ignore_index,\n","                 metrics=['mIoU'],\n","                 nan_to_num=None,\n","                 label_map=dict(),\n","                 reduce_zero_label=False,\n","                 beta=1):\n","    \"\"\"Calculate evaluation metrics\n","    Args:\n","        results (list[ndarray] | list[str]): List of prediction segmentation\n","            maps or list of prediction result filenames.\n","        gt_seg_maps (list[ndarray] | list[str] | Iterables): list of ground\n","            truth segmentation maps or list of label filenames.\n","        num_classes (int): Number of categories.\n","        ignore_index (int): Index that will be ignored in evaluation.\n","        metrics (list[str] | str): Metrics to be evaluated, 'mIoU' and 'mDice'.\n","        nan_to_num (int, optional): If specified, NaN values will be replaced\n","            by the numbers defined by the user. Default: None.\n","        label_map (dict): Mapping old labels to new labels. Default: dict().\n","        reduce_zero_label (bool): Whether ignore zero label. Default: False.\n","     Returns:\n","        float: Overall accuracy on all images.\n","        ndarray: Per category accuracy, shape (num_classes, ).\n","        ndarray: Per category evaluation metrics, shape (num_classes, ).\n","    \"\"\"\n","\n","    total_area_intersect, total_area_union, total_area_pred_label, \\\n","        total_area_label, per_img_mdice = total_intersect_and_union(\n","            results, gt_seg_maps, num_classes, ignore_index, label_map,\n","            reduce_zero_label)\n","    ret_metrics = total_area_to_metrics(total_area_intersect, total_area_union,\n","                                        total_area_pred_label,\n","                                        total_area_label,\n","                                        per_img_mdice,\n","                                        metrics, nan_to_num,\n","                                        beta)\n","\n","    return ret_metrics\n","\n","\n","def pre_eval_to_metrics(pre_eval_results,\n","                        metrics=['mIoU'],\n","                        nan_to_num=None,\n","                        beta=1):\n","    \"\"\"Convert pre-eval results to metrics.\n","\n","    Args:\n","        pre_eval_results (list[tuple[torch.Tensor]]): per image eval results\n","            for computing evaluation metric\n","        metrics (list[str] | str): Metrics to be evaluated, 'mIoU' and 'mDice'.\n","        nan_to_num (int, optional): If specified, NaN values will be replaced\n","            by the numbers defined by the user. Default: None.\n","     Returns:\n","        float: Overall accuracy on all images.\n","        ndarray: Per category accuracy, shape (num_classes, ).\n","        ndarray: Per category evaluation metrics, shape (num_classes, ).\n","    \"\"\"\n","\n","    # convert list of tuples to tuple of lists, e.g.\n","    # [(A_1, B_1, C_1, D_1), ...,  (A_n, B_n, C_n, D_n)] to\n","    # ([A_1, ..., A_n], ..., [D_1, ..., D_n])\n","    print('\\nexcuting <pre_eval_to_metrics>')\n","    pre_eval_results = tuple(zip(*pre_eval_results))\n","    assert len(pre_eval_results) == 4\n","\n","    total_area_intersect = sum(pre_eval_results[0])\n","    total_area_union = sum(pre_eval_results[1])\n","    total_area_pred_label = sum(pre_eval_results[2])\n","    total_area_label = sum(pre_eval_results[3])\n","    per_img_mdice = None  # sum(pre_eval_results[4])\n","\n","    ret_metrics = total_area_to_metrics(total_area_intersect, total_area_union,\n","                                        total_area_pred_label,\n","                                        total_area_label,\n","                                        per_img_mdice,\n","                                        metrics, nan_to_num,\n","                                        beta)\n","\n","    return ret_metrics\n","\n","\n","def total_area_to_metrics(total_area_intersect,\n","                          total_area_union,\n","                          total_area_pred_label,\n","                          total_area_label,\n","                          per_img_mdice,\n","                          metrics=['mIoU'],\n","                          nan_to_num=None,\n","                          beta=1):\n","    \"\"\"Calculate evaluation metrics\n","    Args:\n","        total_area_intersect (ndarray): The intersection of prediction and\n","            ground truth histogram on all classes.\n","        total_area_union (ndarray): The union of prediction and ground truth\n","            histogram on all classes.\n","        total_area_pred_label (ndarray): The prediction histogram on all\n","            classes.\n","        total_area_label (ndarray): The ground truth histogram on all classes.\n","        metrics (list[str] | str): Metrics to be evaluated, 'mIoU' and 'mDice'.\n","        nan_to_num (int, optional): If specified, NaN values will be replaced\n","            by the numbers defined by the user. Default: None.\n","     Returns:\n","        float: Overall accuracy on all images.\n","        ndarray: Per category accuracy, shape (num_classes, ).\n","        ndarray: Per category evaluation metrics, shape (num_classes, ).\n","    \"\"\"\n","    if isinstance(metrics, str):\n","        metrics = [metrics]\n","    allowed_metrics = ['mIoU', 'mDice', 'mFscore']\n","    if not set(metrics).issubset(set(allowed_metrics)):\n","        raise KeyError('metrics {} is not supported'.format(metrics))\n","\n","    all_acc = total_area_intersect.sum() / total_area_label.sum()\n","    ret_metrics = OrderedDict({'aAcc': all_acc})\n","    for metric in metrics:\n","        if metric == 'mIoU':\n","            iou = total_area_intersect / total_area_union\n","            acc = total_area_intersect / total_area_label\n","            ret_metrics['IoU'] = iou\n","            ret_metrics['Acc'] = acc\n","        elif metric == 'mDice':\n","            print(f'\\033[31\\nper_img_mdice:{per_img_mdice}\\033[39m')\n","            if per_img_mdice is None:\n","                dice = 2 * total_area_intersect / (\n","                    total_area_pred_label + total_area_label)\n","            else:\n","                dice = per_img_mdice\n","\n","            acc = total_area_intersect / total_area_label\n","            ret_metrics['Dice'] = dice\n","            ret_metrics['Acc'] = acc\n","        elif metric == 'mFscore':\n","            precision = total_area_intersect / total_area_pred_label\n","            recall = total_area_intersect / total_area_label\n","            f_value = torch.tensor(\n","                [f_score(x[0], x[1], beta) for x in zip(precision, recall)])\n","            ret_metrics['Fscore'] = f_value\n","            ret_metrics['Precision'] = precision\n","            ret_metrics['Recall'] = recall\n","\n","    ret_metrics = {\n","        metric: value.numpy()\n","        for metric, value in ret_metrics.items()\n","    }\n","    if nan_to_num is not None:\n","        ret_metrics = OrderedDict({\n","            metric: np.nan_to_num(metric_value, nan=nan_to_num)\n","            for metric, metric_value in ret_metrics.items()\n","        })\n","    return ret_metrics\n","\n","EOF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ccxIFSjYbWj"},"outputs":[],"source":["%%bash\n","cat << EOF > /content/mmsegmentation/mmseg/core/evaluation/metrics.py\n","# Copyright (c) OpenMMLab. All rights reserved.\n","from collections import OrderedDict\n","\n","import mmcv\n","import numpy as np\n","import torch\n","\n","\n","def f_score(precision, recall, beta=1):\n","    \"\"\"calculate the f-score value.\n","\n","    Args:\n","        precision (float | torch.Tensor): The precision value.\n","        recall (float | torch.Tensor): The recall value.\n","        beta (int): Determines the weight of recall in the combined score.\n","            Default: False.\n","\n","    Returns:\n","        [torch.tensor]: The f-score value.\n","    \"\"\"\n","    score = (1 + beta**2) * (precision * recall) / (\n","        (beta**2 * precision) + recall)\n","    return score\n","\n","\n","def intersect_and_union(pred_label,\n","                        label,\n","                        num_classes,\n","                        ignore_index,\n","                        label_map=dict(),\n","                        reduce_zero_label=False):\n","    \"\"\"Calculate intersection and Union.\n","\n","    Args:\n","        pred_label (ndarray | str): Prediction segmentation map\n","            or predict result filename.\n","        label (ndarray | str): Ground truth segmentation map\n","            or label filename.\n","        num_classes (int): Number of categories.\n","        ignore_index (int): Index that will be ignored in evaluation.\n","        label_map (dict): Mapping old labels to new labels. The parameter will\n","            work only when label is str. Default: dict().\n","        reduce_zero_label (bool): Whether ignore zero label. The parameter will\n","            work only when label is str. Default: False.\n","\n","     Returns:\n","         torch.Tensor: The intersection of prediction and ground truth\n","            histogram on all classes.\n","         torch.Tensor: The union of prediction and ground truth histogram on\n","            all classes.\n","         torch.Tensor: The prediction histogram on all classes.\n","         torch.Tensor: The ground truth histogram on all classes.\n","    \"\"\"\n","\n","    if isinstance(pred_label, str):\n","        pred_label = torch.from_numpy(np.load(pred_label))\n","    else:\n","        pred_label = torch.from_numpy((pred_label))\n","\n","    if isinstance(label, str):\n","        label = torch.from_numpy(\n","            mmcv.imread(label, flag='unchanged', backend='pillow'))\n","    else:\n","        label = torch.from_numpy(label)\n","\n","    if label_map is not None:\n","        for old_id, new_id in label_map.items():\n","            label[label == old_id] = new_id\n","    if reduce_zero_label:\n","        label[label == 0] = 255\n","        label = label - 1\n","        label[label == 254] = 255\n","\n","    mask = (label != ignore_index)\n","    pred_label = pred_label[mask]\n","    label = label[mask]\n","\n","    intersect = pred_label[pred_label == label]\n","    area_intersect = torch.histc(\n","        intersect.float(), bins=(num_classes), min=0, max=num_classes - 1)\n","    area_pred_label = torch.histc(\n","        pred_label.float(), bins=(num_classes), min=0, max=num_classes - 1)\n","    area_label = torch.histc(\n","        label.float(), bins=(num_classes), min=0, max=num_classes - 1)\n","    area_union = area_pred_label + area_label - area_intersect\n","    return area_intersect, area_union, area_pred_label, area_label\n","\n","\n","def total_intersect_and_union(results,\n","                              gt_seg_maps,\n","                              num_classes,\n","                              ignore_index,\n","                              label_map=dict(),\n","                              reduce_zero_label=False,\n","                              ):\n","    \"\"\"Calculate Total Intersection and Union.\n","\n","    Args:\n","        results (list[ndarray] | list[str]): List of prediction segmentation\n","            maps or list of prediction result filenames.\n","        gt_seg_maps (list[ndarray] | list[str] | Iterables): list of ground\n","            truth segmentation maps or list of label filenames.\n","        num_classes (int): Number of categories.\n","        ignore_index (int): Index that will be ignored in evaluation.\n","        label_map (dict): Mapping old labels to new labels. Default: dict().\n","        reduce_zero_label (bool): Whether ignore zero label. Default: False.\n","\n","     Returns:\n","         ndarray: The intersection of prediction and ground truth histogram\n","             on all classes.\n","         ndarray: The union of prediction and ground truth histogram on all\n","             classes.\n","         ndarray: The prediction histogram on all classes.\n","         ndarray: The ground truth histogram on all classes.\n","    \"\"\"\n","\n","    print('excuting <total_intersect_and_union>')\n","    total_area_intersect = torch.zeros((num_classes, ), dtype=torch.float64)\n","    total_area_union = torch.zeros((num_classes, ), dtype=torch.float64)\n","    total_area_pred_label = torch.zeros((num_classes, ), dtype=torch.float64)\n","    total_area_label = torch.zeros((num_classes, ), dtype=torch.float64)\n","    per_img_mdice = torch.zeros((num_classes, ), dtype=torch.float64)\n","\n","    cnt = 0\n","    for result, gt_seg_map in zip(results, gt_seg_maps):\n","        area_intersect, area_union, area_pred_label, area_label = \\\n","            intersect_and_union(\n","                result, gt_seg_map, num_classes, ignore_index,\n","                label_map, reduce_zero_label)\n","        total_area_intersect += area_intersect\n","        total_area_union += area_union\n","        total_area_pred_label += area_pred_label\n","        total_area_label += area_label\n","\n","        dice_coefficient = 2 * area_intersect / (area_pred_label + area_label)\n","        per_img_mdice += dice_coefficient\n","        cnt += 1\n","\n","    per_img_mdice /= cnt\n","    return total_area_intersect, total_area_union, total_area_pred_label, \\\n","        total_area_label, per_img_mdice\n","\n","\n","def mean_iou(results,\n","             gt_seg_maps,\n","             num_classes,\n","             ignore_index,\n","             nan_to_num=None,\n","             label_map=dict(),\n","             reduce_zero_label=False):\n","    \"\"\"Calculate Mean Intersection and Union (mIoU)\n","\n","    Args:\n","        results (list[ndarray] | list[str]): List of prediction segmentation\n","            maps or list of prediction result filenames.\n","        gt_seg_maps (list[ndarray] | list[str]): list of ground truth\n","            segmentation maps or list of label filenames.\n","        num_classes (int): Number of categories.\n","        ignore_index (int): Index that will be ignored in evaluation.\n","        nan_to_num (int, optional): If specified, NaN values will be replaced\n","            by the numbers defined by the user. Default: None.\n","        label_map (dict): Mapping old labels to new labels. Default: dict().\n","        reduce_zero_label (bool): Whether ignore zero label. Default: False.\n","\n","     Returns:\n","        dict[str, float | ndarray]:\n","            <aAcc> float: Overall accuracy on all images.\n","            <Acc> ndarray: Per category accuracy, shape (num_classes, ).\n","            <IoU> ndarray: Per category IoU, shape (num_classes, ).\n","    \"\"\"\n","    iou_result = eval_metrics(\n","        results=results,\n","        gt_seg_maps=gt_seg_maps,\n","        num_classes=num_classes,\n","        ignore_index=ignore_index,\n","        metrics=['mIoU'],\n","        nan_to_num=nan_to_num,\n","        label_map=label_map,\n","        reduce_zero_label=reduce_zero_label)\n","    return iou_result\n","\n","\n","def mean_dice(results,\n","              gt_seg_maps,\n","              num_classes,\n","              ignore_index,\n","              nan_to_num=None,\n","              label_map=dict(),\n","              reduce_zero_label=False):\n","    \"\"\"Calculate Mean Dice (mDice)\n","\n","    Args:\n","        results (list[ndarray] | list[str]): List of prediction segmentation\n","            maps or list of prediction result filenames.\n","        gt_seg_maps (list[ndarray] | list[str]): list of ground truth\n","            segmentation maps or list of label filenames.\n","        num_classes (int): Number of categories.\n","        ignore_index (int): Index that will be ignored in evaluation.\n","        nan_to_num (int, optional): If specified, NaN values will be replaced\n","            by the numbers defined by the user. Default: None.\n","        label_map (dict): Mapping old labels to new labels. Default: dict().\n","        reduce_zero_label (bool): Whether ignore zero label. Default: False.\n","\n","     Returns:\n","        dict[str, float | ndarray]: Default metrics.\n","            <aAcc> float: Overall accuracy on all images.\n","            <Acc> ndarray: Per category accuracy, shape (num_classes, ).\n","            <Dice> ndarray: Per category dice, shape (num_classes, ).\n","    \"\"\"\n","\n","    dice_result = eval_metrics(\n","        results=results,\n","        gt_seg_maps=gt_seg_maps,\n","        num_classes=num_classes,\n","        ignore_index=ignore_index,\n","        metrics=['mDice'],\n","        nan_to_num=nan_to_num,\n","        label_map=label_map,\n","        reduce_zero_label=reduce_zero_label)\n","    return dice_result\n","\n","\n","def mean_fscore(results,\n","                gt_seg_maps,\n","                num_classes,\n","                ignore_index,\n","                nan_to_num=None,\n","                label_map=dict(),\n","                reduce_zero_label=False,\n","                beta=1):\n","    \"\"\"Calculate Mean F-Score (mFscore)\n","\n","    Args:\n","        results (list[ndarray] | list[str]): List of prediction segmentation\n","            maps or list of prediction result filenames.\n","        gt_seg_maps (list[ndarray] | list[str]): list of ground truth\n","            segmentation maps or list of label filenames.\n","        num_classes (int): Number of categories.\n","        ignore_index (int): Index that will be ignored in evaluation.\n","        nan_to_num (int, optional): If specified, NaN values will be replaced\n","            by the numbers defined by the user. Default: None.\n","        label_map (dict): Mapping old labels to new labels. Default: dict().\n","        reduce_zero_label (bool): Whether ignore zero label. Default: False.\n","        beta (int): Determines the weight of recall in the combined score.\n","            Default: False.\n","\n","\n","     Returns:\n","        dict[str, float | ndarray]: Default metrics.\n","            <aAcc> float: Overall accuracy on all images.\n","            <Fscore> ndarray: Per category recall, shape (num_classes, ).\n","            <Precision> ndarray: Per category precision, shape (num_classes, ).\n","            <Recall> ndarray: Per category f-score, shape (num_classes, ).\n","    \"\"\"\n","    fscore_result = eval_metrics(\n","        results=results,\n","        gt_seg_maps=gt_seg_maps,\n","        num_classes=num_classes,\n","        ignore_index=ignore_index,\n","        metrics=['mFscore'],\n","        nan_to_num=nan_to_num,\n","        label_map=label_map,\n","        reduce_zero_label=reduce_zero_label,\n","        beta=beta)\n","    return fscore_result\n","\n","\n","def eval_metrics(results,\n","                 gt_seg_maps,\n","                 num_classes,\n","                 ignore_index,\n","                 metrics=['mIoU'],\n","                 nan_to_num=None,\n","                 label_map=dict(),\n","                 reduce_zero_label=False,\n","                 beta=1):\n","    \"\"\"Calculate evaluation metrics\n","    Args:\n","        results (list[ndarray] | list[str]): List of prediction segmentation\n","            maps or list of prediction result filenames.\n","        gt_seg_maps (list[ndarray] | list[str] | Iterables): list of ground\n","            truth segmentation maps or list of label filenames.\n","        num_classes (int): Number of categories.\n","        ignore_index (int): Index that will be ignored in evaluation.\n","        metrics (list[str] | str): Metrics to be evaluated, 'mIoU' and 'mDice'.\n","        nan_to_num (int, optional): If specified, NaN values will be replaced\n","            by the numbers defined by the user. Default: None.\n","        label_map (dict): Mapping old labels to new labels. Default: dict().\n","        reduce_zero_label (bool): Whether ignore zero label. Default: False.\n","     Returns:\n","        float: Overall accuracy on all images.\n","        ndarray: Per category accuracy, shape (num_classes, ).\n","        ndarray: Per category evaluation metrics, shape (num_classes, ).\n","    \"\"\"\n","\n","    total_area_intersect, total_area_union, total_area_pred_label, \\\n","        total_area_label, per_img_mdice = total_intersect_and_union(\n","            results, gt_seg_maps, num_classes, ignore_index, label_map,\n","            reduce_zero_label)\n","    ret_metrics = total_area_to_metrics(total_area_intersect, total_area_union,\n","                                        total_area_pred_label,\n","                                        total_area_label,\n","                                        per_img_mdice,\n","                                        metrics, nan_to_num,\n","                                        beta)\n","\n","    return ret_metrics\n","\n","\n","def pre_eval_to_metrics(pre_eval_results,\n","                        metrics=['mIoU'],\n","                        nan_to_num=None,\n","                        beta=1):\n","    \"\"\"Convert pre-eval results to metrics.\n","\n","    Args:\n","        pre_eval_results (list[tuple[torch.Tensor]]): per image eval results\n","            for computing evaluation metric\n","        metrics (list[str] | str): Metrics to be evaluated, 'mIoU' and 'mDice'.\n","        nan_to_num (int, optional): If specified, NaN values will be replaced\n","            by the numbers defined by the user. Default: None.\n","     Returns:\n","        float: Overall accuracy on all images.\n","        ndarray: Per category accuracy, shape (num_classes, ).\n","        ndarray: Per category evaluation metrics, shape (num_classes, ).\n","    \"\"\"\n","\n","    # convert list of tuples to tuple of lists, e.g.\n","    # [(A_1, B_1, C_1, D_1), ...,  (A_n, B_n, C_n, D_n)] to\n","    # ([A_1, ..., A_n], ..., [D_1, ..., D_n])\n","    print('\\nexcuting <pre_eval_to_metrics>')\n","    pre_eval_results = tuple(zip(*pre_eval_results))\n","    assert len(pre_eval_results) == 4\n","\n","    total_area_intersect = sum(pre_eval_results[0])\n","    total_area_union = sum(pre_eval_results[1])\n","    total_area_pred_label = sum(pre_eval_results[2])\n","    total_area_label = sum(pre_eval_results[3])\n","    per_img_mdice = None  # sum(pre_eval_results[4])\n","\n","    ret_metrics = total_area_to_metrics(total_area_intersect, total_area_union,\n","                                        total_area_pred_label,\n","                                        total_area_label,\n","                                        per_img_mdice,\n","                                        metrics, nan_to_num,\n","                                        beta)\n","\n","    return ret_metrics\n","\n","\n","def total_area_to_metrics(total_area_intersect,\n","                          total_area_union,\n","                          total_area_pred_label,\n","                          total_area_label,\n","                          per_img_mdice,\n","                          metrics=['mIoU'],\n","                          nan_to_num=None,\n","                          beta=1):\n","    \"\"\"Calculate evaluation metrics\n","    Args:\n","        total_area_intersect (ndarray): The intersection of prediction and\n","            ground truth histogram on all classes.\n","        total_area_union (ndarray): The union of prediction and ground truth\n","            histogram on all classes.\n","        total_area_pred_label (ndarray): The prediction histogram on all\n","            classes.\n","        total_area_label (ndarray): The ground truth histogram on all classes.\n","        metrics (list[str] | str): Metrics to be evaluated, 'mIoU' and 'mDice'.\n","        nan_to_num (int, optional): If specified, NaN values will be replaced\n","            by the numbers defined by the user. Default: None.\n","     Returns:\n","        float: Overall accuracy on all images.\n","        ndarray: Per category accuracy, shape (num_classes, ).\n","        ndarray: Per category evaluation metrics, shape (num_classes, ).\n","    \"\"\"\n","    if isinstance(metrics, str):\n","        metrics = [metrics]\n","    allowed_metrics = ['mIoU', 'mDice', 'mFscore']\n","    if not set(metrics).issubset(set(allowed_metrics)):\n","        raise KeyError('metrics {} is not supported'.format(metrics))\n","\n","    all_acc = total_area_intersect.sum() / total_area_label.sum()\n","    ret_metrics = OrderedDict({'aAcc': all_acc})\n","    for metric in metrics:\n","        if metric == 'mIoU':\n","            iou = total_area_intersect / total_area_union\n","            acc = total_area_intersect / total_area_label\n","            ret_metrics['IoU'] = iou\n","            ret_metrics['Acc'] = acc\n","        elif metric == 'mDice':\n","            print(f'\\033[31\\nper_img_mdice:{per_img_mdice}\\033[39m')\n","            if per_img_mdice is None:\n","                dice = 2 * total_area_intersect / (\n","                    total_area_pred_label + total_area_label)\n","            else:\n","                dice = per_img_mdice\n","\n","            acc = total_area_intersect / total_area_label\n","            ret_metrics['Dice'] = dice\n","            ret_metrics['Acc'] = acc\n","        elif metric == 'mFscore':\n","            precision = total_area_intersect / total_area_pred_label\n","            recall = total_area_intersect / total_area_label\n","            f_value = torch.tensor(\n","                [f_score(x[0], x[1], beta) for x in zip(precision, recall)])\n","            ret_metrics['Fscore'] = f_value\n","            ret_metrics['Precision'] = precision\n","            ret_metrics['Recall'] = recall\n","\n","    ret_metrics = {\n","        metric: value.numpy()\n","        for metric, value in ret_metrics.items()\n","    }\n","    if nan_to_num is not None:\n","        ret_metrics = OrderedDict({\n","            metric: np.nan_to_num(metric_value, nan=nan_to_num)\n","            for metric, metric_value in ret_metrics.items()\n","        })\n","    return ret_metrics\n","\n","EOF"]},{"cell_type":"markdown","metadata":{"id":"x-EnYSaKKVIU"},"source":["# Prepare MMSegmentation training configs"]},{"cell_type":"code","source":["!mkdir /content/training_configs"],"metadata":{"id":"_kg5MMK8Km5a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bash\n","\n","cat << EOF > /content/training_configs/segformer_mit-b3_1024.py\n","\n","#-------------------------------------------------------------------------\n","# model settings\n","norm_cfg = dict(type='GN', num_groups=32, requires_grad=True)\n","model = dict(\n","    type='EncoderDecoder',\n","    backbone=dict(\n","        type='MixVisionTransformer',\n","        init_cfg=dict(\n","            type='Pretrained',\n","            checkpoint='https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b3_20220624-13b1141c.pth'\n","            ),\n","        in_channels=3,\n","        embed_dims=64,\n","        num_stages=4,\n","        num_layers=[3, 4, 18, 3],\n","        num_heads=[1, 2, 5, 8],\n","        patch_sizes=[7, 3, 3, 3],\n","        sr_ratios=[8, 4, 2, 1],\n","        out_indices=(0, 1, 2, 3),\n","        mlp_ratio=4,\n","        qkv_bias=True,\n","        drop_rate=0.0,\n","        attn_drop_rate=0.0,\n","        drop_path_rate=0.1),\n","    decode_head=dict(\n","        type='SegformerHead',\n","        in_channels=[64, 128, 320, 512],\n","        in_index=[0, 1, 2, 3],\n","        channels=256,\n","        dropout_ratio=0.1,\n","        num_classes=2,\n","        norm_cfg=norm_cfg,\n","        align_corners=False,\n","        loss_decode=[\n","            dict(type='CrossEntropyLoss', loss_name='loss_ce', loss_weight=1),\n","            dict(type='LovaszLoss', loss_name='loss_lovasz', per_image=True, loss_weight=3),\n","        ]\n","        ),\n","    train_cfg=dict(),\n","    test_cfg=dict(mode='whole'))\n","\n","\n","\n","#-------------------------------------------------------------------------\n","# dataset settings\n","\n","dataset_type = 'HubmapDataset'\n","data_root = '/content'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","crop_size = (1024, 1024)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='OrgansDataAug'),\n","    dict(type='Resize', img_scale=[(480,480),(1600, 1600)], keep_ratio=False, ratio_range=None),\n","    dict(type='RandomCrop', crop_size=crop_size, cat_max_ratio=0.5),\n","    dict(type='RandomFlip', direction='horizontal', prob=0),\n","    #dict(type='RandomRotate', degree=180, prob=0.7),\n","    dict(type='SaveOverlay', save_root_dir='/content', save_num=500, no_overlay=True),\n","    dict(type='Convert2Class1'),\n","    dict(type='Normalize', **img_norm_cfg),\n","    dict(type='Pad', size=crop_size, pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(1024, 1024),\n","        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n","        flip=True,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(type='Normalize', **img_norm_cfg),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img']),\n","        ])\n","]\n","\n","\n","data = dict(\n","    samples_per_gpu=1,\n","    workers_per_gpu=2,\n","    train=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        img_dir=[\n","            'hubmap_multi_2000x2000/images',\n","            'hubmap_multi_2000x2000/images_stained_with_hubmap1',\n","            'hubmap_multi_2000x2000/images_stained_with_hubmap2',\n","            'hubmap_multi_2000x2000/images_stained_with_sample1',\n","            'hubmap_multi_2000x2000/images_stained_with_test',\n","            'external_spleen_v2/image',\n","            'external_lung_v1/image'\n","        ],\n","        ann_dir=[\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'external_spleen_v2/mask',\n","            'external_lung_v1/mask_0.3'\n","        ],\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        split= [\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/external_spleen_v2/trainval.txt',\n","            '/content/external_lung_v1/external_lung.txt'\n","        ],\n","        pipeline=train_pipeline),\n","    val=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        img_dir='hubmap_multi_2000x2000/images_stained_with_hubmap1',\n","        ann_dir='hubmap_multi_2000x2000/lung_refined_masks_2class',\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        split='/content/hubmap_multi_2000x2000/ImageSets/Segmentation/val_fold0.txt',\n","        pipeline=test_pipeline),\n","    test=dict()\n","    )\n","\n","#-------------------------------------------------------------------------\n","# schedule\n","\n","# optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0005)\n","optimizer_config = dict()\n","# lr_config = dict(warmup='linear', warmup_iters=500, by_epoch=False, \n","#                  policy='poly', power=0.9, min_lr=0.001)\n","\n","optimizer = dict(\n","    type='AdamW',\n","    lr=0.00006,\n","    betas=(0.9, 0.999),\n","    weight_decay=0.01,\n","    paramwise_cfg=dict(\n","        custom_keys={\n","            'pos_block': dict(decay_mult=0.),\n","            'norm': dict(decay_mult=0.),\n","            'head': dict(lr_mult=10.)\n","        }))\n","\n","lr_config = dict(\n","    policy='poly',\n","    warmup='linear',\n","    warmup_iters=1500,\n","    warmup_ratio=1e-6,\n","    power=1.0,\n","    min_lr=0,\n","    by_epoch=False)\n","\n","\n","runner = dict(type='IterBasedRunner', max_iters=45000)\n","checkpoint_config = dict(by_epoch=False, interval=45000) \n","evaluation = dict(interval=3000, metric=['mDice', 'mIoU'], pre_eval=False)\n","\n","#-------------------------------------------------------------------------\n","# runtime\n","\n","log_config = dict(\n","    interval=10,\n","    hooks=[\n","        dict(type='TextLoggerHook', by_epoch=False),\n","\n","        # dict(type='MMSegWandbHook',\n","        #         init_kwargs=dict(project=\"HubMap\",\n","        #                          name=f'segformer_mit-b3_1024',\n","        #                          config={'config':'segformer_mit-b3_1024.py',\n","        #                                  'comment':'No comment',\n","        #                                  'dataset_type': dataset_type,\n","        #                                  'model': model,\n","        #                                  'crop_size': crop_size,\n","        #                                  'train_pipeline': train_pipeline,\n","        #                                  'test_pipeline': test_pipeline,\n","        #                                  'optimizer':optimizer,\n","        #                                  'lr_config':lr_config,\n","        #                                  'runner': runner,\n","        #                                  'checkpoint_config': checkpoint_config,\n","        #                                  'evaluation':evaluation,\n","        #                                  'data': data,\n","        #                                  },\n","        #                          #group='',\n","        #                          entity=None),\n","        #         interval=3000,\n","        #         log_checkpoint=True,\n","        #         log_checkpoint_metadata=True,\n","        #         num_eval_images=100)\n","    ]\n","    )\n","\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = None\n","resume_from = None\n","workflow = [('train', 1)]\n","cudnn_benchmark = True\n","\n","\n","\n","#-------------------------------------------------------------------------\n","work_dir='/content/hubmap_training'\n","\n","from mmseg.apis import set_random_seed\n","set_random_seed(0, deterministic=False)\n","\n","# 必須\n","seed = 0\n","gpu_ids = range(1)\n","device='cuda'\n","\n","EOF"],"metadata":{"id":"8vc4BAKJZDY9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q5uDxvI6dmP3"},"outputs":[],"source":["%%bash\n","\n","cat << EOF > /content/training_configs/segformer_mit-b4_960.py\n","\n","#-------------------------------------------------------------------------\n","# model settings\n","norm_cfg = dict(type='GN', num_groups=32, requires_grad=True)\n","model = dict(\n","    type='EncoderDecoder',\n","    pretrained='https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b4_20220624-d588d980.pth',\n","    backbone=dict(\n","        type='MixVisionTransformer',\n","        in_channels=3,\n","        embed_dims=64,\n","        num_stages=4,\n","        num_layers=[3, 8, 27, 3],\n","        num_heads=[1, 2, 5, 8],\n","        patch_sizes=[7, 3, 3, 3],\n","        sr_ratios=[8, 4, 2, 1],\n","        out_indices=(0, 1, 2, 3),\n","        mlp_ratio=4,\n","        qkv_bias=True,\n","        drop_rate=0.0,\n","        attn_drop_rate=0.0,\n","        drop_path_rate=0.1),\n","    decode_head=dict(\n","        type='SegformerHead',\n","        in_channels=[64, 128, 320, 512],\n","        in_index=[0, 1, 2, 3],\n","        channels=256,\n","        dropout_ratio=0.1,\n","        num_classes=2,\n","        norm_cfg=norm_cfg,\n","        align_corners=False,\n","        loss_decode=[\n","            dict(type='CrossEntropyLoss', loss_name='loss_ce', loss_weight=1),\n","            dict(type='LovaszLoss', loss_name='loss_lovasz', per_image=True, loss_weight=3),\n","        ]\n","        ),\n","    train_cfg=dict(),\n","    test_cfg=dict(mode='whole'))\n","\n","\n","\n","#-------------------------------------------------------------------------\n","# dataset settings\n","\n","dataset_type = 'HubmapDataset'\n","data_root = '/content'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","crop_size = (960, 960)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='OrgansDataAug'),\n","    dict(type='Resize', img_scale=[(480,480),(1600, 1600)], keep_ratio=False, ratio_range=None),\n","    dict(type='RandomCrop', crop_size=crop_size, cat_max_ratio=0.5),\n","    dict(type='RandomFlip', direction='horizontal', prob=0),\n","    #dict(type='RandomRotate', degree=180, prob=0.7),\n","    dict(type='SaveOverlay', save_root_dir='/content', save_num=500, no_overlay=True),\n","    dict(type='Convert2Class1'),\n","    dict(type='Normalize', **img_norm_cfg),\n","    dict(type='Pad', size=crop_size, pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(960, 960),\n","        flip=True,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(type='Normalize', **img_norm_cfg),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img']),\n","        ])\n","]\n","\n","\n","data = dict(\n","    samples_per_gpu=1,\n","    workers_per_gpu=2,\n","    train=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        img_dir=[\n","            'hubmap_multi_2000x2000/images',\n","            'hubmap_multi_2000x2000/images_stained_with_hubmap1',\n","            'hubmap_multi_2000x2000/images_stained_with_hubmap2',\n","            'hubmap_multi_2000x2000/images_stained_with_sample1',\n","            'hubmap_multi_2000x2000/images_stained_with_test',\n","            'external_spleen_v2/image',\n","            'external_lung_v1/image'\n","        ],\n","        ann_dir=[\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'external_spleen_v2/mask',\n","            'external_lung_v1/mask_0.3'\n","        ],\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        split= [\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/external_spleen_v2/trainval.txt',\n","            '/content/external_lung_v1/external_lung.txt'\n","        ],\n","        pipeline=train_pipeline),\n","    val=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        img_dir='hubmap_multi_2000x2000/images_stained_with_hubmap1',\n","        ann_dir='hubmap_multi_2000x2000/lung_refined_masks_2class',\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        split='/content/hubmap_multi_2000x2000/ImageSets/Segmentation/val_fold0.txt',\n","        pipeline=test_pipeline),\n","    test=dict()\n","    )\n","\n","#-------------------------------------------------------------------------\n","# scheduler\n","\n","# optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0005)\n","optimizer_config = dict()\n","# lr_config = dict(warmup='linear', warmup_iters=500, by_epoch=False, \n","#                  policy='poly', power=0.9, min_lr=0.001)\n","\n","optimizer = dict(\n","    type='AdamW',\n","    lr=0.00006,\n","    betas=(0.9, 0.999),\n","    weight_decay=0.01,\n","    paramwise_cfg=dict(\n","        custom_keys={\n","            'pos_block': dict(decay_mult=0.),\n","            'norm': dict(decay_mult=0.),\n","            'head': dict(lr_mult=10.)\n","        }))\n","\n","lr_config = dict(\n","    policy='poly',\n","    warmup='linear',\n","    warmup_iters=1500,\n","    warmup_ratio=1e-6,\n","    power=1.0,\n","    min_lr=0,\n","    by_epoch=False)\n","\n","\n","# runtime settings\n","runner = dict(type='IterBasedRunner', max_iters=45000)\n","checkpoint_config = dict(by_epoch=False, interval=45000)\n","evaluation = dict(interval=3000, metric=['mDice', 'mIoU'], pre_eval=False)\n","\n","#-------------------------------------------------------------------------\n","# runtime\n","\n","log_config = dict(\n","    interval=10,\n","    hooks=[\n","        dict(type='TextLoggerHook', by_epoch=False),\n","\n","        # dict(type='MMSegWandbHook',\n","        #         init_kwargs=dict(project=\"HubMap\",\n","        #                          name=f'segformer_mit-b4_960',\n","        #                          config={'config':'segformer_mit-b4_960.py',\n","        #                                  'comment':'No comment',\n","        #                                  'dataset_type': dataset_type,\n","        #                                  'model': model,\n","        #                                  'crop_size': crop_size,\n","        #                                  'train_pipeline': train_pipeline,\n","        #                                  'test_pipeline': test_pipeline,\n","        #                                  'optimizer':optimizer,\n","        #                                  'lr_config':lr_config,\n","        #                                  'runner': runner,\n","        #                                  'checkpoint_config': checkpoint_config,\n","        #                                  'evaluation':evaluation,\n","        #                                  'data': data,\n","        #                                  },\n","        #                          #group='',\n","        #                          entity=None),\n","        #         interval=3000,\n","        #         log_checkpoint=True,\n","        #         log_checkpoint_metadata=True,\n","        #         num_eval_images=100)\n","    ]\n","    )\n","\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = None\n","resume_from = None\n","workflow = [('train', 1)]\n","cudnn_benchmark = True\n","\n","\n","\n","#-------------------------------------------------------------------------\n","work_dir='/content/hubmap_training'\n","\n","from mmseg.apis import set_random_seed\n","set_random_seed(0, deterministic=False)\n","\n","seed = 0\n","gpu_ids = range(1)\n","device='cuda'\n","\n","EOF"]},{"cell_type":"code","source":["%%bash\n","\n","cat << EOF > /content/training_configs/segformer_mit-b4_960_2.py\n","\n","#-------------------------------------------------------------------------\n","# model settings\n","norm_cfg = dict(type='GN', num_groups=32, requires_grad=True)\n","model = dict(\n","    type='EncoderDecoder',\n","    #pretrained='https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b4_20220624-d588d980.pth',\n","    backbone=dict(\n","        type='MixVisionTransformer',\n","        in_channels=3,\n","        embed_dims=64,\n","        num_stages=4,\n","        num_layers=[3, 8, 27, 3],\n","        num_heads=[1, 2, 5, 8],\n","        patch_sizes=[7, 3, 3, 3],\n","        sr_ratios=[8, 4, 2, 1],\n","        out_indices=(0, 1, 2, 3),\n","        mlp_ratio=4,\n","        qkv_bias=True,\n","        drop_rate=0.0,\n","        attn_drop_rate=0.0,\n","        drop_path_rate=0.1),\n","    decode_head=dict(\n","        type='SegformerHead',\n","        in_channels=[64, 128, 320, 512],\n","        in_index=[0, 1, 2, 3],\n","        channels=256,\n","        dropout_ratio=0.1,\n","        num_classes=2,\n","        norm_cfg=norm_cfg,\n","        align_corners=False,\n","        loss_decode=[\n","            dict(type='CrossEntropyLoss', loss_name='loss_ce', loss_weight=1),\n","            dict(type='LovaszLoss', loss_name='loss_lovasz', per_image=True, loss_weight=3),\n","        ]\n","        ),\n","    train_cfg=dict(),\n","    test_cfg=dict(mode='whole'))\n","\n","\n","\n","#-------------------------------------------------------------------------\n","# dataset settings\n","\n","dataset_type = 'HubmapDataset'\n","data_root = '/content'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","crop_size = (960, 960)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='OrgansDataAug'),\n","    dict(type='Resize', img_scale=[(480,480),(1600, 1600)], keep_ratio=False, ratio_range=None),\n","    dict(type='RandomCrop', crop_size=crop_size, cat_max_ratio=0.5),\n","    dict(type='RandomFlip', direction='horizontal', prob=0),\n","    #dict(type='RandomRotate', degree=180, prob=0.7),\n","    dict(type='SaveOverlay', save_root_dir='/content', save_num=500, no_overlay=True),\n","    dict(type='Convert2Class1'),\n","    dict(type='Normalize', **img_norm_cfg),\n","    dict(type='Pad', size=crop_size, pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(960, 960),\n","        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n","        flip=True,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(type='Normalize', **img_norm_cfg),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img']),\n","        ])\n","]\n","\n","\n","data = dict(\n","    samples_per_gpu=1,\n","    workers_per_gpu=2,\n","    train=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        img_dir=[\n","            'hubmap_multi_2000x2000/images',\n","            'hubmap_multi_2000x2000/images_stained_with_hubmap1',\n","            'hubmap_multi_2000x2000/images_stained_with_hubmap2',\n","            'hubmap_multi_2000x2000/images_stained_with_sample1',\n","            'hubmap_multi_2000x2000/images_stained_with_test',\n","            'external_spleen_v2/image',\n","            'external_lung_v1/image'\n","        ],\n","        ann_dir=[\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'external_spleen_v2/mask',\n","            'external_lung_v1/mask_0.3'\n","        ],\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        split= [\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/external_spleen_v2/trainval.txt',\n","            '/content/external_lung_v1/external_lung.txt'\n","        ],\n","        pipeline=train_pipeline),\n","    val=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        img_dir='hubmap_multi_2000x2000/images_stained_with_hubmap1',\n","        ann_dir='hubmap_multi_2000x2000/lung_refined_masks_2class',\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        split='/content/hubmap_multi_2000x2000/ImageSets/Segmentation/val_fold0.txt',\n","        pipeline=test_pipeline),\n","    test=dict()\n","    )\n","\n","#-------------------------------------------------------------------------\n","# schedule\n","\n","# optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0005)\n","optimizer_config = dict()\n","# lr_config = dict(warmup='linear', warmup_iters=500, by_epoch=False, \n","#                  policy='poly', power=0.9, min_lr=0.001)\n","\n","optimizer = dict(\n","    type='AdamW',\n","    lr=0.00006,\n","    betas=(0.9, 0.999),\n","    weight_decay=0.01,\n","    paramwise_cfg=dict(\n","        custom_keys={\n","            'pos_block': dict(decay_mult=0.),\n","            'norm': dict(decay_mult=0.),\n","            'head': dict(lr_mult=10.)\n","        }))\n","\n","lr_config = dict(\n","    policy='poly',\n","    warmup='linear',\n","    warmup_iters=1500,\n","    warmup_ratio=1e-6,\n","    power=1.0,\n","    min_lr=0,\n","    by_epoch=False)\n","\n","\n","# runtime settings\n","runner = dict(type='IterBasedRunner', max_iters=45000)\n","checkpoint_config = dict(by_epoch=False, interval=45000)\n","evaluation = dict(interval=3000, metric=['mDice', 'mIoU'], pre_eval=False)\n","\n","#-------------------------------------------------------------------------\n","# _base_/default_runtime.py\n","\n","log_config = dict(\n","    interval=10,\n","    hooks=[\n","        dict(type='TextLoggerHook', by_epoch=False),\n","\n","        # dict(type='MMSegWandbHook',\n","        #         init_kwargs=dict(project=\"HubMap\",\n","        #                          name=f'segformer_mit-b4_960_2',\n","        #                          config={'config':'segformer_mit-b4_960_2.py',\n","        #                                  'comment':'No comment',\n","        #                                  'dataset_type': dataset_type,\n","        #                                  'model': model,\n","        #                                  'crop_size': crop_size,\n","        #                                  'train_pipeline': train_pipeline,\n","        #                                  'test_pipeline': test_pipeline,\n","        #                                  'optimizer':optimizer,\n","        #                                  'lr_config':lr_config,\n","        #                                  'runner': runner,\n","        #                                  'checkpoint_config': checkpoint_config,\n","        #                                  'evaluation':evaluation,\n","        #                                  'data': data,\n","        #                                  },\n","        #                          #group='',\n","        #                          entity=None),\n","        #         interval=3000,\n","        #         log_checkpoint=True,\n","        #         log_checkpoint_metadata=True,\n","        #         num_eval_images=100)\n","    ]\n","    )\n","\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b4_8x1_1024x1024_160k_cityscapes/segformer_mit-b4_8x1_1024x1024_160k_cityscapes_20211207_080709-07f6c333.pth'\n","resume_from = None\n","workflow = [('train', 1)]\n","cudnn_benchmark = True\n","\n","\n","\n","#-------------------------------------------------------------------------\n","work_dir='/content/hubmap_training'\n","\n","from mmseg.apis import set_random_seed\n","set_random_seed(0, deterministic=False)\n","\n","seed = 0\n","gpu_ids = range(1)\n","device='cuda'\n","\n","EOF"],"metadata":{"id":"xuDBOIfFZcS7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bash\n","\n","cat << EOF > /content/training_configs/segformer_mit-b5_928.py\n","\n","#-------------------------------------------------------------------------\n","# model settings\n","\n","norm_cfg = dict(type='GN', num_groups=32, requires_grad=True)\n","model = dict(\n","    type='EncoderDecoder',\n","    backbone=dict(\n","        type='MixVisionTransformer',\n","        init_cfg=dict(\n","            type='Pretrained',\n","            checkpoint='https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'\n","            ),\n","        in_channels=3,\n","        embed_dims=64,\n","        num_stages=4,\n","        num_layers=[3, 6, 40, 3],\n","        num_heads=[1, 2, 5, 8],\n","        patch_sizes=[7, 3, 3, 3],\n","        sr_ratios=[8, 4, 2, 1],\n","        out_indices=(0, 1, 2, 3),\n","        mlp_ratio=4,\n","        qkv_bias=True,\n","        drop_rate=0.0,\n","        attn_drop_rate=0.0,\n","        drop_path_rate=0.1),\n","    decode_head=dict(\n","        type='SegformerHead',\n","        in_channels=[64, 128, 320, 512],\n","        in_index=[0, 1, 2, 3],\n","        channels=256,\n","        dropout_ratio=0.1,\n","        num_classes=2,\n","        norm_cfg=norm_cfg,\n","        align_corners=False,\n","        loss_decode=[\n","            dict(type='CrossEntropyLoss', loss_name='loss_ce', loss_weight=1),\n","            dict(type='LovaszLoss', loss_name='loss_lovasz', per_image=True, loss_weight=3),\n","        ]\n","        ),\n","    train_cfg=dict(),\n","    test_cfg=dict(mode='whole'))\n","\n","\n","\n","#-------------------------------------------------------------------------\n","# dataset settings\n","\n","dataset_type = 'HubmapDataset'\n","data_root = '/content'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","crop_size = (928, 928)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='OrgansDataAug'),\n","    dict(type='Resize', img_scale=[(480,480),(1600, 1600)], keep_ratio=False, ratio_range=None),\n","    dict(type='RandomCrop', crop_size=crop_size, cat_max_ratio=0.5),\n","    dict(type='RandomFlip', direction='horizontal', prob=0),\n","    #dict(type='RandomRotate', degree=180, prob=0.7),\n","    dict(type='SaveOverlay', save_root_dir='/content', save_num=500, no_overlay=True),\n","    dict(type='Convert2Class1'),\n","    dict(type='Normalize', **img_norm_cfg),\n","    dict(type='Pad', size=crop_size, pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=crop_size,\n","        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n","        flip=True,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(type='Normalize', **img_norm_cfg),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img']),\n","        ])\n","]\n","\n","\n","data = dict(\n","    samples_per_gpu=1,\n","    workers_per_gpu=2,\n","    train=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        img_dir=[\n","            'hubmap_multi_2000x2000/images',\n","            'hubmap_multi_2000x2000/images_stained_with_hubmap1',\n","            'hubmap_multi_2000x2000/images_stained_with_hubmap2',\n","            'hubmap_multi_2000x2000/images_stained_with_sample1',\n","            'hubmap_multi_2000x2000/images_stained_with_test',\n","            'external_spleen_v2/image',\n","            'external_lung_v1/image'\n","        ],\n","        ann_dir=[\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'external_spleen_v2/mask',\n","            'external_lung_v1/mask_0.3'\n","        ],\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        split= [\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/external_spleen_v2/trainval.txt',\n","            '/content/external_lung_v1/external_lung.txt'\n","        ],\n","        pipeline=train_pipeline),\n","    val=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        img_dir='hubmap_multi_2000x2000/images_stained_with_hubmap1',\n","        ann_dir='hubmap_multi_2000x2000/lung_refined_masks_2class',\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        split='/content/hubmap_multi_2000x2000/ImageSets/Segmentation/val_fold0.txt',\n","        pipeline=test_pipeline),\n","    test=dict()\n","    )\n","\n","#-------------------------------------------------------------------------\n","# schedule\n","\n","# optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0005)\n","optimizer_config = dict()\n","# lr_config = dict(warmup='linear', warmup_iters=500, by_epoch=False, \n","#                  policy='poly', power=0.9, min_lr=0.001)\n","\n","optimizer = dict(\n","    type='AdamW',\n","    lr=0.00006,\n","    betas=(0.9, 0.999),\n","    weight_decay=0.01,\n","    paramwise_cfg=dict(\n","        custom_keys={\n","            'pos_block': dict(decay_mult=0.),\n","            'norm': dict(decay_mult=0.),\n","            'head': dict(lr_mult=10.)\n","        }))\n","\n","lr_config = dict(\n","    policy='poly',\n","    warmup='linear',\n","    warmup_iters=1500,\n","    warmup_ratio=1e-6,\n","    power=1.0,\n","    min_lr=0,\n","    by_epoch=False)\n","\n","\n","# runtime settings\n","runner = dict(type='IterBasedRunner', max_iters=45000)\n","checkpoint_config = dict(by_epoch=False, interval=45000)\n","evaluation = dict(interval=3000, metric=['mDice', 'mIoU'], pre_eval=False)\n","\n","#-------------------------------------------------------------------------\n","# runtime\n","\n","log_config = dict(\n","    interval=10,\n","    hooks=[\n","        dict(type='TextLoggerHook', by_epoch=False),\n","\n","        # dict(type='MMSegWandbHook',\n","        #         init_kwargs=dict(project=\"HubMap\",\n","        #                          name=f'segformer_mit-b5_928',\n","        #                          config={'config':'segformer_mit-b5_928.py',\n","        #                                  'comment':'No comment',\n","        #                                  'dataset_type': dataset_type,\n","        #                                  'model': model,\n","        #                                  'crop_size': crop_size,\n","        #                                  'train_pipeline': train_pipeline,\n","        #                                  'test_pipeline': test_pipeline,\n","        #                                  'optimizer':optimizer,\n","        #                                  'lr_config':lr_config,\n","        #                                  'runner': runner,\n","        #                                  'checkpoint_config': checkpoint_config,\n","        #                                  'evaluation':evaluation,\n","        #                                  'data': data,\n","        #                                  },\n","        #                          #group='',\n","        #                          entity=None),\n","        #         interval=3000,\n","        #         log_checkpoint=True,\n","        #         log_checkpoint_metadata=True,\n","        #         num_eval_images=100)\n","    ]\n","    )\n","\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = None\n","resume_from = None\n","workflow = [('train', 1)]\n","cudnn_benchmark = True\n","\n","\n","\n","#-------------------------------------------------------------------------\n","work_dir='/content/hubmap_training'\n","\n","from mmseg.apis import set_random_seed\n","set_random_seed(0, deterministic=False)\n","\n","seed = 0\n","gpu_ids = range(1)\n","device='cuda'\n","\n","EOF"],"metadata":{"id":"HFHRYMEWZuih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bash\n","\n","cat << EOF > /content/training_configs/segformer_mit-b5_960.py\n","\n","#-------------------------------------------------------------------------\n","# model settings\n","norm_cfg = dict(type='GN', num_groups=32, requires_grad=True)\n","model = dict(\n","    type='EncoderDecoder',\n","    backbone=dict(\n","        type='MixVisionTransformer',\n","        # init_cfg=dict(\n","        #     type='Pretrained',\n","        #     checkpoint='https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'\n","        #     ),\n","        in_channels=3,\n","        embed_dims=64,\n","        num_stages=4,\n","        num_layers=[3, 6, 40, 3],\n","        num_heads=[1, 2, 5, 8],\n","        patch_sizes=[7, 3, 3, 3],\n","        sr_ratios=[8, 4, 2, 1],\n","        out_indices=(0, 1, 2, 3),\n","        mlp_ratio=4,\n","        qkv_bias=True,\n","        drop_rate=0.0,\n","        attn_drop_rate=0.0,\n","        drop_path_rate=0.1),\n","    decode_head=dict(\n","        type='SegformerHead',\n","        in_channels=[64, 128, 320, 512],\n","        in_index=[0, 1, 2, 3],\n","        channels=256,\n","        dropout_ratio=0.1,\n","        num_classes=2,\n","        norm_cfg=norm_cfg,\n","        align_corners=False,\n","        loss_decode=[\n","            dict(type='CrossEntropyLoss', loss_name='loss_ce', loss_weight=1),\n","            dict(type='LovaszLoss', loss_name='loss_lovasz', per_image=True, loss_weight=3),\n","        ]\n","        ),\n","    train_cfg=dict(),\n","    test_cfg=dict(mode='whole'))\n","\n","\n","\n","#-------------------------------------------------------------------------\n","# dataset settings\n","\n","dataset_type = 'HubmapDataset'\n","data_root = '/content'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","crop_size = (960, 960)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='OrgansDataAug'),\n","    dict(type='Resize', img_scale=[(480,480),(1600, 1600)], keep_ratio=False, ratio_range=None),\n","    dict(type='RandomCrop', crop_size=crop_size, cat_max_ratio=0.5),\n","    dict(type='RandomFlip', direction='horizontal', prob=0),\n","    #dict(type='RandomRotate', degree=180, prob=0.7),\n","    dict(type='SaveOverlay', save_root_dir='/content', save_num=500, no_overlay=True),\n","    dict(type='Convert2Class1'),\n","    dict(type='Normalize', **img_norm_cfg),\n","    dict(type='Pad', size=crop_size, pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=crop_size,\n","        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n","        flip=True,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(type='Normalize', **img_norm_cfg),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img']),\n","        ])\n","]\n","\n","\n","data = dict(\n","    samples_per_gpu=1,\n","    workers_per_gpu=2,\n","    train=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        img_dir=[\n","            'hubmap_multi_2000x2000/images',\n","            'hubmap_multi_2000x2000/images_stained_with_hubmap1',\n","            'hubmap_multi_2000x2000/images_stained_with_hubmap2',\n","            'hubmap_multi_2000x2000/images_stained_with_sample1',\n","            'hubmap_multi_2000x2000/images_stained_with_test',\n","            'external_spleen_v2/image',\n","            'external_lung_v1/image'\n","        ],\n","        ann_dir=[\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'external_spleen_v2/mask',\n","            'external_lung_v1/mask_0.3'\n","        ],\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        split= [\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/external_spleen_v2/trainval.txt',\n","            '/content/external_lung_v1/external_lung.txt'\n","        ],\n","        pipeline=train_pipeline),\n","    val=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        img_dir='hubmap_multi_2000x2000/images_stained_with_hubmap1',\n","        ann_dir='hubmap_multi_2000x2000/lung_refined_masks_2class',\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        split='/content/hubmap_multi_2000x2000/ImageSets/Segmentation/val_fold0.txt',\n","        pipeline=test_pipeline),\n","    test=dict()\n","    )\n","\n","#-------------------------------------------------------------------------\n","# schedule\n","\n","# optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0005)\n","optimizer_config = dict()\n","# lr_config = dict(warmup='linear', warmup_iters=500, by_epoch=False, \n","#                  policy='poly', power=0.9, min_lr=0.001)\n","\n","optimizer = dict(\n","    type='AdamW',\n","    lr=0.00006,\n","    betas=(0.9, 0.999),\n","    weight_decay=0.01,\n","    paramwise_cfg=dict(\n","        custom_keys={\n","            'pos_block': dict(decay_mult=0.),\n","            'norm': dict(decay_mult=0.),\n","            'head': dict(lr_mult=10.)\n","        }))\n","\n","lr_config = dict(\n","    policy='poly',\n","    warmup='linear',\n","    warmup_iters=1500,\n","    warmup_ratio=1e-6,\n","    power=1.0,\n","    min_lr=0,\n","    by_epoch=False)\n","\n","\n","# runtime settings\n","runner = dict(type='IterBasedRunner', max_iters=45000)\n","checkpoint_config = dict(by_epoch=False, interval=45000)\n","evaluation = dict(interval=3000, metric=['mDice', 'mIoU'], pre_eval=False) \n","\n","#-------------------------------------------------------------------------\n","# _base_/default_runtime.py\n","\n","log_config = dict(\n","    interval=10,\n","    hooks=[\n","        dict(type='TextLoggerHook', by_epoch=False),\n","\n","        # dict(type='MMSegWandbHook',\n","        #         init_kwargs=dict(project=\"HubMap\",\n","        #                          name=f'segformer_mit-b5_960',\n","        #                          config={'config':'segformer_mit-b5_960.py',\n","        #                                  'comment':'No comment',\n","        #                                  'dataset_type': dataset_type,\n","        #                                  'model': model,\n","        #                                  'crop_size': crop_size,\n","        #                                  'train_pipeline': train_pipeline,\n","        #                                  'test_pipeline': test_pipeline,\n","        #                                  'optimizer':optimizer,\n","        #                                  'lr_config':lr_config,\n","        #                                  'runner': runner,\n","        #                                  'checkpoint_config': checkpoint_config,\n","        #                                  'evaluation':evaluation,\n","        #                                  'data': data,\n","        #                                  },\n","        #                          #group='',\n","        #                          entity=None),\n","        #         interval=3000,\n","        #         log_checkpoint=True,\n","        #         log_checkpoint_metadata=True,\n","        #         num_eval_images=100)\n","    ]\n","    )\n","\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_8x1_1024x1024_160k_cityscapes/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth'\n","resume_from = None\n","workflow = [('train', 1)]\n","cudnn_benchmark = True\n","\n","\n","\n","#-------------------------------------------------------------------------\n","work_dir='/content/hubmap_training'\n","\n","from mmseg.apis import set_random_seed\n","set_random_seed(0, deterministic=False)\n","\n","seed = 0\n","gpu_ids = range(1)\n","device='cuda'\n","\n","EOF"],"metadata":{"id":"cOKqLbE9Z2wm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bash\n","\n","cat << EOF > /content/training_configs/segformer_mit-b5_960_2.py\n","\n","#-------------------------------------------------------------------------\n","# model settings\n","norm_cfg = dict(type='GN', num_groups=32, requires_grad=True)\n","model = dict(\n","    type='EncoderDecoder',\n","    backbone=dict(\n","        type='MixVisionTransformer',\n","        # init_cfg=dict(\n","        #     type='Pretrained',\n","        #     checkpoint='https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'\n","        #     ),\n","        in_channels=3,\n","        embed_dims=64,\n","        num_stages=4,\n","        num_layers=[3, 6, 40, 3],\n","        num_heads=[1, 2, 5, 8],\n","        patch_sizes=[7, 3, 3, 3],\n","        sr_ratios=[8, 4, 2, 1],\n","        out_indices=(0, 1, 2, 3),\n","        mlp_ratio=4,\n","        qkv_bias=True,\n","        drop_rate=0.0,\n","        attn_drop_rate=0.0,\n","        drop_path_rate=0.1),\n","    decode_head=dict(\n","        type='SegformerHead',\n","        in_channels=[64, 128, 320, 512],\n","        in_index=[0, 1, 2, 3],\n","        channels=256,\n","        dropout_ratio=0.1,\n","        num_classes=2,\n","        norm_cfg=norm_cfg,\n","        align_corners=False,\n","        loss_decode=[\n","            dict(type='CrossEntropyLoss', loss_name='loss_ce', loss_weight=1),\n","            dict(type='LovaszLoss', loss_name='loss_lovasz', per_image=True, loss_weight=3),\n","        ]\n","        ),\n","    train_cfg=dict(),\n","    test_cfg=dict(mode='whole'))\n","\n","\n","\n","#-------------------------------------------------------------------------\n","# dataset settings\n","\n","dataset_type = 'HubmapDataset'\n","data_root = '/content'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","crop_size = (960, 960)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='OrgansDataAug'),\n","    dict(type='Resize', img_scale=[(450,450),(1650, 1650)], keep_ratio=False, ratio_range=None),\n","    dict(type='RandomCrop', crop_size=crop_size, cat_max_ratio=0.5), \n","    dict(type='RandomFlip', direction='horizontal', prob=0),\n","    #dict(type='RandomRotate', degree=180, prob=0.7),\n","    dict(type='SaveOverlay', save_root_dir='/content', save_num=500, no_overlay=True),\n","    dict(type='Convert2Class1'),\n","    dict(type='Normalize', **img_norm_cfg),\n","    dict(type='Pad', size=crop_size, pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=crop_size,\n","        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n","        flip=True,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(type='Normalize', **img_norm_cfg),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img']),\n","        ])\n","]\n","\n","\n","data = dict(\n","    samples_per_gpu=1,\n","    workers_per_gpu=2,\n","    train=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        img_dir=[\n","            'hubmap_multi_2000x2000/images',\n","            'hubmap_multi_2000x2000/images_stained_with_hubmap1',\n","            'hubmap_multi_2000x2000/images_stained_with_hubmap2',\n","            'hubmap_multi_2000x2000/images_stained_with_sample1',\n","            'hubmap_multi_2000x2000/images_stained_with_test',\n","            'external_spleen_v2/image',\n","            'external_lung_v1/image'\n","        ],\n","        ann_dir=[\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'external_spleen_v2/mask',\n","            'external_lung_v1/mask_0.3'\n","        ],\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        split= [\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/external_spleen_v2/trainval.txt',\n","            '/content/external_lung_v1/external_lung.txt'\n","        ],\n","        pipeline=train_pipeline),\n","    val=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        img_dir='hubmap_multi_2000x2000/images_stained_with_hubmap1',\n","        ann_dir='hubmap_multi_2000x2000/lung_refined_masks_2class',\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        split='/content/hubmap_multi_2000x2000/ImageSets/Segmentation/val_fold0.txt',\n","        pipeline=test_pipeline),\n","    test=dict()\n","    )\n","\n","#-------------------------------------------------------------------------\n","# schedule\n","\n","# optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0005)\n","optimizer_config = dict()\n","# lr_config = dict(warmup='linear', warmup_iters=500, by_epoch=False, \n","#                  policy='poly', power=0.9, min_lr=0.001)\n","\n","optimizer = dict(\n","    type='AdamW',\n","    lr=0.00006,\n","    betas=(0.9, 0.999),\n","    weight_decay=0.01,\n","    paramwise_cfg=dict(\n","        custom_keys={\n","            'pos_block': dict(decay_mult=0.),\n","            'norm': dict(decay_mult=0.),\n","            'head': dict(lr_mult=10.)\n","        }))\n","\n","lr_config = dict(\n","    policy='poly',\n","    warmup='linear',\n","    warmup_iters=1500,\n","    warmup_ratio=1e-6,\n","    power=1.0,\n","    min_lr=0,\n","    by_epoch=False)\n","\n","\n","runner = dict(type='IterBasedRunner', max_iters=45000)\n","checkpoint_config = dict(by_epoch=False, interval=45000)\n","evaluation = dict(interval=3000, metric=['mDice', 'mIoU'], pre_eval=False)\n","\n","#-------------------------------------------------------------------------\n","# runtime\n","\n","log_config = dict(\n","    interval=10,\n","    hooks=[\n","        dict(type='TextLoggerHook', by_epoch=False),\n","\n","        # dict(type='MMSegWandbHook',\n","        #         init_kwargs=dict(project=\"HubMap\",\n","        #                          name=f'segformer_mit-b5_960_2',\n","        #                          config={'config':'segformer_mit-b5_960_2.py',\n","        #                                  'comment':'No comment',\n","        #                                  'dataset_type': dataset_type,\n","        #                                  'model': model,\n","        #                                  'crop_size': crop_size,\n","        #                                  'train_pipeline': train_pipeline,\n","        #                                  'test_pipeline': test_pipeline,\n","        #                                  'optimizer':optimizer,\n","        #                                  'lr_config':lr_config,\n","        #                                  'runner': runner,\n","        #                                  'checkpoint_config': checkpoint_config,\n","        #                                  'evaluation':evaluation,\n","        #                                  'data': data,\n","        #                                  },\n","        #                          #group='',\n","        #                          entity=None),\n","        #         interval=3000,\n","        #         log_checkpoint=True,\n","        #         log_checkpoint_metadata=True,\n","        #         num_eval_images=100)\n","    ]\n","    )\n","\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_8x1_1024x1024_160k_cityscapes/segformer_mit-b5_8x1_1024x1024_160k_cityscapes_20211206_072934-87a052ec.pth'\n","resume_from = None\n","workflow = [('train', 1)]\n","cudnn_benchmark = True\n","\n","\n","#-------------------------------------------------------------------------\n","work_dir='/content/hubmap_training'\n","\n","from mmseg.apis import set_random_seed\n","set_random_seed(0, deterministic=False)\n","\n","seed = 2022\n","gpu_ids = range(1)\n","device='cuda'\n","\n","EOF"],"metadata":{"id":"7rWi-6Q7aIb8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","In the above training configs:\n","\n","cat << EOF > /content/training_configs/segformer_mit-b5_960_2.py\n","...\n","EOF\n","--> Shell script that create the file which contains \"...\"\n","\n","norm_cfg = dict(type='GN', num_groups=32, requires_grad=True)\n","--> Use Group Normalization instead of batch normalization.\n","\n","\n","type='MixVisionTransformer',\n","init_cfg=dict(\n","    type='Pretrained',\n","    checkpoint='https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'\n","    ),\n","    ...\n","--> Use pretrained encorder \"mit-b5\" (not whole segformer)\n","\n","decode_head=dict(\n","    type='SegformerHead',\n","    in_channels=[64, 128, 320, 512],\n","    in_index=[0, 1, 2, 3],\n","    channels=256,\n","    dropout_ratio=0.1,\n","    num_classes=2,\n","    ...\n","--> num_classes=2 (background and cells)\n","\n","dict(type='CrossEntropyLoss', loss_name='loss_ce', loss_weight=1),\n","dict(type='LovaszLoss', loss_name='loss_lovasz', per_image=True, loss_weight=3),\n","--> I used cross entropy: lovasz loss=1:3\n","\n","dataset_type = 'HubmapDataset'\n","--> use settings of mmsegmentation/mmseg/datasets/hubmap.py (customized)\n","\n","dict(type='OrgansDataAug')\n","--> use piplie of mmsegmentation/mmseg/datasets/pipelines/my_pipeline.py (customized)\n","    Since masks are 6 classes, use different method among cell types.\n","\n","dict(type='Resize', img_scale=[(450,450),(1650, 1650)], keep_ratio=False, ratio_range=None),\n","--> such as (480, 1600), (1024,1024), (1500,480)\n","\n","dict(type='SaveOverlay', save_root_dir='/content', save_num=500, no_overlay=True),\n","--> save overlays for visuzalition. show only transformed images if no_overlay=True\n","    \n","dict(type='Convert2Class1')\n","--> convert 6 class mask into 2 class mask.\n","\n","samples_per_gpu=1\n","--> trained with batch_num=1\n","\n","# dict(type='MMSegWandbHook',\n","#         init_kwargs=dict(project=\"HubMap\",\n","...\n","--> you can uncomment here to use wandb.\n","\n","\n","load_from = 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_8x1_1024x1024_160k_cityscapes/...'\n","--> use pretrained whole segformer\n","\n","\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S_QCcDSt7pY0","executionInfo":{"status":"ok","timestamp":1665290241430,"user_tz":-540,"elapsed":464,"user":{"displayName":"vov nanda","userId":"09231748423501225228"}},"outputId":"e43d8420-b4e9-426e-9a40-830887d66dbd"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"code","source":["\"\"\"\n","About customized MMSegmentation:\n","\n","mmsegmentation/mmseg/datasets/pipelines/my_pipeline.py\n","--> data augmentation settings such as 'OrgandDataAug' 'SaveOverlay'.\n","\n","mmsegmentation/mmseg/models/segmentors/encoder_decoder.py\n","--> added config settings for raw sigmoid output (default: Argmax of softmax outputs)\n","\n","mmsegmentation/mmseg/datasets/pipelines/transforms.py\n","--> added for backend control (not used here)\n","\n","mmsegmentation/mmseg/apis/test.py\n","--> change segmentation output from int64 to uint8 to save memory. (may not needed now)\n","    you have to change here if you use more than 256 classes.\n","\n","mmsegmentation/mmseg/datasets/hubmap.py\n","--> hubmap dataset settings. \n","\n","mmsegmentation/mmseg/mylib/seg_utils.py\n","--> segmentation utils used for my_pipeline.py\n","\n","\"\"\""],"metadata":{"id":"L-R5SZne9jbj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QWuH14LYF2gQ"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cl3fzvmidhdp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"735a804e-966f-48e1-d6a3-9a5f58f51a92"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/mmsegmentation\n","rm: cannot remove '/content/overlay': No such file or directory\n","2022-10-08 12:31:20,511 - mmseg - INFO - Multi-processing start method is `None`\n","2022-10-08 12:31:20,520 - mmseg - INFO - OpenCV num_threads is `12\n","2022-10-08 12:31:20,609 - mmseg - INFO - Environment info:\n","------------------------------------------------------------\n","sys.platform: linux\n","Python: 3.7.14 (default, Sep  8 2022, 00:06:44) [GCC 7.5.0]\n","CUDA available: True\n","GPU 0: A100-SXM4-40GB\n","CUDA_HOME: /usr/local/cuda\n","NVCC: Cuda compilation tools, release 11.2, V11.2.152\n","GCC: x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","PyTorch: 1.10.0+cu111\n","PyTorch compiling details: PyTorch built with:\n","  - GCC 7.3\n","  - C++ Version: 201402\n","  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n","  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n","  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n","  - LAPACK is enabled (usually provided by MKL)\n","  - NNPACK is enabled\n","  - CPU capability usage: AVX512\n","  - CUDA Runtime 11.1\n","  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n","  - CuDNN 8.0.5\n","  - Magma 2.5.2\n","  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n","\n","TorchVision: 0.11.0+cu111\n","OpenCV: 4.6.0\n","MMCV: 1.6.0\n","MMCV Compiler: GCC 7.3\n","MMCV CUDA Compiler: 11.1\n","MMSegmentation: 0.28.0+3fb9c77\n","------------------------------------------------------------\n","\n","2022-10-08 12:31:20,609 - mmseg - INFO - Distributed training: False\n","2022-10-08 12:31:21,749 - mmseg - INFO - Config:\n","norm_cfg = dict(type='GN', num_groups=32, requires_grad=True)\n","model = dict(\n","    type='EncoderDecoder',\n","    pretrained=\n","    'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b4_20220624-d588d980.pth',\n","    backbone=dict(\n","        type='MixVisionTransformer',\n","        in_channels=3,\n","        embed_dims=64,\n","        num_stages=4,\n","        num_layers=[3, 8, 27, 3],\n","        num_heads=[1, 2, 5, 8],\n","        patch_sizes=[7, 3, 3, 3],\n","        sr_ratios=[8, 4, 2, 1],\n","        out_indices=(0, 1, 2, 3),\n","        mlp_ratio=4,\n","        qkv_bias=True,\n","        drop_rate=0.0,\n","        attn_drop_rate=0.0,\n","        drop_path_rate=0.1),\n","    decode_head=dict(\n","        type='SegformerHead',\n","        in_channels=[64, 128, 320, 512],\n","        in_index=[0, 1, 2, 3],\n","        channels=256,\n","        dropout_ratio=0.1,\n","        num_classes=2,\n","        norm_cfg=dict(type='GN', num_groups=32, requires_grad=True),\n","        align_corners=False,\n","        loss_decode=[\n","            dict(type='CrossEntropyLoss', loss_name='loss_ce', loss_weight=1),\n","            dict(\n","                type='LovaszLoss',\n","                loss_name='loss_lovasz',\n","                per_image=True,\n","                loss_weight=3)\n","        ]),\n","    train_cfg=dict(),\n","    test_cfg=dict(mode='whole'))\n","dataset_type = 'HubmapDataset'\n","data_root = '/content'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","crop_size = (960, 960)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='OrgansDataAug'),\n","    dict(\n","        type='Resize',\n","        img_scale=[(480, 480), (1600, 1600)],\n","        keep_ratio=False,\n","        ratio_range=None),\n","    dict(type='RandomCrop', crop_size=(960, 960), cat_max_ratio=0.5),\n","    dict(type='RandomFlip', direction='horizontal', prob=0),\n","    dict(\n","        type='SaveOverlay',\n","        save_root_dir='/content',\n","        save_num=500,\n","        no_overlay=True),\n","    dict(type='Convert2Class1'),\n","    dict(\n","        type='Normalize',\n","        mean=[123.675, 116.28, 103.53],\n","        std=[58.395, 57.12, 57.375],\n","        to_rgb=True),\n","    dict(type='Pad', size=(960, 960), pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(960, 960),\n","        flip=True,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img'])\n","        ])\n","]\n","data = dict(\n","    samples_per_gpu=1,\n","    workers_per_gpu=2,\n","    train=dict(\n","        type='HubmapDataset',\n","        data_root='/content',\n","        img_dir=[\n","            'hubmap_multi_2000x2000/images',\n","            'hubmap_multi_2000x2000/images_stained_with_hubmap1',\n","            'hubmap_multi_2000x2000/images_stained_with_hubmap2',\n","            'hubmap_multi_2000x2000/images_stained_with_sample1',\n","            'hubmap_multi_2000x2000/images_stained_with_test',\n","            'external_spleen_v2/image', 'external_lung_v1/image'\n","        ],\n","        ann_dir=[\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'hubmap_multi_2000x2000/lung_refined_masks',\n","            'external_spleen_v2/mask', 'external_lung_v1/mask_0.3'\n","        ],\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        split=[\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/trainval.txt',\n","            '/content/external_spleen_v2/trainval.txt',\n","            '/content/external_lung_v1/external_lung.txt'\n","        ],\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations'),\n","            dict(type='OrgansDataAug'),\n","            dict(\n","                type='Resize',\n","                img_scale=[(480, 480), (1600, 1600)],\n","                keep_ratio=False,\n","                ratio_range=None),\n","            dict(type='RandomCrop', crop_size=(960, 960), cat_max_ratio=0.5),\n","            dict(type='RandomFlip', direction='horizontal', prob=0),\n","            dict(\n","                type='SaveOverlay',\n","                save_root_dir='/content',\n","                save_num=500,\n","                no_overlay=True),\n","            dict(type='Convert2Class1'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='Pad', size=(960, 960), pad_val=0, seg_pad_val=255),\n","            dict(type='DefaultFormatBundle'),\n","            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n","        ]),\n","    val=dict(\n","        type='HubmapDataset',\n","        data_root='/content',\n","        img_dir='hubmap_multi_2000x2000/images_stained_with_hubmap1',\n","        ann_dir='hubmap_multi_2000x2000/lung_refined_masks_2class',\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        split=\n","        '/content/hubmap_multi_2000x2000/ImageSets/Segmentation/val_fold0.txt',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(960, 960),\n","                flip=True,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ]),\n","    test=dict())\n","optimizer_config = dict()\n","optimizer = dict(\n","    type='AdamW',\n","    lr=6e-05,\n","    betas=(0.9, 0.999),\n","    weight_decay=0.01,\n","    paramwise_cfg=dict(\n","        custom_keys=dict(\n","            pos_block=dict(decay_mult=0.0),\n","            norm=dict(decay_mult=0.0),\n","            head=dict(lr_mult=10.0))))\n","lr_config = dict(\n","    policy='poly',\n","    warmup='linear',\n","    warmup_iters=1500,\n","    warmup_ratio=1e-06,\n","    power=1.0,\n","    min_lr=0,\n","    by_epoch=False)\n","runner = dict(type='IterBasedRunner', max_iters=45000)\n","checkpoint_config = dict(by_epoch=False, interval=45000)\n","evaluation = dict(interval=3000, metric=['mDice', 'mIoU'], pre_eval=False)\n","log_config = dict(\n","    interval=10, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = None\n","resume_from = None\n","workflow = [('train', 1)]\n","cudnn_benchmark = True\n","work_dir = '/content/hubmap_training'\n","seed = 0\n","gpu_ids = [0]\n","device = 'cuda'\n","auto_resume = False\n","\n","2022-10-08 12:31:21,751 - mmseg - INFO - Set random seed to 209652396, deterministic: False\n","/content/mmsegmentation/mmseg/models/backbones/mit.py:365: UserWarning: DeprecationWarning: pretrained is deprecated, please use \"init_cfg\" instead\n","  warnings.warn('DeprecationWarning: pretrained is deprecated, '\n","/content/mmsegmentation/mmseg/models/decode_heads/decode_head.py:94: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert seg_logist into a predictionapplying a threshold\n","  warnings.warn('For binary segmentation, we suggest using'\n","/content/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:236: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n","  'Default ``avg_non_ignore`` is False, if you would like to '\n","2022-10-08 12:31:22,431 - mmseg - INFO - initialize MixVisionTransformer with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b4_20220624-d588d980.pth'}\n","2022-10-08 12:31:22,431 - mmcv - INFO - load model from: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b4_20220624-d588d980.pth\n","2022-10-08 12:31:22,432 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b4_20220624-d588d980.pth\n","Downloading: \"https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b4_20220624-d588d980.pth\" to /root/.cache/torch/hub/checkpoints/mit_b4_20220624-d588d980.pth\n","100% 232M/232M [00:25<00:00, 9.50MB/s]\n","2022-10-08 12:31:49,121 - mmseg - INFO - initialize SegformerHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n","tools/train.py:207: UserWarning: SyncBN is only supported with DDP. To be compatible with DP, we convert SyncBN to BN. Please use dist_train.sh which can avoid this error.\n","  'SyncBN is only supported with DDP. To be compatible with DP, '\n","2022-10-08 12:31:49,136 - mmseg - INFO - EncoderDecoder(\n","  (backbone): MixVisionTransformer(\n","    (layers): ModuleList(\n","      (0): ModuleList(\n","        (0): PatchEmbed(\n","          (projection): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n","          (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","        )\n","        (1): ModuleList(\n","          (0): TransformerEncoderLayer(\n","            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n","              (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (1): TransformerEncoderLayer(\n","            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n","              (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (2): TransformerEncoderLayer(\n","            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n","              (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","        )\n","        (2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","      )\n","      (1): ModuleList(\n","        (0): PatchEmbed(\n","          (projection): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","        )\n","        (1): ModuleList(\n","          (0): TransformerEncoderLayer(\n","            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (1): TransformerEncoderLayer(\n","            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (2): TransformerEncoderLayer(\n","            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (3): TransformerEncoderLayer(\n","            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (4): TransformerEncoderLayer(\n","            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (5): TransformerEncoderLayer(\n","            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (6): TransformerEncoderLayer(\n","            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (7): TransformerEncoderLayer(\n","            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","        )\n","        (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","      )\n","      (2): ModuleList(\n","        (0): PatchEmbed(\n","          (projection): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","          (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","        )\n","        (1): ModuleList(\n","          (0): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (1): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (2): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (3): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (4): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (5): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (6): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (7): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (8): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (9): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (10): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (11): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (12): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (13): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (14): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (15): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (16): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (17): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (18): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (19): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (20): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (21): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (22): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (23): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (24): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (25): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (26): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","        )\n","        (2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","      )\n","      (3): ModuleList(\n","        (0): PatchEmbed(\n","          (projection): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        )\n","        (1): ModuleList(\n","          (0): TransformerEncoderLayer(\n","            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","            )\n","            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (1): TransformerEncoderLayer(\n","            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","            )\n","            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (2): TransformerEncoderLayer(\n","            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","            )\n","            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU()\n","              (layers): Sequential(\n","                (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n","                (2): GELU()\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","        )\n","        (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b4_20220624-d588d980.pth'}\n","  (decode_head): SegformerHead(\n","    input_transform=multiple_select, ignore_index=255, align_corners=False\n","    (loss_decode): ModuleList(\n","      (0): CrossEntropyLoss(avg_non_ignore=False)\n","      (1): LovaszLoss()\n","    )\n","    (conv_seg): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n","    (dropout): Dropout2d(p=0.1, inplace=False)\n","    (convs): ModuleList(\n","      (0): ConvModule(\n","        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","      (1): ConvModule(\n","        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","      (2): ConvModule(\n","        (conv): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","      (3): ConvModule(\n","        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","    )\n","    (fusion_conv): ConvModule(\n","      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (gn): GroupNorm(32, 256, eps=1e-05, affine=True)\n","      (activate): ReLU(inplace=True)\n","    )\n","  )\n","  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",")\n","/usr/local/lib/python3.7/dist-packages/albumentations/augmentations/transforms.py:1615: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n","  FutureWarning,\n","[OrgansDataAug] organ:kidney transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(50.0, 300.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:largeintestine transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(50.0, 300.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:lung transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:prostate transforms:[Downscale(always_apply=False, p=0.9, scale_min=0.08, scale_max=0.4, interpolation=1), Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:spleen transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","2022-10-08 12:31:49,235 - mmseg - INFO - Loaded 351 images\n","[OrgansDataAug] organ:kidney transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(50.0, 300.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:largeintestine transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(50.0, 300.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:lung transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:prostate transforms:[Downscale(always_apply=False, p=0.9, scale_min=0.08, scale_max=0.4, interpolation=1), Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:spleen transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","2022-10-08 12:31:49,237 - mmseg - INFO - Loaded 351 images\n","[OrgansDataAug] organ:kidney transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(50.0, 300.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:largeintestine transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(50.0, 300.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:lung transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:prostate transforms:[Downscale(always_apply=False, p=0.9, scale_min=0.08, scale_max=0.4, interpolation=1), Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:spleen transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","2022-10-08 12:31:49,239 - mmseg - INFO - Loaded 351 images\n","[OrgansDataAug] organ:kidney transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(50.0, 300.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:largeintestine transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(50.0, 300.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:lung transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:prostate transforms:[Downscale(always_apply=False, p=0.9, scale_min=0.08, scale_max=0.4, interpolation=1), Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:spleen transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","2022-10-08 12:31:49,329 - mmseg - INFO - Loaded 351 images\n","[OrgansDataAug] organ:kidney transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(50.0, 300.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:largeintestine transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(50.0, 300.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:lung transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:prostate transforms:[Downscale(always_apply=False, p=0.9, scale_min=0.08, scale_max=0.4, interpolation=1), Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:spleen transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","2022-10-08 12:31:49,331 - mmseg - INFO - Loaded 351 images\n","[OrgansDataAug] organ:kidney transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(50.0, 300.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:largeintestine transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(50.0, 300.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:lung transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:prostate transforms:[Downscale(always_apply=False, p=0.9, scale_min=0.08, scale_max=0.4, interpolation=1), Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:spleen transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","2022-10-08 12:31:49,333 - mmseg - INFO - Loaded 195 images\n","[OrgansDataAug] organ:kidney transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(50.0, 300.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:largeintestine transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(50.0, 300.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:lung transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:prostate transforms:[Downscale(always_apply=False, p=0.9, scale_min=0.08, scale_max=0.4, interpolation=1), Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","[OrgansDataAug] organ:spleen transforms:[Crop(always_apply=False, p=0.7, x_min=100, y_min=100, x_max=1900, y_max=1900), Flip(always_apply=False, p=1), RandomRotate90(always_apply=False, p=1), HueSaturationValue(always_apply=False, p=1, hue_shift_limit=(-20, 20), sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)), RandomGamma(always_apply=False, p=1, gamma_limit=(25.0, 250.0), eps=None), RandomBrightness(always_apply=False, p=1, limit=(-0.2, 0.1))]\n","2022-10-08 12:31:49,334 - mmseg - INFO - Loaded 73 images\n","2022-10-08 12:32:03,301 - mmseg - INFO - Loaded 71 images\n","2022-10-08 12:32:03,302 - mmseg - INFO - Start running, host: root@4e85216ef6cd, work_dir: /content/hubmap_training\n","2022-10-08 12:32:03,302 - mmseg - INFO - Hooks will be executed in the following order:\n","before_run:\n","(VERY_HIGH   ) PolyLrUpdaterHook                  \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_epoch:\n","(VERY_HIGH   ) PolyLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_iter:\n","(VERY_HIGH   ) PolyLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n"," -------------------- \n","after_train_iter:\n","(ABOVE_NORMAL) OptimizerHook                      \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_train_epoch:\n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_epoch:\n","(LOW         ) IterTimerHook                      \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_epoch:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_run:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","2022-10-08 12:32:03,302 - mmseg - INFO - workflow: [('train', 1)], max: 45000 iters\n","2022-10-08 12:32:03,303 - mmseg - INFO - Checkpoints will be saved to /content/hubmap_training by HardDiskBackend.\n","2022-10-08 12:32:10,192 - mmseg - INFO - Iter [10/45000]\tlr: 3.600e-07, eta: 8:27:32, time: 0.677, data_time: 0.065, memory: 24005, decode.loss_ce: 0.5398, decode.loss_lovasz: 1.5393, decode.acc_seg: 73.4212, loss: 2.0792\n","2022-10-08 12:32:13,399 - mmseg - INFO - Iter [20/45000]\tlr: 7.597e-07, eta: 6:13:56, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.5678, decode.loss_lovasz: 1.5281, decode.acc_seg: 68.8518, loss: 2.0959\n","2022-10-08 12:32:16,594 - mmseg - INFO - Iter [30/45000]\tlr: 1.159e-06, eta: 5:29:02, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.5147, decode.loss_lovasz: 1.5375, decode.acc_seg: 72.3454, loss: 2.0522\n","2022-10-08 12:32:19,808 - mmseg - INFO - Iter [40/45000]\tlr: 1.559e-06, eta: 5:06:55, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.5133, decode.loss_lovasz: 1.5221, decode.acc_seg: 83.2908, loss: 2.0353\n","2022-10-08 12:32:23,007 - mmseg - INFO - Iter [50/45000]\tlr: 1.958e-06, eta: 4:53:25, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.5340, decode.loss_lovasz: 1.5394, decode.acc_seg: 74.3569, loss: 2.0734\n","2022-10-08 12:32:26,224 - mmseg - INFO - Iter [60/45000]\tlr: 2.357e-06, eta: 4:44:37, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.5169, decode.loss_lovasz: 1.5333, decode.acc_seg: 76.1116, loss: 2.0502\n","2022-10-08 12:32:29,489 - mmseg - INFO - Iter [70/45000]\tlr: 2.756e-06, eta: 4:38:50, time: 0.327, data_time: 0.007, memory: 24005, decode.loss_ce: 0.5281, decode.loss_lovasz: 1.5184, decode.acc_seg: 83.7936, loss: 2.0466\n","2022-10-08 12:32:32,711 - mmseg - INFO - Iter [80/45000]\tlr: 3.155e-06, eta: 4:34:05, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.4963, decode.loss_lovasz: 1.4999, decode.acc_seg: 87.1582, loss: 1.9962\n","2022-10-08 12:32:35,914 - mmseg - INFO - Iter [90/45000]\tlr: 3.553e-06, eta: 4:30:12, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.4714, decode.loss_lovasz: 1.5181, decode.acc_seg: 87.6617, loss: 1.9896\n","2022-10-08 12:32:39,103 - mmseg - INFO - Iter [100/45000]\tlr: 3.951e-06, eta: 4:26:59, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.3796, decode.loss_lovasz: 1.5060, decode.acc_seg: 86.0979, loss: 1.8856\n","2022-10-08 12:32:42,337 - mmseg - INFO - Iter [110/45000]\tlr: 4.349e-06, eta: 4:24:39, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.5031, decode.loss_lovasz: 1.5098, decode.acc_seg: 81.4495, loss: 2.0129\n","2022-10-08 12:32:45,550 - mmseg - INFO - Iter [120/45000]\tlr: 4.747e-06, eta: 4:22:35, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.4861, decode.loss_lovasz: 1.4626, decode.acc_seg: 86.2522, loss: 1.9488\n","2022-10-08 12:32:48,771 - mmseg - INFO - Iter [130/45000]\tlr: 5.145e-06, eta: 4:20:51, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.4135, decode.loss_lovasz: 1.4596, decode.acc_seg: 82.6660, loss: 1.8731\n","2022-10-08 12:32:51,975 - mmseg - INFO - Iter [140/45000]\tlr: 5.543e-06, eta: 4:19:17, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.4814, decode.loss_lovasz: 1.4621, decode.acc_seg: 86.1493, loss: 1.9435\n","2022-10-08 12:32:55,194 - mmseg - INFO - Iter [150/45000]\tlr: 5.940e-06, eta: 4:17:59, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.4394, decode.loss_lovasz: 1.4427, decode.acc_seg: 87.5687, loss: 1.8821\n","2022-10-08 12:32:58,413 - mmseg - INFO - Iter [160/45000]\tlr: 6.338e-06, eta: 4:16:50, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.4760, decode.loss_lovasz: 1.4876, decode.acc_seg: 82.2499, loss: 1.9636\n","2022-10-08 12:33:01,632 - mmseg - INFO - Iter [170/45000]\tlr: 6.735e-06, eta: 4:15:49, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.4191, decode.loss_lovasz: 1.3876, decode.acc_seg: 87.7230, loss: 1.8067\n","2022-10-08 12:33:04,893 - mmseg - INFO - Iter [180/45000]\tlr: 7.132e-06, eta: 4:15:05, time: 0.326, data_time: 0.006, memory: 24005, decode.loss_ce: 0.3302, decode.loss_lovasz: 1.3735, decode.acc_seg: 86.9371, loss: 1.7038\n","2022-10-08 12:33:08,121 - mmseg - INFO - Iter [190/45000]\tlr: 7.528e-06, eta: 4:14:18, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.3433, decode.loss_lovasz: 1.3535, decode.acc_seg: 84.5679, loss: 1.6969\n","2022-10-08 12:33:11,326 - mmseg - INFO - Iter [200/45000]\tlr: 7.925e-06, eta: 4:13:29, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.3162, decode.loss_lovasz: 1.3503, decode.acc_seg: 89.4411, loss: 1.6664\n","2022-10-08 12:33:14,527 - mmseg - INFO - Iter [210/45000]\tlr: 8.321e-06, eta: 4:12:45, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.3252, decode.loss_lovasz: 1.3385, decode.acc_seg: 87.3525, loss: 1.6637\n","2022-10-08 12:33:17,728 - mmseg - INFO - Iter [220/45000]\tlr: 8.717e-06, eta: 4:12:04, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.3591, decode.loss_lovasz: 1.4537, decode.acc_seg: 83.6388, loss: 1.8128\n","2022-10-08 12:33:20,933 - mmseg - INFO - Iter [230/45000]\tlr: 9.113e-06, eta: 4:11:27, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.2262, decode.loss_lovasz: 1.2439, decode.acc_seg: 88.9876, loss: 1.4702\n","2022-10-08 12:33:24,157 - mmseg - INFO - Iter [240/45000]\tlr: 9.509e-06, eta: 4:10:56, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.2891, decode.loss_lovasz: 1.2470, decode.acc_seg: 87.7960, loss: 1.5360\n","2022-10-08 12:33:27,377 - mmseg - INFO - Iter [250/45000]\tlr: 9.905e-06, eta: 4:10:27, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2379, decode.loss_lovasz: 1.2875, decode.acc_seg: 86.7594, loss: 1.5254\n","2022-10-08 12:33:30,605 - mmseg - INFO - Iter [260/45000]\tlr: 1.030e-05, eta: 4:10:01, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2999, decode.loss_lovasz: 1.2905, decode.acc_seg: 82.9362, loss: 1.5903\n","2022-10-08 12:33:33,801 - mmseg - INFO - Iter [270/45000]\tlr: 1.070e-05, eta: 4:09:32, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2735, decode.loss_lovasz: 1.2448, decode.acc_seg: 87.0785, loss: 1.5183\n","2022-10-08 12:33:37,029 - mmseg - INFO - Iter [280/45000]\tlr: 1.109e-05, eta: 4:09:09, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2468, decode.loss_lovasz: 1.2728, decode.acc_seg: 88.6776, loss: 1.5196\n","2022-10-08 12:33:40,259 - mmseg - INFO - Iter [290/45000]\tlr: 1.149e-05, eta: 4:08:49, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.3312, decode.loss_lovasz: 1.1825, decode.acc_seg: 84.9215, loss: 1.5137\n","2022-10-08 12:33:43,473 - mmseg - INFO - Iter [300/45000]\tlr: 1.188e-05, eta: 4:08:27, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2998, decode.loss_lovasz: 1.2397, decode.acc_seg: 83.8714, loss: 1.5395\n","2022-10-08 12:33:46,702 - mmseg - INFO - Iter [310/45000]\tlr: 1.228e-05, eta: 4:08:08, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2040, decode.loss_lovasz: 1.1784, decode.acc_seg: 87.3133, loss: 1.3824\n","2022-10-08 12:33:49,903 - mmseg - INFO - Iter [320/45000]\tlr: 1.267e-05, eta: 4:07:46, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.2190, decode.loss_lovasz: 1.0625, decode.acc_seg: 87.6205, loss: 1.2814\n","2022-10-08 12:33:53,109 - mmseg - INFO - Iter [330/45000]\tlr: 1.306e-05, eta: 4:07:27, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.3059, decode.loss_lovasz: 1.2371, decode.acc_seg: 88.0501, loss: 1.5430\n","2022-10-08 12:33:56,334 - mmseg - INFO - Iter [340/45000]\tlr: 1.346e-05, eta: 4:07:10, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2204, decode.loss_lovasz: 1.1204, decode.acc_seg: 88.2249, loss: 1.3408\n","2022-10-08 12:33:59,560 - mmseg - INFO - Iter [350/45000]\tlr: 1.385e-05, eta: 4:06:55, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1828, decode.loss_lovasz: 0.9561, decode.acc_seg: 90.5958, loss: 1.1389\n","2022-10-08 12:34:02,796 - mmseg - INFO - Iter [360/45000]\tlr: 1.425e-05, eta: 4:06:41, time: 0.324, data_time: 0.007, memory: 24005, decode.loss_ce: 0.2296, decode.loss_lovasz: 1.1734, decode.acc_seg: 86.2360, loss: 1.4030\n","2022-10-08 12:34:06,026 - mmseg - INFO - Iter [370/45000]\tlr: 1.464e-05, eta: 4:06:28, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2047, decode.loss_lovasz: 1.0319, decode.acc_seg: 90.1758, loss: 1.2365\n","2022-10-08 12:34:09,224 - mmseg - INFO - Iter [380/45000]\tlr: 1.503e-05, eta: 4:06:11, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1567, decode.loss_lovasz: 0.9125, decode.acc_seg: 92.0526, loss: 1.0693\n","2022-10-08 12:34:12,421 - mmseg - INFO - Iter [390/45000]\tlr: 1.543e-05, eta: 4:05:55, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1773, decode.loss_lovasz: 1.0482, decode.acc_seg: 89.2326, loss: 1.2255\n","2022-10-08 12:34:15,623 - mmseg - INFO - Iter [400/45000]\tlr: 1.582e-05, eta: 4:05:39, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1318, decode.loss_lovasz: 0.8773, decode.acc_seg: 92.3639, loss: 1.0091\n","2022-10-08 12:34:18,854 - mmseg - INFO - Iter [410/45000]\tlr: 1.621e-05, eta: 4:05:28, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2046, decode.loss_lovasz: 1.0138, decode.acc_seg: 90.8221, loss: 1.2185\n","2022-10-08 12:34:22,086 - mmseg - INFO - Iter [420/45000]\tlr: 1.660e-05, eta: 4:05:17, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2687, decode.loss_lovasz: 1.0013, decode.acc_seg: 87.4310, loss: 1.2701\n","2022-10-08 12:34:25,302 - mmseg - INFO - Iter [430/45000]\tlr: 1.700e-05, eta: 4:05:05, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2262, decode.loss_lovasz: 1.0008, decode.acc_seg: 88.0421, loss: 1.2270\n","2022-10-08 12:34:28,534 - mmseg - INFO - Iter [440/45000]\tlr: 1.739e-05, eta: 4:04:55, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1586, decode.loss_lovasz: 0.9581, decode.acc_seg: 92.2154, loss: 1.1167\n","2022-10-08 12:34:31,756 - mmseg - INFO - Iter [450/45000]\tlr: 1.778e-05, eta: 4:04:44, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1525, decode.loss_lovasz: 0.9179, decode.acc_seg: 92.3080, loss: 1.0704\n","2022-10-08 12:34:34,973 - mmseg - INFO - Iter [460/45000]\tlr: 1.817e-05, eta: 4:04:33, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2005, decode.loss_lovasz: 0.9552, decode.acc_seg: 89.7338, loss: 1.1557\n","2022-10-08 12:34:38,155 - mmseg - INFO - Iter [470/45000]\tlr: 1.856e-05, eta: 4:04:19, time: 0.318, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1570, decode.loss_lovasz: 0.8183, decode.acc_seg: 90.2042, loss: 0.9753\n","2022-10-08 12:34:41,382 - mmseg - INFO - Iter [480/45000]\tlr: 1.896e-05, eta: 4:04:10, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1401, decode.loss_lovasz: 0.9145, decode.acc_seg: 91.8981, loss: 1.0545\n","2022-10-08 12:34:44,584 - mmseg - INFO - Iter [490/45000]\tlr: 1.935e-05, eta: 4:03:58, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1787, decode.loss_lovasz: 0.8009, decode.acc_seg: 93.3896, loss: 0.9796\n","2022-10-08 12:34:47,954 - mmseg - INFO - Iter [500/45000]\tlr: 1.974e-05, eta: 4:04:02, time: 0.337, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2342, decode.loss_lovasz: 0.8877, decode.acc_seg: 90.0902, loss: 1.1219\n","2022-10-08 12:34:51,195 - mmseg - INFO - Iter [510/45000]\tlr: 2.013e-05, eta: 4:03:55, time: 0.324, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1253, decode.loss_lovasz: 0.8700, decode.acc_seg: 92.7956, loss: 0.9954\n","2022-10-08 12:34:54,415 - mmseg - INFO - Iter [520/45000]\tlr: 2.052e-05, eta: 4:03:46, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1652, decode.loss_lovasz: 0.9126, decode.acc_seg: 92.3210, loss: 1.0778\n","2022-10-08 12:34:57,640 - mmseg - INFO - Iter [530/45000]\tlr: 2.091e-05, eta: 4:03:37, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1903, decode.loss_lovasz: 0.9018, decode.acc_seg: 91.1995, loss: 1.0921\n","2022-10-08 12:35:00,882 - mmseg - INFO - Iter [540/45000]\tlr: 2.130e-05, eta: 4:03:30, time: 0.324, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2748, decode.loss_lovasz: 1.0151, decode.acc_seg: 84.2639, loss: 1.2898\n","2022-10-08 12:35:04,080 - mmseg - INFO - Iter [550/45000]\tlr: 2.169e-05, eta: 4:03:20, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1837, decode.loss_lovasz: 0.8228, decode.acc_seg: 91.3247, loss: 1.0065\n","2022-10-08 12:35:07,269 - mmseg - INFO - Iter [560/45000]\tlr: 2.208e-05, eta: 4:03:09, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1400, decode.loss_lovasz: 0.7997, decode.acc_seg: 92.0855, loss: 0.9396\n","2022-10-08 12:35:10,480 - mmseg - INFO - Iter [570/45000]\tlr: 2.247e-05, eta: 4:03:00, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2406, decode.loss_lovasz: 0.9331, decode.acc_seg: 88.7631, loss: 1.1737\n","2022-10-08 12:35:13,704 - mmseg - INFO - Iter [580/45000]\tlr: 2.286e-05, eta: 4:02:52, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1652, decode.loss_lovasz: 0.8633, decode.acc_seg: 90.7349, loss: 1.0286\n","2022-10-08 12:35:16,940 - mmseg - INFO - Iter [590/45000]\tlr: 2.325e-05, eta: 4:02:45, time: 0.324, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1495, decode.loss_lovasz: 0.8329, decode.acc_seg: 92.3714, loss: 0.9824\n","2022-10-08 12:35:20,192 - mmseg - INFO - Iter [600/45000]\tlr: 2.364e-05, eta: 4:02:40, time: 0.325, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1551, decode.loss_lovasz: 0.8365, decode.acc_seg: 93.5361, loss: 0.9916\n","2022-10-08 12:35:23,408 - mmseg - INFO - Iter [610/45000]\tlr: 2.403e-05, eta: 4:02:32, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1035, decode.loss_lovasz: 0.7856, decode.acc_seg: 94.9101, loss: 0.8890\n","2022-10-08 12:35:26,634 - mmseg - INFO - Iter [620/45000]\tlr: 2.442e-05, eta: 4:02:25, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1874, decode.loss_lovasz: 0.7383, decode.acc_seg: 91.1856, loss: 0.9257\n","2022-10-08 12:35:29,836 - mmseg - INFO - Iter [630/45000]\tlr: 2.481e-05, eta: 4:02:17, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1640, decode.loss_lovasz: 0.7378, decode.acc_seg: 91.8671, loss: 0.9018\n","2022-10-08 12:35:33,059 - mmseg - INFO - Iter [640/45000]\tlr: 2.520e-05, eta: 4:02:10, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1468, decode.loss_lovasz: 0.7007, decode.acc_seg: 92.4690, loss: 0.8475\n","2022-10-08 12:35:36,249 - mmseg - INFO - Iter [650/45000]\tlr: 2.559e-05, eta: 4:02:00, time: 0.319, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1704, decode.loss_lovasz: 0.7046, decode.acc_seg: 92.6259, loss: 0.8750\n","2022-10-08 12:35:39,444 - mmseg - INFO - Iter [660/45000]\tlr: 2.597e-05, eta: 4:01:52, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0989, decode.loss_lovasz: 0.6186, decode.acc_seg: 96.0725, loss: 0.7174\n","2022-10-08 12:35:42,649 - mmseg - INFO - Iter [670/45000]\tlr: 2.636e-05, eta: 4:01:44, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0877, decode.loss_lovasz: 0.8636, decode.acc_seg: 94.9807, loss: 0.9513\n","2022-10-08 12:35:45,867 - mmseg - INFO - Iter [680/45000]\tlr: 2.675e-05, eta: 4:01:37, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1340, decode.loss_lovasz: 0.7829, decode.acc_seg: 92.9963, loss: 0.9169\n","2022-10-08 12:35:49,070 - mmseg - INFO - Iter [690/45000]\tlr: 2.714e-05, eta: 4:01:30, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2276, decode.loss_lovasz: 0.9636, decode.acc_seg: 89.7112, loss: 1.1912\n","2022-10-08 12:35:52,274 - mmseg - INFO - Iter [700/45000]\tlr: 2.753e-05, eta: 4:01:22, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1387, decode.loss_lovasz: 0.6755, decode.acc_seg: 94.7041, loss: 0.8141\n","2022-10-08 12:35:55,546 - mmseg - INFO - Iter [710/45000]\tlr: 2.791e-05, eta: 4:01:19, time: 0.327, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2116, decode.loss_lovasz: 0.9492, decode.acc_seg: 90.2313, loss: 1.1608\n","2022-10-08 12:35:58,755 - mmseg - INFO - Iter [720/45000]\tlr: 2.830e-05, eta: 4:01:12, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2346, decode.loss_lovasz: 0.9946, decode.acc_seg: 88.5967, loss: 1.2292\n","2022-10-08 12:36:01,974 - mmseg - INFO - Iter [730/45000]\tlr: 2.869e-05, eta: 4:01:06, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1685, decode.loss_lovasz: 0.7982, decode.acc_seg: 91.2173, loss: 0.9667\n","2022-10-08 12:36:05,190 - mmseg - INFO - Iter [740/45000]\tlr: 2.907e-05, eta: 4:00:59, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1799, decode.loss_lovasz: 0.7889, decode.acc_seg: 90.8498, loss: 0.9687\n","2022-10-08 12:36:08,386 - mmseg - INFO - Iter [750/45000]\tlr: 2.946e-05, eta: 4:00:52, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2845, decode.loss_lovasz: 0.9921, decode.acc_seg: 87.5320, loss: 1.2766\n","2022-10-08 12:36:11,608 - mmseg - INFO - Iter [760/45000]\tlr: 2.985e-05, eta: 4:00:46, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2187, decode.loss_lovasz: 0.9236, decode.acc_seg: 88.3151, loss: 1.1424\n","2022-10-08 12:36:14,823 - mmseg - INFO - Iter [770/45000]\tlr: 3.023e-05, eta: 4:00:40, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1595, decode.loss_lovasz: 0.8192, decode.acc_seg: 90.3998, loss: 0.9787\n","2022-10-08 12:36:18,023 - mmseg - INFO - Iter [780/45000]\tlr: 3.062e-05, eta: 4:00:33, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1796, decode.loss_lovasz: 0.9076, decode.acc_seg: 90.5281, loss: 1.0872\n","2022-10-08 12:36:21,226 - mmseg - INFO - Iter [790/45000]\tlr: 3.101e-05, eta: 4:00:26, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1807, decode.loss_lovasz: 0.9389, decode.acc_seg: 91.0075, loss: 1.1196\n","2022-10-08 12:36:24,433 - mmseg - INFO - Iter [800/45000]\tlr: 3.139e-05, eta: 4:00:20, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1861, decode.loss_lovasz: 0.8832, decode.acc_seg: 92.6868, loss: 1.0693\n","2022-10-08 12:36:27,651 - mmseg - INFO - Iter [810/45000]\tlr: 3.178e-05, eta: 4:00:14, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1794, decode.loss_lovasz: 0.8694, decode.acc_seg: 87.8175, loss: 1.0488\n","2022-10-08 12:36:30,872 - mmseg - INFO - Iter [820/45000]\tlr: 3.216e-05, eta: 4:00:09, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1652, decode.loss_lovasz: 0.8536, decode.acc_seg: 92.5183, loss: 1.0188\n","2022-10-08 12:36:34,103 - mmseg - INFO - Iter [830/45000]\tlr: 3.255e-05, eta: 4:00:04, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2419, decode.loss_lovasz: 0.8750, decode.acc_seg: 91.1946, loss: 1.1169\n","2022-10-08 12:36:37,293 - mmseg - INFO - Iter [840/45000]\tlr: 3.293e-05, eta: 3:59:57, time: 0.319, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1810, decode.loss_lovasz: 0.8444, decode.acc_seg: 90.1024, loss: 1.0254\n","2022-10-08 12:36:40,508 - mmseg - INFO - Iter [850/45000]\tlr: 3.332e-05, eta: 3:59:51, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1042, decode.loss_lovasz: 0.6390, decode.acc_seg: 95.1705, loss: 0.7432\n","2022-10-08 12:36:43,712 - mmseg - INFO - Iter [860/45000]\tlr: 3.370e-05, eta: 3:59:45, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1141, decode.loss_lovasz: 0.7045, decode.acc_seg: 94.5435, loss: 0.8186\n","2022-10-08 12:36:46,923 - mmseg - INFO - Iter [870/45000]\tlr: 3.409e-05, eta: 3:59:39, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1519, decode.loss_lovasz: 0.6534, decode.acc_seg: 94.2491, loss: 0.8053\n","2022-10-08 12:36:50,129 - mmseg - INFO - Iter [880/45000]\tlr: 3.447e-05, eta: 3:59:34, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1447, decode.loss_lovasz: 0.5976, decode.acc_seg: 93.3716, loss: 0.7423\n","2022-10-08 12:36:53,363 - mmseg - INFO - Iter [890/45000]\tlr: 3.486e-05, eta: 3:59:29, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1575, decode.loss_lovasz: 0.7404, decode.acc_seg: 92.3025, loss: 0.8979\n","2022-10-08 12:36:56,584 - mmseg - INFO - Iter [900/45000]\tlr: 3.524e-05, eta: 3:59:24, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1189, decode.loss_lovasz: 0.6568, decode.acc_seg: 95.3441, loss: 0.7757\n","2022-10-08 12:36:59,814 - mmseg - INFO - Iter [910/45000]\tlr: 3.563e-05, eta: 3:59:19, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2037, decode.loss_lovasz: 0.6949, decode.acc_seg: 92.1409, loss: 0.8986\n","2022-10-08 12:37:03,049 - mmseg - INFO - Iter [920/45000]\tlr: 3.601e-05, eta: 3:59:15, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1530, decode.loss_lovasz: 0.7531, decode.acc_seg: 93.3660, loss: 0.9061\n","2022-10-08 12:37:06,310 - mmseg - INFO - Iter [930/45000]\tlr: 3.639e-05, eta: 3:59:12, time: 0.326, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1583, decode.loss_lovasz: 0.7289, decode.acc_seg: 93.6855, loss: 0.8872\n","2022-10-08 12:37:09,553 - mmseg - INFO - Iter [940/45000]\tlr: 3.678e-05, eta: 3:59:08, time: 0.324, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2167, decode.loss_lovasz: 0.7797, decode.acc_seg: 90.7852, loss: 0.9964\n","2022-10-08 12:37:12,783 - mmseg - INFO - Iter [950/45000]\tlr: 3.716e-05, eta: 3:59:04, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1464, decode.loss_lovasz: 0.8456, decode.acc_seg: 90.3079, loss: 0.9920\n","2022-10-08 12:37:15,993 - mmseg - INFO - Iter [960/45000]\tlr: 3.754e-05, eta: 3:58:58, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1737, decode.loss_lovasz: 0.8382, decode.acc_seg: 92.0287, loss: 1.0119\n","2022-10-08 12:37:19,206 - mmseg - INFO - Iter [970/45000]\tlr: 3.793e-05, eta: 3:58:53, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1476, decode.loss_lovasz: 0.7633, decode.acc_seg: 92.7437, loss: 0.9109\n","2022-10-08 12:37:22,411 - mmseg - INFO - Iter [980/45000]\tlr: 3.831e-05, eta: 3:58:48, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1372, decode.loss_lovasz: 0.6470, decode.acc_seg: 92.9130, loss: 0.7843\n","2022-10-08 12:37:25,635 - mmseg - INFO - Iter [990/45000]\tlr: 3.869e-05, eta: 3:58:43, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1047, decode.loss_lovasz: 0.6703, decode.acc_seg: 95.2587, loss: 0.7750\n","2022-10-08 12:37:28,894 - mmseg - INFO - Exp name: segformer_mit-b4_960.py\n","2022-10-08 12:37:28,894 - mmseg - INFO - Iter [1000/45000]\tlr: 3.907e-05, eta: 3:58:40, time: 0.326, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1521, decode.loss_lovasz: 0.7688, decode.acc_seg: 93.2985, loss: 0.9209\n","2022-10-08 12:37:32,136 - mmseg - INFO - Iter [1010/45000]\tlr: 3.946e-05, eta: 3:58:36, time: 0.324, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2513, decode.loss_lovasz: 0.7175, decode.acc_seg: 91.0052, loss: 0.9689\n","2022-10-08 12:37:35,347 - mmseg - INFO - Iter [1020/45000]\tlr: 3.984e-05, eta: 3:58:31, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1842, decode.loss_lovasz: 0.7378, decode.acc_seg: 89.2379, loss: 0.9219\n","2022-10-08 12:37:38,554 - mmseg - INFO - Iter [1030/45000]\tlr: 4.022e-05, eta: 3:58:26, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1581, decode.loss_lovasz: 0.7984, decode.acc_seg: 92.2971, loss: 0.9565\n","2022-10-08 12:37:41,762 - mmseg - INFO - Iter [1040/45000]\tlr: 4.060e-05, eta: 3:58:20, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2316, decode.loss_lovasz: 0.9568, decode.acc_seg: 87.9485, loss: 1.1884\n","2022-10-08 12:37:44,969 - mmseg - INFO - Iter [1050/45000]\tlr: 4.098e-05, eta: 3:58:15, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1496, decode.loss_lovasz: 0.5980, decode.acc_seg: 94.2679, loss: 0.7476\n","2022-10-08 12:37:48,177 - mmseg - INFO - Iter [1060/45000]\tlr: 4.136e-05, eta: 3:58:10, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1303, decode.loss_lovasz: 0.7005, decode.acc_seg: 93.3609, loss: 0.8308\n","2022-10-08 12:37:51,396 - mmseg - INFO - Iter [1070/45000]\tlr: 4.174e-05, eta: 3:58:06, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1162, decode.loss_lovasz: 0.6044, decode.acc_seg: 95.1057, loss: 0.7206\n","2022-10-08 12:37:54,597 - mmseg - INFO - Iter [1080/45000]\tlr: 4.213e-05, eta: 3:58:00, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1200, decode.loss_lovasz: 0.7215, decode.acc_seg: 93.7695, loss: 0.8415\n","2022-10-08 12:37:57,805 - mmseg - INFO - Iter [1090/45000]\tlr: 4.251e-05, eta: 3:57:55, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1658, decode.loss_lovasz: 0.7211, decode.acc_seg: 92.7246, loss: 0.8869\n","2022-10-08 12:38:01,041 - mmseg - INFO - Iter [1100/45000]\tlr: 4.289e-05, eta: 3:57:51, time: 0.324, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1084, decode.loss_lovasz: 0.6924, decode.acc_seg: 94.1011, loss: 0.8008\n","2022-10-08 12:38:04,280 - mmseg - INFO - Iter [1110/45000]\tlr: 4.327e-05, eta: 3:57:48, time: 0.324, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1586, decode.loss_lovasz: 0.7517, decode.acc_seg: 94.2363, loss: 0.9103\n","2022-10-08 12:38:07,502 - mmseg - INFO - Iter [1120/45000]\tlr: 4.365e-05, eta: 3:57:43, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.2259, decode.loss_lovasz: 0.7559, decode.acc_seg: 91.2622, loss: 0.9818\n","2022-10-08 12:38:10,709 - mmseg - INFO - Iter [1130/45000]\tlr: 4.403e-05, eta: 3:57:38, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1573, decode.loss_lovasz: 0.7731, decode.acc_seg: 91.6242, loss: 0.9305\n","2022-10-08 12:38:13,925 - mmseg - INFO - Iter [1140/45000]\tlr: 4.441e-05, eta: 3:57:34, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1511, decode.loss_lovasz: 0.7688, decode.acc_seg: 92.4632, loss: 0.9199\n","2022-10-08 12:38:17,121 - mmseg - INFO - Iter [1150/45000]\tlr: 4.479e-05, eta: 3:57:28, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1978, decode.loss_lovasz: 0.7063, decode.acc_seg: 91.2350, loss: 0.9042\n","2022-10-08 12:38:20,324 - mmseg - INFO - Iter [1160/45000]\tlr: 4.517e-05, eta: 3:57:23, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1568, decode.loss_lovasz: 0.6006, decode.acc_seg: 93.7087, loss: 0.7574\n","2022-10-08 12:38:23,526 - mmseg - INFO - Iter [1170/45000]\tlr: 4.555e-05, eta: 3:57:18, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1525, decode.loss_lovasz: 0.7706, decode.acc_seg: 92.7143, loss: 0.9231\n","2022-10-08 12:38:26,745 - mmseg - INFO - Iter [1180/45000]\tlr: 4.592e-05, eta: 3:57:14, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1854, decode.loss_lovasz: 0.8054, decode.acc_seg: 92.4933, loss: 0.9908\n","2022-10-08 12:38:29,962 - mmseg - INFO - Iter [1190/45000]\tlr: 4.630e-05, eta: 3:57:10, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0780, decode.loss_lovasz: 0.5856, decode.acc_seg: 96.8377, loss: 0.6636\n","2022-10-08 12:38:33,168 - mmseg - INFO - Iter [1200/45000]\tlr: 4.668e-05, eta: 3:57:05, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1698, decode.loss_lovasz: 0.7172, decode.acc_seg: 91.9185, loss: 0.8870\n","2022-10-08 12:38:36,368 - mmseg - INFO - Iter [1210/45000]\tlr: 4.706e-05, eta: 3:57:00, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0926, decode.loss_lovasz: 0.8017, decode.acc_seg: 95.0630, loss: 0.8942\n","2022-10-08 12:38:39,577 - mmseg - INFO - Iter [1220/45000]\tlr: 4.744e-05, eta: 3:56:55, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.2244, decode.loss_lovasz: 0.8410, decode.acc_seg: 90.7353, loss: 1.0654\n","2022-10-08 12:38:42,767 - mmseg - INFO - Iter [1230/45000]\tlr: 4.782e-05, eta: 3:56:50, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1715, decode.loss_lovasz: 0.7606, decode.acc_seg: 92.0210, loss: 0.9321\n","2022-10-08 12:38:45,998 - mmseg - INFO - Iter [1240/45000]\tlr: 4.820e-05, eta: 3:56:46, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2763, decode.loss_lovasz: 0.8956, decode.acc_seg: 88.6245, loss: 1.1719\n","2022-10-08 12:38:49,244 - mmseg - INFO - Iter [1250/45000]\tlr: 4.857e-05, eta: 3:56:43, time: 0.325, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2032, decode.loss_lovasz: 0.9717, decode.acc_seg: 90.5118, loss: 1.1749\n","2022-10-08 12:38:52,452 - mmseg - INFO - Iter [1260/45000]\tlr: 4.895e-05, eta: 3:56:38, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1205, decode.loss_lovasz: 0.6645, decode.acc_seg: 94.7488, loss: 0.7850\n","2022-10-08 12:38:55,652 - mmseg - INFO - Iter [1270/45000]\tlr: 4.933e-05, eta: 3:56:33, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1466, decode.loss_lovasz: 0.8243, decode.acc_seg: 91.9449, loss: 0.9709\n","2022-10-08 12:38:58,893 - mmseg - INFO - Iter [1280/45000]\tlr: 4.971e-05, eta: 3:56:30, time: 0.324, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1543, decode.loss_lovasz: 0.7242, decode.acc_seg: 92.6039, loss: 0.8785\n","2022-10-08 12:39:02,110 - mmseg - INFO - Iter [1290/45000]\tlr: 5.008e-05, eta: 3:56:26, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1344, decode.loss_lovasz: 0.5118, decode.acc_seg: 93.8913, loss: 0.6462\n","2022-10-08 12:39:05,319 - mmseg - INFO - Iter [1300/45000]\tlr: 5.046e-05, eta: 3:56:21, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0790, decode.loss_lovasz: 0.5073, decode.acc_seg: 96.8451, loss: 0.5864\n","2022-10-08 12:39:08,535 - mmseg - INFO - Iter [1310/45000]\tlr: 5.084e-05, eta: 3:56:17, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1911, decode.loss_lovasz: 0.6269, decode.acc_seg: 91.5635, loss: 0.8180\n","2022-10-08 12:39:11,763 - mmseg - INFO - Iter [1320/45000]\tlr: 5.121e-05, eta: 3:56:13, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1893, decode.loss_lovasz: 0.7761, decode.acc_seg: 92.0564, loss: 0.9654\n","2022-10-08 12:39:14,983 - mmseg - INFO - Iter [1330/45000]\tlr: 5.159e-05, eta: 3:56:09, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1449, decode.loss_lovasz: 0.7174, decode.acc_seg: 92.8844, loss: 0.8622\n","2022-10-08 12:39:18,180 - mmseg - INFO - Iter [1340/45000]\tlr: 5.197e-05, eta: 3:56:04, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1514, decode.loss_lovasz: 0.7521, decode.acc_seg: 93.2649, loss: 0.9036\n","2022-10-08 12:39:21,399 - mmseg - INFO - Iter [1350/45000]\tlr: 5.234e-05, eta: 3:56:00, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0506, decode.loss_lovasz: 0.3416, decode.acc_seg: 97.6252, loss: 0.3922\n","2022-10-08 12:39:24,609 - mmseg - INFO - Iter [1360/45000]\tlr: 5.272e-05, eta: 3:55:56, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1860, decode.loss_lovasz: 0.7349, decode.acc_seg: 92.4585, loss: 0.9209\n","2022-10-08 12:39:27,834 - mmseg - INFO - Iter [1370/45000]\tlr: 5.309e-05, eta: 3:55:52, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1840, decode.loss_lovasz: 0.6038, decode.acc_seg: 91.8436, loss: 0.7877\n","2022-10-08 12:39:31,091 - mmseg - INFO - Iter [1380/45000]\tlr: 5.347e-05, eta: 3:55:49, time: 0.326, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2593, decode.loss_lovasz: 0.7809, decode.acc_seg: 90.1550, loss: 1.0402\n","2022-10-08 12:39:34,319 - mmseg - INFO - Iter [1390/45000]\tlr: 5.385e-05, eta: 3:55:46, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1397, decode.loss_lovasz: 0.5733, decode.acc_seg: 93.8086, loss: 0.7129\n","2022-10-08 12:39:37,572 - mmseg - INFO - Iter [1400/45000]\tlr: 5.422e-05, eta: 3:55:43, time: 0.325, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1257, decode.loss_lovasz: 0.5354, decode.acc_seg: 94.2951, loss: 0.6610\n","2022-10-08 12:39:40,777 - mmseg - INFO - Iter [1410/45000]\tlr: 5.460e-05, eta: 3:55:38, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0951, decode.loss_lovasz: 0.5469, decode.acc_seg: 95.7032, loss: 0.6420\n","2022-10-08 12:39:43,998 - mmseg - INFO - Iter [1420/45000]\tlr: 5.497e-05, eta: 3:55:34, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0918, decode.loss_lovasz: 0.5874, decode.acc_seg: 95.9123, loss: 0.6792\n","2022-10-08 12:39:47,234 - mmseg - INFO - Iter [1430/45000]\tlr: 5.534e-05, eta: 3:55:31, time: 0.324, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1110, decode.loss_lovasz: 0.5540, decode.acc_seg: 96.5818, loss: 0.6650\n","2022-10-08 12:39:50,466 - mmseg - INFO - Iter [1440/45000]\tlr: 5.572e-05, eta: 3:55:27, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1252, decode.loss_lovasz: 0.5720, decode.acc_seg: 94.6797, loss: 0.6973\n","2022-10-08 12:39:53,693 - mmseg - INFO - Iter [1450/45000]\tlr: 5.609e-05, eta: 3:55:24, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1279, decode.loss_lovasz: 0.6324, decode.acc_seg: 94.0841, loss: 0.7603\n","2022-10-08 12:39:56,914 - mmseg - INFO - Iter [1460/45000]\tlr: 5.647e-05, eta: 3:55:20, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1551, decode.loss_lovasz: 0.8617, decode.acc_seg: 92.5565, loss: 1.0167\n","2022-10-08 12:40:00,173 - mmseg - INFO - Iter [1470/45000]\tlr: 5.684e-05, eta: 3:55:17, time: 0.326, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1941, decode.loss_lovasz: 0.8125, decode.acc_seg: 92.3813, loss: 1.0065\n","2022-10-08 12:40:03,412 - mmseg - INFO - Iter [1480/45000]\tlr: 5.722e-05, eta: 3:55:13, time: 0.324, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1521, decode.loss_lovasz: 0.6477, decode.acc_seg: 94.5858, loss: 0.7998\n","2022-10-08 12:40:06,630 - mmseg - INFO - Iter [1490/45000]\tlr: 5.759e-05, eta: 3:55:09, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0861, decode.loss_lovasz: 0.5109, decode.acc_seg: 95.8757, loss: 0.5969\n","2022-10-08 12:40:09,852 - mmseg - INFO - Iter [1500/45000]\tlr: 5.796e-05, eta: 3:55:06, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1631, decode.loss_lovasz: 0.7516, decode.acc_seg: 93.9954, loss: 0.9147\n","2022-10-08 12:40:13,070 - mmseg - INFO - Iter [1510/45000]\tlr: 5.799e-05, eta: 3:55:02, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1853, decode.loss_lovasz: 0.7591, decode.acc_seg: 89.7354, loss: 0.9444\n","2022-10-08 12:40:16,290 - mmseg - INFO - Iter [1520/45000]\tlr: 5.797e-05, eta: 3:54:58, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1375, decode.loss_lovasz: 0.7841, decode.acc_seg: 92.3678, loss: 0.9216\n","2022-10-08 12:40:19,512 - mmseg - INFO - Iter [1530/45000]\tlr: 5.796e-05, eta: 3:54:54, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1181, decode.loss_lovasz: 0.6584, decode.acc_seg: 95.3807, loss: 0.7765\n","2022-10-08 12:40:22,720 - mmseg - INFO - Iter [1540/45000]\tlr: 5.795e-05, eta: 3:54:50, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1656, decode.loss_lovasz: 0.8038, decode.acc_seg: 92.3036, loss: 0.9693\n","2022-10-08 12:40:25,915 - mmseg - INFO - Iter [1550/45000]\tlr: 5.793e-05, eta: 3:54:45, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1723, decode.loss_lovasz: 0.6950, decode.acc_seg: 92.7039, loss: 0.8673\n","2022-10-08 12:40:29,243 - mmseg - INFO - Iter [1560/45000]\tlr: 5.792e-05, eta: 3:54:44, time: 0.333, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1316, decode.loss_lovasz: 0.6495, decode.acc_seg: 92.8597, loss: 0.7811\n","2022-10-08 12:40:32,462 - mmseg - INFO - Iter [1570/45000]\tlr: 5.791e-05, eta: 3:54:40, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1328, decode.loss_lovasz: 0.8042, decode.acc_seg: 93.0605, loss: 0.9370\n","2022-10-08 12:40:35,669 - mmseg - INFO - Iter [1580/45000]\tlr: 5.789e-05, eta: 3:54:36, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1937, decode.loss_lovasz: 0.7912, decode.acc_seg: 90.6364, loss: 0.9848\n","2022-10-08 12:40:38,900 - mmseg - INFO - Iter [1590/45000]\tlr: 5.788e-05, eta: 3:54:33, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2456, decode.loss_lovasz: 0.7949, decode.acc_seg: 89.5247, loss: 1.0405\n","2022-10-08 12:40:42,098 - mmseg - INFO - Iter [1600/45000]\tlr: 5.787e-05, eta: 3:54:28, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1021, decode.loss_lovasz: 0.6440, decode.acc_seg: 95.0662, loss: 0.7461\n","2022-10-08 12:40:45,319 - mmseg - INFO - Iter [1610/45000]\tlr: 5.785e-05, eta: 3:54:24, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1349, decode.loss_lovasz: 0.5960, decode.acc_seg: 94.3384, loss: 0.7309\n","2022-10-08 12:40:48,538 - mmseg - INFO - Iter [1620/45000]\tlr: 5.784e-05, eta: 3:54:21, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0884, decode.loss_lovasz: 0.4482, decode.acc_seg: 96.4811, loss: 0.5366\n","2022-10-08 12:40:51,758 - mmseg - INFO - Iter [1630/45000]\tlr: 5.783e-05, eta: 3:54:17, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2023, decode.loss_lovasz: 0.6914, decode.acc_seg: 92.2253, loss: 0.8937\n","2022-10-08 12:40:54,949 - mmseg - INFO - Iter [1640/45000]\tlr: 5.781e-05, eta: 3:54:12, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1006, decode.loss_lovasz: 0.6030, decode.acc_seg: 95.0364, loss: 0.7035\n","2022-10-08 12:40:58,171 - mmseg - INFO - Iter [1650/45000]\tlr: 5.780e-05, eta: 3:54:08, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0696, decode.loss_lovasz: 0.5388, decode.acc_seg: 95.5096, loss: 0.6084\n","2022-10-08 12:41:01,394 - mmseg - INFO - Iter [1660/45000]\tlr: 5.779e-05, eta: 3:54:05, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1548, decode.loss_lovasz: 0.7233, decode.acc_seg: 91.0277, loss: 0.8780\n","2022-10-08 12:41:04,605 - mmseg - INFO - Iter [1670/45000]\tlr: 5.777e-05, eta: 3:54:01, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0715, decode.loss_lovasz: 0.5454, decode.acc_seg: 96.7850, loss: 0.6168\n","2022-10-08 12:41:07,817 - mmseg - INFO - Iter [1680/45000]\tlr: 5.776e-05, eta: 3:53:57, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1329, decode.loss_lovasz: 0.6731, decode.acc_seg: 94.6191, loss: 0.8060\n","2022-10-08 12:41:11,033 - mmseg - INFO - Iter [1690/45000]\tlr: 5.775e-05, eta: 3:53:53, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.2191, decode.loss_lovasz: 0.7736, decode.acc_seg: 92.0243, loss: 0.9926\n","2022-10-08 12:41:14,248 - mmseg - INFO - Iter [1700/45000]\tlr: 5.773e-05, eta: 3:53:49, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1856, decode.loss_lovasz: 0.7920, decode.acc_seg: 91.2821, loss: 0.9776\n","2022-10-08 12:41:17,476 - mmseg - INFO - Iter [1710/45000]\tlr: 5.772e-05, eta: 3:53:45, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1295, decode.loss_lovasz: 0.6231, decode.acc_seg: 93.3120, loss: 0.7526\n","2022-10-08 12:41:20,704 - mmseg - INFO - Iter [1720/45000]\tlr: 5.771e-05, eta: 3:53:42, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1751, decode.loss_lovasz: 0.9307, decode.acc_seg: 92.2067, loss: 1.1058\n","2022-10-08 12:41:23,934 - mmseg - INFO - Iter [1730/45000]\tlr: 5.769e-05, eta: 3:53:38, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0784, decode.loss_lovasz: 0.5259, decode.acc_seg: 96.1088, loss: 0.6043\n","2022-10-08 12:41:27,145 - mmseg - INFO - Iter [1740/45000]\tlr: 5.768e-05, eta: 3:53:34, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1482, decode.loss_lovasz: 0.6416, decode.acc_seg: 93.5679, loss: 0.7898\n","2022-10-08 12:41:30,362 - mmseg - INFO - Iter [1750/45000]\tlr: 5.767e-05, eta: 3:53:31, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1680, decode.loss_lovasz: 0.6961, decode.acc_seg: 93.0861, loss: 0.8641\n","2022-10-08 12:41:33,557 - mmseg - INFO - Iter [1760/45000]\tlr: 5.765e-05, eta: 3:53:26, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1263, decode.loss_lovasz: 0.6045, decode.acc_seg: 94.7351, loss: 0.7307\n","2022-10-08 12:41:36,783 - mmseg - INFO - Iter [1770/45000]\tlr: 5.764e-05, eta: 3:53:23, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1966, decode.loss_lovasz: 0.6388, decode.acc_seg: 91.2750, loss: 0.8354\n","2022-10-08 12:41:39,996 - mmseg - INFO - Iter [1780/45000]\tlr: 5.763e-05, eta: 3:53:19, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1849, decode.loss_lovasz: 0.5972, decode.acc_seg: 92.0473, loss: 0.7821\n","2022-10-08 12:41:43,198 - mmseg - INFO - Iter [1790/45000]\tlr: 5.761e-05, eta: 3:53:15, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1371, decode.loss_lovasz: 0.6481, decode.acc_seg: 92.3182, loss: 0.7852\n","2022-10-08 12:41:46,421 - mmseg - INFO - Iter [1800/45000]\tlr: 5.760e-05, eta: 3:53:11, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1725, decode.loss_lovasz: 0.6661, decode.acc_seg: 93.1039, loss: 0.8386\n","2022-10-08 12:41:49,690 - mmseg - INFO - Iter [1810/45000]\tlr: 5.759e-05, eta: 3:53:09, time: 0.327, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1354, decode.loss_lovasz: 0.5700, decode.acc_seg: 93.3160, loss: 0.7055\n","2022-10-08 12:41:52,922 - mmseg - INFO - Iter [1820/45000]\tlr: 5.757e-05, eta: 3:53:05, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1300, decode.loss_lovasz: 0.5706, decode.acc_seg: 93.6061, loss: 0.7006\n","2022-10-08 12:41:56,141 - mmseg - INFO - Iter [1830/45000]\tlr: 5.756e-05, eta: 3:53:02, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1132, decode.loss_lovasz: 0.6668, decode.acc_seg: 95.0126, loss: 0.7800\n","2022-10-08 12:41:59,348 - mmseg - INFO - Iter [1840/45000]\tlr: 5.755e-05, eta: 3:52:58, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1524, decode.loss_lovasz: 0.5258, decode.acc_seg: 94.5473, loss: 0.6782\n","2022-10-08 12:42:02,559 - mmseg - INFO - Iter [1850/45000]\tlr: 5.753e-05, eta: 3:52:54, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2366, decode.loss_lovasz: 0.7693, decode.acc_seg: 91.4167, loss: 1.0059\n","2022-10-08 12:42:05,777 - mmseg - INFO - Iter [1860/45000]\tlr: 5.752e-05, eta: 3:52:50, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1996, decode.loss_lovasz: 0.7895, decode.acc_seg: 90.1477, loss: 0.9891\n","2022-10-08 12:42:08,988 - mmseg - INFO - Iter [1870/45000]\tlr: 5.751e-05, eta: 3:52:46, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0992, decode.loss_lovasz: 0.4608, decode.acc_seg: 95.6061, loss: 0.5599\n","2022-10-08 12:42:12,214 - mmseg - INFO - Iter [1880/45000]\tlr: 5.749e-05, eta: 3:52:43, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1230, decode.loss_lovasz: 0.4831, decode.acc_seg: 94.8747, loss: 0.6060\n","2022-10-08 12:42:15,436 - mmseg - INFO - Iter [1890/45000]\tlr: 5.748e-05, eta: 3:52:39, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1236, decode.loss_lovasz: 0.6360, decode.acc_seg: 94.5063, loss: 0.7596\n","2022-10-08 12:42:18,694 - mmseg - INFO - Iter [1900/45000]\tlr: 5.747e-05, eta: 3:52:36, time: 0.326, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1936, decode.loss_lovasz: 0.6586, decode.acc_seg: 91.0484, loss: 0.8522\n","2022-10-08 12:42:21,897 - mmseg - INFO - Iter [1910/45000]\tlr: 5.745e-05, eta: 3:52:32, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1940, decode.loss_lovasz: 0.5959, decode.acc_seg: 92.0482, loss: 0.7899\n","2022-10-08 12:42:25,098 - mmseg - INFO - Iter [1920/45000]\tlr: 5.744e-05, eta: 3:52:28, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1414, decode.loss_lovasz: 0.5941, decode.acc_seg: 94.3530, loss: 0.7355\n","2022-10-08 12:42:28,304 - mmseg - INFO - Iter [1930/45000]\tlr: 5.743e-05, eta: 3:52:24, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1001, decode.loss_lovasz: 0.6076, decode.acc_seg: 95.2410, loss: 0.7077\n","2022-10-08 12:42:31,504 - mmseg - INFO - Iter [1940/45000]\tlr: 5.741e-05, eta: 3:52:20, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1297, decode.loss_lovasz: 0.6759, decode.acc_seg: 93.6137, loss: 0.8056\n","2022-10-08 12:42:34,701 - mmseg - INFO - Iter [1950/45000]\tlr: 5.740e-05, eta: 3:52:16, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1858, decode.loss_lovasz: 0.6746, decode.acc_seg: 91.1219, loss: 0.8604\n","2022-10-08 12:42:37,895 - mmseg - INFO - Iter [1960/45000]\tlr: 5.739e-05, eta: 3:52:12, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1056, decode.loss_lovasz: 0.6015, decode.acc_seg: 94.8214, loss: 0.7071\n","2022-10-08 12:42:41,110 - mmseg - INFO - Iter [1970/45000]\tlr: 5.737e-05, eta: 3:52:08, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0259, decode.loss_lovasz: 0.3386, decode.acc_seg: 98.7270, loss: 0.3645\n","2022-10-08 12:42:44,316 - mmseg - INFO - Iter [1980/45000]\tlr: 5.736e-05, eta: 3:52:04, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1430, decode.loss_lovasz: 0.6348, decode.acc_seg: 93.1815, loss: 0.7779\n","2022-10-08 12:42:47,539 - mmseg - INFO - Iter [1990/45000]\tlr: 5.735e-05, eta: 3:52:01, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1136, decode.loss_lovasz: 0.5658, decode.acc_seg: 95.0420, loss: 0.6793\n","2022-10-08 12:42:50,773 - mmseg - INFO - Exp name: segformer_mit-b4_960.py\n","2022-10-08 12:42:50,773 - mmseg - INFO - Iter [2000/45000]\tlr: 5.733e-05, eta: 3:51:57, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1070, decode.loss_lovasz: 0.5536, decode.acc_seg: 95.0889, loss: 0.6606\n","2022-10-08 12:42:53,999 - mmseg - INFO - Iter [2010/45000]\tlr: 5.732e-05, eta: 3:51:54, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1044, decode.loss_lovasz: 0.5060, decode.acc_seg: 95.4276, loss: 0.6104\n","2022-10-08 12:42:57,193 - mmseg - INFO - Iter [2020/45000]\tlr: 5.731e-05, eta: 3:51:50, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0927, decode.loss_lovasz: 0.3973, decode.acc_seg: 96.0142, loss: 0.4900\n","2022-10-08 12:43:02,884 - mmseg - INFO - Iter [2030/45000]\tlr: 5.729e-05, eta: 3:52:38, time: 0.569, data_time: 0.254, memory: 24005, decode.loss_ce: 0.1819, decode.loss_lovasz: 0.6848, decode.acc_seg: 91.2802, loss: 0.8667\n","2022-10-08 12:43:06,097 - mmseg - INFO - Iter [2040/45000]\tlr: 5.728e-05, eta: 3:52:34, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1147, decode.loss_lovasz: 0.5648, decode.acc_seg: 96.1307, loss: 0.6795\n","2022-10-08 12:43:09,319 - mmseg - INFO - Iter [2050/45000]\tlr: 5.727e-05, eta: 3:52:31, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1153, decode.loss_lovasz: 0.5071, decode.acc_seg: 94.7578, loss: 0.6224\n","2022-10-08 12:43:12,570 - mmseg - INFO - Iter [2060/45000]\tlr: 5.725e-05, eta: 3:52:27, time: 0.325, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1013, decode.loss_lovasz: 0.4889, decode.acc_seg: 96.2096, loss: 0.5901\n","2022-10-08 12:43:15,761 - mmseg - INFO - Iter [2070/45000]\tlr: 5.724e-05, eta: 3:52:23, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0663, decode.loss_lovasz: 0.5569, decode.acc_seg: 96.5299, loss: 0.6233\n","2022-10-08 12:43:18,962 - mmseg - INFO - Iter [2080/45000]\tlr: 5.723e-05, eta: 3:52:19, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1312, decode.loss_lovasz: 0.5081, decode.acc_seg: 95.0859, loss: 0.6393\n","2022-10-08 12:43:22,178 - mmseg - INFO - Iter [2090/45000]\tlr: 5.721e-05, eta: 3:52:15, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1695, decode.loss_lovasz: 0.7002, decode.acc_seg: 92.6947, loss: 0.8697\n","2022-10-08 12:43:25,404 - mmseg - INFO - Iter [2100/45000]\tlr: 5.720e-05, eta: 3:52:11, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1635, decode.loss_lovasz: 0.6244, decode.acc_seg: 94.0099, loss: 0.7878\n","2022-10-08 12:43:28,610 - mmseg - INFO - Iter [2110/45000]\tlr: 5.719e-05, eta: 3:52:07, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1257, decode.loss_lovasz: 0.7174, decode.acc_seg: 95.1256, loss: 0.8431\n","2022-10-08 12:43:31,820 - mmseg - INFO - Iter [2120/45000]\tlr: 5.717e-05, eta: 3:52:03, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1074, decode.loss_lovasz: 0.5002, decode.acc_seg: 95.6304, loss: 0.6076\n","2022-10-08 12:43:35,037 - mmseg - INFO - Iter [2130/45000]\tlr: 5.716e-05, eta: 3:51:59, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0911, decode.loss_lovasz: 0.4770, decode.acc_seg: 96.0212, loss: 0.5680\n","2022-10-08 12:43:38,278 - mmseg - INFO - Iter [2140/45000]\tlr: 5.715e-05, eta: 3:51:56, time: 0.324, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1562, decode.loss_lovasz: 0.5966, decode.acc_seg: 92.1909, loss: 0.7527\n","2022-10-08 12:43:41,501 - mmseg - INFO - Iter [2150/45000]\tlr: 5.713e-05, eta: 3:51:52, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0970, decode.loss_lovasz: 0.6510, decode.acc_seg: 94.2224, loss: 0.7480\n","2022-10-08 12:43:44,712 - mmseg - INFO - Iter [2160/45000]\tlr: 5.712e-05, eta: 3:51:48, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1261, decode.loss_lovasz: 0.5873, decode.acc_seg: 93.6130, loss: 0.7134\n","2022-10-08 12:43:47,921 - mmseg - INFO - Iter [2170/45000]\tlr: 5.711e-05, eta: 3:51:44, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1046, decode.loss_lovasz: 0.6658, decode.acc_seg: 94.5413, loss: 0.7704\n","2022-10-08 12:43:51,118 - mmseg - INFO - Iter [2180/45000]\tlr: 5.709e-05, eta: 3:51:40, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0636, decode.loss_lovasz: 0.2795, decode.acc_seg: 97.1082, loss: 0.3430\n","2022-10-08 12:43:54,338 - mmseg - INFO - Iter [2190/45000]\tlr: 5.708e-05, eta: 3:51:36, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1010, decode.loss_lovasz: 0.5257, decode.acc_seg: 95.8698, loss: 0.6266\n","2022-10-08 12:43:57,574 - mmseg - INFO - Iter [2200/45000]\tlr: 5.707e-05, eta: 3:51:33, time: 0.324, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1258, decode.loss_lovasz: 0.4789, decode.acc_seg: 95.1446, loss: 0.6047\n","2022-10-08 12:44:00,780 - mmseg - INFO - Iter [2210/45000]\tlr: 5.705e-05, eta: 3:51:29, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1599, decode.loss_lovasz: 0.6450, decode.acc_seg: 92.7584, loss: 0.8049\n","2022-10-08 12:44:03,965 - mmseg - INFO - Iter [2220/45000]\tlr: 5.704e-05, eta: 3:51:24, time: 0.318, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1354, decode.loss_lovasz: 0.6742, decode.acc_seg: 94.0716, loss: 0.8096\n","2022-10-08 12:44:07,178 - mmseg - INFO - Iter [2230/45000]\tlr: 5.703e-05, eta: 3:51:20, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2071, decode.loss_lovasz: 0.7407, decode.acc_seg: 92.6899, loss: 0.9477\n","2022-10-08 12:44:10,426 - mmseg - INFO - Iter [2240/45000]\tlr: 5.701e-05, eta: 3:51:17, time: 0.325, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0749, decode.loss_lovasz: 0.6217, decode.acc_seg: 96.3723, loss: 0.6966\n","2022-10-08 12:44:13,632 - mmseg - INFO - Iter [2250/45000]\tlr: 5.700e-05, eta: 3:51:13, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1959, decode.loss_lovasz: 0.6455, decode.acc_seg: 92.5881, loss: 0.8414\n","2022-10-08 12:44:16,869 - mmseg - INFO - Iter [2260/45000]\tlr: 5.699e-05, eta: 3:51:10, time: 0.324, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1621, decode.loss_lovasz: 0.7081, decode.acc_seg: 91.1895, loss: 0.8702\n","2022-10-08 12:44:20,101 - mmseg - INFO - Iter [2270/45000]\tlr: 5.697e-05, eta: 3:51:06, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0717, decode.loss_lovasz: 0.4048, decode.acc_seg: 97.2698, loss: 0.4764\n","2022-10-08 12:44:23,322 - mmseg - INFO - Iter [2280/45000]\tlr: 5.696e-05, eta: 3:51:03, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0980, decode.loss_lovasz: 0.5216, decode.acc_seg: 95.1886, loss: 0.6197\n","2022-10-08 12:44:26,543 - mmseg - INFO - Iter [2290/45000]\tlr: 5.695e-05, eta: 3:50:59, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1536, decode.loss_lovasz: 0.6525, decode.acc_seg: 94.2720, loss: 0.8062\n","2022-10-08 12:44:29,776 - mmseg - INFO - Iter [2300/45000]\tlr: 5.693e-05, eta: 3:50:55, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1860, decode.loss_lovasz: 0.6109, decode.acc_seg: 91.9538, loss: 0.7969\n","2022-10-08 12:44:33,000 - mmseg - INFO - Iter [2310/45000]\tlr: 5.692e-05, eta: 3:50:52, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1837, decode.loss_lovasz: 0.7022, decode.acc_seg: 91.1026, loss: 0.8859\n","2022-10-08 12:44:36,205 - mmseg - INFO - Iter [2320/45000]\tlr: 5.691e-05, eta: 3:50:48, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2433, decode.loss_lovasz: 0.6761, decode.acc_seg: 92.5268, loss: 0.9194\n","2022-10-08 12:44:39,431 - mmseg - INFO - Iter [2330/45000]\tlr: 5.689e-05, eta: 3:50:44, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0823, decode.loss_lovasz: 0.4928, decode.acc_seg: 95.5416, loss: 0.5751\n","2022-10-08 12:44:42,652 - mmseg - INFO - Iter [2340/45000]\tlr: 5.688e-05, eta: 3:50:41, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1462, decode.loss_lovasz: 0.5992, decode.acc_seg: 92.6547, loss: 0.7453\n","2022-10-08 12:44:45,864 - mmseg - INFO - Iter [2350/45000]\tlr: 5.687e-05, eta: 3:50:37, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1241, decode.loss_lovasz: 0.6155, decode.acc_seg: 93.0527, loss: 0.7396\n","2022-10-08 12:44:49,068 - mmseg - INFO - Iter [2360/45000]\tlr: 5.685e-05, eta: 3:50:33, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1265, decode.loss_lovasz: 0.5620, decode.acc_seg: 94.3766, loss: 0.6885\n","2022-10-08 12:44:52,291 - mmseg - INFO - Iter [2370/45000]\tlr: 5.684e-05, eta: 3:50:29, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1262, decode.loss_lovasz: 0.6164, decode.acc_seg: 93.4715, loss: 0.7426\n","2022-10-08 12:44:55,507 - mmseg - INFO - Iter [2380/45000]\tlr: 5.683e-05, eta: 3:50:25, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0736, decode.loss_lovasz: 0.3817, decode.acc_seg: 96.7643, loss: 0.4553\n","2022-10-08 12:44:58,757 - mmseg - INFO - Iter [2390/45000]\tlr: 5.681e-05, eta: 3:50:22, time: 0.325, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1411, decode.loss_lovasz: 0.5567, decode.acc_seg: 94.6392, loss: 0.6979\n","2022-10-08 12:45:01,956 - mmseg - INFO - Iter [2400/45000]\tlr: 5.680e-05, eta: 3:50:18, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1227, decode.loss_lovasz: 0.4967, decode.acc_seg: 95.3846, loss: 0.6194\n","2022-10-08 12:45:05,177 - mmseg - INFO - Iter [2410/45000]\tlr: 5.679e-05, eta: 3:50:15, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1101, decode.loss_lovasz: 0.6227, decode.acc_seg: 94.3612, loss: 0.7328\n","2022-10-08 12:45:08,392 - mmseg - INFO - Iter [2420/45000]\tlr: 5.677e-05, eta: 3:50:11, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2593, decode.loss_lovasz: 0.6671, decode.acc_seg: 90.6505, loss: 0.9264\n","2022-10-08 12:45:11,653 - mmseg - INFO - Iter [2430/45000]\tlr: 5.676e-05, eta: 3:50:08, time: 0.326, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0901, decode.loss_lovasz: 0.4214, decode.acc_seg: 96.2169, loss: 0.5115\n","2022-10-08 12:45:14,883 - mmseg - INFO - Iter [2440/45000]\tlr: 5.675e-05, eta: 3:50:04, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1460, decode.loss_lovasz: 0.5649, decode.acc_seg: 94.6230, loss: 0.7109\n","2022-10-08 12:45:18,108 - mmseg - INFO - Iter [2450/45000]\tlr: 5.673e-05, eta: 3:50:01, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1749, decode.loss_lovasz: 0.7987, decode.acc_seg: 92.5207, loss: 0.9736\n","2022-10-08 12:45:21,348 - mmseg - INFO - Iter [2460/45000]\tlr: 5.672e-05, eta: 3:49:57, time: 0.324, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0890, decode.loss_lovasz: 0.5744, decode.acc_seg: 95.8875, loss: 0.6634\n","2022-10-08 12:45:24,569 - mmseg - INFO - Iter [2470/45000]\tlr: 5.671e-05, eta: 3:49:54, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1223, decode.loss_lovasz: 0.6369, decode.acc_seg: 95.3567, loss: 0.7592\n","2022-10-08 12:45:27,772 - mmseg - INFO - Iter [2480/45000]\tlr: 5.669e-05, eta: 3:49:50, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1392, decode.loss_lovasz: 0.6035, decode.acc_seg: 92.9488, loss: 0.7427\n","2022-10-08 12:45:30,977 - mmseg - INFO - Iter [2490/45000]\tlr: 5.668e-05, eta: 3:49:46, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1186, decode.loss_lovasz: 0.5565, decode.acc_seg: 95.0808, loss: 0.6751\n","2022-10-08 12:45:34,186 - mmseg - INFO - Iter [2500/45000]\tlr: 5.667e-05, eta: 3:49:42, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1113, decode.loss_lovasz: 0.5462, decode.acc_seg: 95.5716, loss: 0.6575\n","2022-10-08 12:45:37,408 - mmseg - INFO - Iter [2510/45000]\tlr: 5.665e-05, eta: 3:49:39, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0346, decode.loss_lovasz: 0.3401, decode.acc_seg: 98.6345, loss: 0.3747\n","2022-10-08 12:45:40,623 - mmseg - INFO - Iter [2520/45000]\tlr: 5.664e-05, eta: 3:49:35, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0989, decode.loss_lovasz: 0.4918, decode.acc_seg: 96.0508, loss: 0.5907\n","2022-10-08 12:45:43,834 - mmseg - INFO - Iter [2530/45000]\tlr: 5.663e-05, eta: 3:49:31, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1966, decode.loss_lovasz: 0.5500, decode.acc_seg: 93.3436, loss: 0.7466\n","2022-10-08 12:45:47,046 - mmseg - INFO - Iter [2540/45000]\tlr: 5.661e-05, eta: 3:49:27, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1200, decode.loss_lovasz: 0.7187, decode.acc_seg: 94.7271, loss: 0.8387\n","2022-10-08 12:45:50,235 - mmseg - INFO - Iter [2550/45000]\tlr: 5.660e-05, eta: 3:49:23, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0611, decode.loss_lovasz: 0.4062, decode.acc_seg: 97.3103, loss: 0.4674\n","2022-10-08 12:45:53,448 - mmseg - INFO - Iter [2560/45000]\tlr: 5.659e-05, eta: 3:49:19, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1970, decode.loss_lovasz: 0.6470, decode.acc_seg: 90.7819, loss: 0.8440\n","2022-10-08 12:45:56,658 - mmseg - INFO - Iter [2570/45000]\tlr: 5.657e-05, eta: 3:49:16, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1091, decode.loss_lovasz: 0.5675, decode.acc_seg: 94.8245, loss: 0.6766\n","2022-10-08 12:45:59,891 - mmseg - INFO - Iter [2580/45000]\tlr: 5.656e-05, eta: 3:49:12, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0964, decode.loss_lovasz: 0.5434, decode.acc_seg: 95.9649, loss: 0.6399\n","2022-10-08 12:46:03,098 - mmseg - INFO - Iter [2590/45000]\tlr: 5.655e-05, eta: 3:49:08, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1391, decode.loss_lovasz: 0.7723, decode.acc_seg: 93.3476, loss: 0.9114\n","2022-10-08 12:46:06,300 - mmseg - INFO - Iter [2600/45000]\tlr: 5.653e-05, eta: 3:49:05, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1237, decode.loss_lovasz: 0.5925, decode.acc_seg: 93.6638, loss: 0.7162\n","2022-10-08 12:46:09,514 - mmseg - INFO - Iter [2610/45000]\tlr: 5.652e-05, eta: 3:49:01, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1150, decode.loss_lovasz: 0.5533, decode.acc_seg: 95.3592, loss: 0.6684\n","2022-10-08 12:46:12,823 - mmseg - INFO - Iter [2620/45000]\tlr: 5.651e-05, eta: 3:48:59, time: 0.331, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1571, decode.loss_lovasz: 0.6566, decode.acc_seg: 91.8112, loss: 0.8136\n","2022-10-08 12:46:16,046 - mmseg - INFO - Iter [2630/45000]\tlr: 5.649e-05, eta: 3:48:55, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1338, decode.loss_lovasz: 0.5138, decode.acc_seg: 94.3713, loss: 0.6476\n","2022-10-08 12:46:19,257 - mmseg - INFO - Iter [2640/45000]\tlr: 5.648e-05, eta: 3:48:51, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1385, decode.loss_lovasz: 0.5954, decode.acc_seg: 94.6616, loss: 0.7339\n","2022-10-08 12:46:22,460 - mmseg - INFO - Iter [2650/45000]\tlr: 5.647e-05, eta: 3:48:48, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0659, decode.loss_lovasz: 0.5442, decode.acc_seg: 96.2309, loss: 0.6101\n","2022-10-08 12:46:25,665 - mmseg - INFO - Iter [2660/45000]\tlr: 5.645e-05, eta: 3:48:44, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1120, decode.loss_lovasz: 0.7189, decode.acc_seg: 94.8086, loss: 0.8309\n","2022-10-08 12:46:28,902 - mmseg - INFO - Iter [2670/45000]\tlr: 5.644e-05, eta: 3:48:40, time: 0.324, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1484, decode.loss_lovasz: 0.6483, decode.acc_seg: 93.7869, loss: 0.7967\n","2022-10-08 12:46:32,161 - mmseg - INFO - Iter [2680/45000]\tlr: 5.643e-05, eta: 3:48:37, time: 0.326, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0761, decode.loss_lovasz: 0.4980, decode.acc_seg: 95.8496, loss: 0.5742\n","2022-10-08 12:46:35,418 - mmseg - INFO - Iter [2690/45000]\tlr: 5.641e-05, eta: 3:48:34, time: 0.326, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1136, decode.loss_lovasz: 0.5462, decode.acc_seg: 95.2983, loss: 0.6599\n","2022-10-08 12:46:38,652 - mmseg - INFO - Iter [2700/45000]\tlr: 5.640e-05, eta: 3:48:31, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1138, decode.loss_lovasz: 0.5475, decode.acc_seg: 94.5766, loss: 0.6613\n","2022-10-08 12:46:41,864 - mmseg - INFO - Iter [2710/45000]\tlr: 5.639e-05, eta: 3:48:27, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1352, decode.loss_lovasz: 0.5512, decode.acc_seg: 94.2454, loss: 0.6864\n","2022-10-08 12:46:45,102 - mmseg - INFO - Iter [2720/45000]\tlr: 5.637e-05, eta: 3:48:24, time: 0.324, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0861, decode.loss_lovasz: 0.7846, decode.acc_seg: 94.7336, loss: 0.8707\n","2022-10-08 12:46:48,326 - mmseg - INFO - Iter [2730/45000]\tlr: 5.636e-05, eta: 3:48:21, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1109, decode.loss_lovasz: 0.4872, decode.acc_seg: 95.2019, loss: 0.5981\n","2022-10-08 12:46:51,550 - mmseg - INFO - Iter [2740/45000]\tlr: 5.635e-05, eta: 3:48:17, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1258, decode.loss_lovasz: 0.5021, decode.acc_seg: 93.9323, loss: 0.6279\n","2022-10-08 12:46:54,765 - mmseg - INFO - Iter [2750/45000]\tlr: 5.633e-05, eta: 3:48:13, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0482, decode.loss_lovasz: 0.4331, decode.acc_seg: 97.1724, loss: 0.4813\n","2022-10-08 12:46:57,984 - mmseg - INFO - Iter [2760/45000]\tlr: 5.632e-05, eta: 3:48:10, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0935, decode.loss_lovasz: 0.5009, decode.acc_seg: 95.5217, loss: 0.5945\n","2022-10-08 12:47:01,231 - mmseg - INFO - Iter [2770/45000]\tlr: 5.631e-05, eta: 3:48:07, time: 0.325, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1044, decode.loss_lovasz: 0.6779, decode.acc_seg: 94.2552, loss: 0.7823\n","2022-10-08 12:47:04,432 - mmseg - INFO - Iter [2780/45000]\tlr: 5.629e-05, eta: 3:48:03, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0653, decode.loss_lovasz: 0.3388, decode.acc_seg: 96.5206, loss: 0.4042\n","2022-10-08 12:47:07,651 - mmseg - INFO - Iter [2790/45000]\tlr: 5.628e-05, eta: 3:47:59, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0813, decode.loss_lovasz: 0.3907, decode.acc_seg: 96.2085, loss: 0.4720\n","2022-10-08 12:47:10,880 - mmseg - INFO - Iter [2800/45000]\tlr: 5.627e-05, eta: 3:47:56, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1279, decode.loss_lovasz: 0.5987, decode.acc_seg: 94.0123, loss: 0.7266\n","2022-10-08 12:47:14,116 - mmseg - INFO - Iter [2810/45000]\tlr: 5.625e-05, eta: 3:47:53, time: 0.324, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1296, decode.loss_lovasz: 0.5345, decode.acc_seg: 94.1278, loss: 0.6641\n","2022-10-08 12:47:17,357 - mmseg - INFO - Iter [2820/45000]\tlr: 5.624e-05, eta: 3:47:49, time: 0.324, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1544, decode.loss_lovasz: 0.5006, decode.acc_seg: 93.6691, loss: 0.6550\n","2022-10-08 12:47:20,587 - mmseg - INFO - Iter [2830/45000]\tlr: 5.623e-05, eta: 3:47:46, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1646, decode.loss_lovasz: 0.6241, decode.acc_seg: 91.7724, loss: 0.7887\n","2022-10-08 12:47:23,824 - mmseg - INFO - Iter [2840/45000]\tlr: 5.621e-05, eta: 3:47:43, time: 0.324, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0991, decode.loss_lovasz: 0.5673, decode.acc_seg: 95.7459, loss: 0.6665\n","2022-10-08 12:47:27,027 - mmseg - INFO - Iter [2850/45000]\tlr: 5.620e-05, eta: 3:47:39, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0791, decode.loss_lovasz: 0.5374, decode.acc_seg: 96.1803, loss: 0.6166\n","2022-10-08 12:47:30,233 - mmseg - INFO - Iter [2860/45000]\tlr: 5.619e-05, eta: 3:47:35, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1165, decode.loss_lovasz: 0.5701, decode.acc_seg: 94.0193, loss: 0.6866\n","2022-10-08 12:47:33,439 - mmseg - INFO - Iter [2870/45000]\tlr: 5.617e-05, eta: 3:47:31, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1067, decode.loss_lovasz: 0.6915, decode.acc_seg: 94.2917, loss: 0.7982\n","2022-10-08 12:47:36,651 - mmseg - INFO - Iter [2880/45000]\tlr: 5.616e-05, eta: 3:47:28, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0630, decode.loss_lovasz: 0.3921, decode.acc_seg: 96.9576, loss: 0.4551\n","2022-10-08 12:47:39,892 - mmseg - INFO - Iter [2890/45000]\tlr: 5.615e-05, eta: 3:47:24, time: 0.324, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0995, decode.loss_lovasz: 0.5445, decode.acc_seg: 94.7807, loss: 0.6440\n","2022-10-08 12:47:43,134 - mmseg - INFO - Iter [2900/45000]\tlr: 5.613e-05, eta: 3:47:21, time: 0.324, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0781, decode.loss_lovasz: 0.5393, decode.acc_seg: 94.9264, loss: 0.6174\n","2022-10-08 12:47:46,341 - mmseg - INFO - Iter [2910/45000]\tlr: 5.612e-05, eta: 3:47:17, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1606, decode.loss_lovasz: 0.4894, decode.acc_seg: 94.2792, loss: 0.6500\n","2022-10-08 12:47:49,563 - mmseg - INFO - Iter [2920/45000]\tlr: 5.611e-05, eta: 3:47:14, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1112, decode.loss_lovasz: 0.3951, decode.acc_seg: 95.3258, loss: 0.5062\n","2022-10-08 12:47:52,775 - mmseg - INFO - Iter [2930/45000]\tlr: 5.609e-05, eta: 3:47:10, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0977, decode.loss_lovasz: 0.4600, decode.acc_seg: 96.0209, loss: 0.5577\n","2022-10-08 12:47:55,995 - mmseg - INFO - Iter [2940/45000]\tlr: 5.608e-05, eta: 3:47:07, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0877, decode.loss_lovasz: 0.4236, decode.acc_seg: 96.4184, loss: 0.5113\n","2022-10-08 12:47:59,216 - mmseg - INFO - Iter [2950/45000]\tlr: 5.607e-05, eta: 3:47:03, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1174, decode.loss_lovasz: 0.5353, decode.acc_seg: 94.9019, loss: 0.6528\n","2022-10-08 12:48:02,439 - mmseg - INFO - Iter [2960/45000]\tlr: 5.605e-05, eta: 3:47:00, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1004, decode.loss_lovasz: 0.3602, decode.acc_seg: 95.7005, loss: 0.4606\n","2022-10-08 12:48:05,661 - mmseg - INFO - Iter [2970/45000]\tlr: 5.604e-05, eta: 3:46:56, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1553, decode.loss_lovasz: 0.6530, decode.acc_seg: 93.5040, loss: 0.8083\n","2022-10-08 12:48:08,881 - mmseg - INFO - Iter [2980/45000]\tlr: 5.603e-05, eta: 3:46:53, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0954, decode.loss_lovasz: 0.4140, decode.acc_seg: 95.6423, loss: 0.5095\n","2022-10-08 12:48:12,096 - mmseg - INFO - Iter [2990/45000]\tlr: 5.601e-05, eta: 3:46:49, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1058, decode.loss_lovasz: 0.4893, decode.acc_seg: 95.5528, loss: 0.5951\n","2022-10-08 12:48:15,291 - mmseg - INFO - Exp name: segformer_mit-b4_960.py\n","2022-10-08 12:48:15,291 - mmseg - INFO - Iter [3000/45000]\tlr: 5.600e-05, eta: 3:46:45, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1170, decode.loss_lovasz: 0.3736, decode.acc_seg: 96.2512, loss: 0.4906\n","[>>] 71/71, 6.3 task/s, elapsed: 11s, ETA:     0sexcuting <total_intersect_and_union>\n","\u001b[31\n","per_img_mdice:tensor([0.9836, 0.8514], dtype=torch.float64)\u001b[39m\n","2022-10-08 12:48:30,324 - mmseg - INFO - per class results:\n","2022-10-08 12:48:30,326 - mmseg - INFO - \n","+------------+-------+-------+-------+\n","|   Class    |  Dice |  Acc  |  IoU  |\n","+------------+-------+-------+-------+\n","| background | 98.36 | 98.19 | 96.97 |\n","|    cell    | 85.14 | 90.09 | 78.81 |\n","+------------+-------+-------+-------+\n","2022-10-08 12:48:30,326 - mmseg - INFO - Summary:\n","2022-10-08 12:48:30,326 - mmseg - INFO - \n","+-------+-------+-------+-------+\n","|  aAcc | mDice |  mAcc |  mIoU |\n","+-------+-------+-------+-------+\n","| 97.27 | 91.75 | 94.14 | 87.89 |\n","+-------+-------+-------+-------+\n","2022-10-08 12:48:30,327 - mmseg - INFO - Exp name: segformer_mit-b4_960.py\n","2022-10-08 12:48:30,327 - mmseg - INFO - Iter(val) [71]\taAcc: 0.9727, mDice: 0.9175, mAcc: 0.9414, mIoU: 0.8789, Dice.background: 0.9836, Dice.cell: 0.8514, Acc.background: 0.9819, Acc.cell: 0.9009, IoU.background: 0.9697, IoU.cell: 0.7881\n","2022-10-08 12:48:33,561 - mmseg - INFO - Iter [3010/45000]\tlr: 5.599e-05, eta: 3:50:12, time: 1.827, data_time: 1.509, memory: 24005, decode.loss_ce: 0.1022, decode.loss_lovasz: 0.4754, decode.acc_seg: 96.2094, loss: 0.5776\n","2022-10-08 12:48:36,759 - mmseg - INFO - Iter [3020/45000]\tlr: 5.597e-05, eta: 3:50:07, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2344, decode.loss_lovasz: 0.6707, decode.acc_seg: 91.8517, loss: 0.9051\n","2022-10-08 12:48:39,990 - mmseg - INFO - Iter [3030/45000]\tlr: 5.596e-05, eta: 3:50:03, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1266, decode.loss_lovasz: 0.6786, decode.acc_seg: 93.8571, loss: 0.8051\n","2022-10-08 12:48:43,206 - mmseg - INFO - Iter [3040/45000]\tlr: 5.595e-05, eta: 3:49:59, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1595, decode.loss_lovasz: 0.7561, decode.acc_seg: 92.4824, loss: 0.9156\n","2022-10-08 12:48:46,437 - mmseg - INFO - Iter [3050/45000]\tlr: 5.593e-05, eta: 3:49:55, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0830, decode.loss_lovasz: 0.4047, decode.acc_seg: 95.8895, loss: 0.4877\n","2022-10-08 12:48:49,648 - mmseg - INFO - Iter [3060/45000]\tlr: 5.592e-05, eta: 3:49:50, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1918, decode.loss_lovasz: 0.6521, decode.acc_seg: 93.7827, loss: 0.8439\n","2022-10-08 12:48:52,898 - mmseg - INFO - Iter [3070/45000]\tlr: 5.591e-05, eta: 3:49:47, time: 0.325, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1394, decode.loss_lovasz: 0.5529, decode.acc_seg: 94.5371, loss: 0.6923\n","2022-10-08 12:48:56,131 - mmseg - INFO - Iter [3080/45000]\tlr: 5.589e-05, eta: 3:49:43, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1107, decode.loss_lovasz: 0.6965, decode.acc_seg: 95.2224, loss: 0.8072\n","2022-10-08 12:48:59,340 - mmseg - INFO - Iter [3090/45000]\tlr: 5.588e-05, eta: 3:49:38, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1646, decode.loss_lovasz: 0.7963, decode.acc_seg: 93.0003, loss: 0.9609\n","2022-10-08 12:49:02,565 - mmseg - INFO - Iter [3100/45000]\tlr: 5.587e-05, eta: 3:49:34, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1176, decode.loss_lovasz: 0.6898, decode.acc_seg: 93.6539, loss: 0.8074\n","2022-10-08 12:49:05,771 - mmseg - INFO - Iter [3110/45000]\tlr: 5.585e-05, eta: 3:49:30, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1149, decode.loss_lovasz: 0.5962, decode.acc_seg: 94.8586, loss: 0.7111\n","2022-10-08 12:49:08,978 - mmseg - INFO - Iter [3120/45000]\tlr: 5.584e-05, eta: 3:49:25, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1289, decode.loss_lovasz: 0.6735, decode.acc_seg: 94.2685, loss: 0.8024\n","2022-10-08 12:49:12,181 - mmseg - INFO - Iter [3130/45000]\tlr: 5.583e-05, eta: 3:49:21, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1324, decode.loss_lovasz: 0.6069, decode.acc_seg: 94.6820, loss: 0.7393\n","2022-10-08 12:49:15,430 - mmseg - INFO - Iter [3140/45000]\tlr: 5.581e-05, eta: 3:49:17, time: 0.325, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1428, decode.loss_lovasz: 0.6016, decode.acc_seg: 93.6425, loss: 0.7444\n","2022-10-08 12:49:18,656 - mmseg - INFO - Iter [3150/45000]\tlr: 5.580e-05, eta: 3:49:13, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0802, decode.loss_lovasz: 0.4110, decode.acc_seg: 96.6491, loss: 0.4912\n","2022-10-08 12:49:21,893 - mmseg - INFO - Iter [3160/45000]\tlr: 5.579e-05, eta: 3:49:09, time: 0.324, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1072, decode.loss_lovasz: 0.5892, decode.acc_seg: 94.4001, loss: 0.6964\n","2022-10-08 12:49:25,079 - mmseg - INFO - Iter [3170/45000]\tlr: 5.577e-05, eta: 3:49:04, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0522, decode.loss_lovasz: 0.3544, decode.acc_seg: 97.6289, loss: 0.4066\n","2022-10-08 12:49:28,284 - mmseg - INFO - Iter [3180/45000]\tlr: 5.576e-05, eta: 3:49:00, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0811, decode.loss_lovasz: 0.5596, decode.acc_seg: 96.1194, loss: 0.6407\n","2022-10-08 12:49:31,484 - mmseg - INFO - Iter [3190/45000]\tlr: 5.575e-05, eta: 3:48:56, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1685, decode.loss_lovasz: 0.6930, decode.acc_seg: 92.3532, loss: 0.8615\n","2022-10-08 12:49:34,702 - mmseg - INFO - Iter [3200/45000]\tlr: 5.573e-05, eta: 3:48:52, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0768, decode.loss_lovasz: 0.3940, decode.acc_seg: 96.7455, loss: 0.4708\n","2022-10-08 12:49:37,899 - mmseg - INFO - Iter [3210/45000]\tlr: 5.572e-05, eta: 3:48:47, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0878, decode.loss_lovasz: 0.4694, decode.acc_seg: 96.0793, loss: 0.5572\n","2022-10-08 12:49:41,120 - mmseg - INFO - Iter [3220/45000]\tlr: 5.571e-05, eta: 3:48:43, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1027, decode.loss_lovasz: 0.4934, decode.acc_seg: 94.0601, loss: 0.5961\n","2022-10-08 12:49:44,331 - mmseg - INFO - Iter [3230/45000]\tlr: 5.569e-05, eta: 3:48:39, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1067, decode.loss_lovasz: 0.4232, decode.acc_seg: 95.1997, loss: 0.5299\n","2022-10-08 12:49:47,545 - mmseg - INFO - Iter [3240/45000]\tlr: 5.568e-05, eta: 3:48:35, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1107, decode.loss_lovasz: 0.4405, decode.acc_seg: 95.0193, loss: 0.5513\n","2022-10-08 12:49:50,768 - mmseg - INFO - Iter [3250/45000]\tlr: 5.567e-05, eta: 3:48:30, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1003, decode.loss_lovasz: 0.4317, decode.acc_seg: 95.8844, loss: 0.5320\n","2022-10-08 12:49:53,976 - mmseg - INFO - Iter [3260/45000]\tlr: 5.565e-05, eta: 3:48:26, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1170, decode.loss_lovasz: 0.6458, decode.acc_seg: 94.6559, loss: 0.7627\n","2022-10-08 12:49:57,186 - mmseg - INFO - Iter [3270/45000]\tlr: 5.564e-05, eta: 3:48:22, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1882, decode.loss_lovasz: 0.7106, decode.acc_seg: 92.5657, loss: 0.8989\n","2022-10-08 12:50:00,396 - mmseg - INFO - Iter [3280/45000]\tlr: 5.563e-05, eta: 3:48:18, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1080, decode.loss_lovasz: 0.4778, decode.acc_seg: 94.6486, loss: 0.5858\n","2022-10-08 12:50:03,628 - mmseg - INFO - Iter [3290/45000]\tlr: 5.561e-05, eta: 3:48:14, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1194, decode.loss_lovasz: 0.6707, decode.acc_seg: 94.4621, loss: 0.7902\n","2022-10-08 12:50:06,857 - mmseg - INFO - Iter [3300/45000]\tlr: 5.560e-05, eta: 3:48:10, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0796, decode.loss_lovasz: 0.3625, decode.acc_seg: 96.9513, loss: 0.4422\n","2022-10-08 12:50:10,071 - mmseg - INFO - Iter [3310/45000]\tlr: 5.559e-05, eta: 3:48:06, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1306, decode.loss_lovasz: 0.5793, decode.acc_seg: 94.3541, loss: 0.7099\n","2022-10-08 12:50:13,267 - mmseg - INFO - Iter [3320/45000]\tlr: 5.557e-05, eta: 3:48:01, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1343, decode.loss_lovasz: 0.6330, decode.acc_seg: 94.2034, loss: 0.7673\n","2022-10-08 12:50:16,457 - mmseg - INFO - Iter [3330/45000]\tlr: 5.556e-05, eta: 3:47:57, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1683, decode.loss_lovasz: 0.5001, decode.acc_seg: 93.9458, loss: 0.6684\n","2022-10-08 12:50:19,655 - mmseg - INFO - Iter [3340/45000]\tlr: 5.555e-05, eta: 3:47:53, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1468, decode.loss_lovasz: 0.5299, decode.acc_seg: 93.0377, loss: 0.6767\n","2022-10-08 12:50:22,889 - mmseg - INFO - Iter [3350/45000]\tlr: 5.553e-05, eta: 3:47:49, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1016, decode.loss_lovasz: 0.5684, decode.acc_seg: 95.0929, loss: 0.6701\n","2022-10-08 12:50:26,116 - mmseg - INFO - Iter [3360/45000]\tlr: 5.552e-05, eta: 3:47:45, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2408, decode.loss_lovasz: 0.7302, decode.acc_seg: 91.6558, loss: 0.9710\n","2022-10-08 12:50:29,307 - mmseg - INFO - Iter [3370/45000]\tlr: 5.551e-05, eta: 3:47:40, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0909, decode.loss_lovasz: 0.5661, decode.acc_seg: 96.1340, loss: 0.6570\n","2022-10-08 12:50:32,503 - mmseg - INFO - Iter [3380/45000]\tlr: 5.549e-05, eta: 3:47:36, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0430, decode.loss_lovasz: 0.4043, decode.acc_seg: 97.4728, loss: 0.4473\n","2022-10-08 12:50:35,705 - mmseg - INFO - Iter [3390/45000]\tlr: 5.548e-05, eta: 3:47:32, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0864, decode.loss_lovasz: 0.4000, decode.acc_seg: 96.0345, loss: 0.4864\n","2022-10-08 12:50:38,934 - mmseg - INFO - Iter [3400/45000]\tlr: 5.547e-05, eta: 3:47:28, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0940, decode.loss_lovasz: 0.4194, decode.acc_seg: 95.8200, loss: 0.5133\n","2022-10-08 12:50:42,142 - mmseg - INFO - Iter [3410/45000]\tlr: 5.545e-05, eta: 3:47:24, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1138, decode.loss_lovasz: 0.5153, decode.acc_seg: 95.1904, loss: 0.6291\n","2022-10-08 12:50:45,330 - mmseg - INFO - Iter [3420/45000]\tlr: 5.544e-05, eta: 3:47:19, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1072, decode.loss_lovasz: 0.5278, decode.acc_seg: 95.1366, loss: 0.6350\n","2022-10-08 12:50:48,541 - mmseg - INFO - Iter [3430/45000]\tlr: 5.543e-05, eta: 3:47:15, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1047, decode.loss_lovasz: 0.5877, decode.acc_seg: 95.4386, loss: 0.6924\n","2022-10-08 12:50:51,759 - mmseg - INFO - Iter [3440/45000]\tlr: 5.541e-05, eta: 3:47:11, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0660, decode.loss_lovasz: 0.5411, decode.acc_seg: 96.8794, loss: 0.6071\n","2022-10-08 12:50:54,956 - mmseg - INFO - Iter [3450/45000]\tlr: 5.540e-05, eta: 3:47:07, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1184, decode.loss_lovasz: 0.4848, decode.acc_seg: 96.0341, loss: 0.6032\n","2022-10-08 12:50:58,169 - mmseg - INFO - Iter [3460/45000]\tlr: 5.539e-05, eta: 3:47:03, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1329, decode.loss_lovasz: 0.6182, decode.acc_seg: 94.9989, loss: 0.7511\n","2022-10-08 12:51:01,378 - mmseg - INFO - Iter [3470/45000]\tlr: 5.537e-05, eta: 3:46:59, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0856, decode.loss_lovasz: 0.3423, decode.acc_seg: 96.1686, loss: 0.4278\n","2022-10-08 12:51:04,569 - mmseg - INFO - Iter [3480/45000]\tlr: 5.536e-05, eta: 3:46:54, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.2528, decode.loss_lovasz: 0.7082, decode.acc_seg: 91.6874, loss: 0.9610\n","2022-10-08 12:51:07,798 - mmseg - INFO - Iter [3490/45000]\tlr: 5.535e-05, eta: 3:46:50, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0860, decode.loss_lovasz: 0.5401, decode.acc_seg: 95.8321, loss: 0.6262\n","2022-10-08 12:51:11,004 - mmseg - INFO - Iter [3500/45000]\tlr: 5.533e-05, eta: 3:46:46, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1307, decode.loss_lovasz: 0.5696, decode.acc_seg: 93.6838, loss: 0.7003\n","2022-10-08 12:51:14,217 - mmseg - INFO - Iter [3510/45000]\tlr: 5.532e-05, eta: 3:46:42, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0839, decode.loss_lovasz: 0.6070, decode.acc_seg: 95.5963, loss: 0.6908\n","2022-10-08 12:51:17,453 - mmseg - INFO - Iter [3520/45000]\tlr: 5.531e-05, eta: 3:46:38, time: 0.324, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1212, decode.loss_lovasz: 0.4990, decode.acc_seg: 94.4278, loss: 0.6202\n","2022-10-08 12:51:20,675 - mmseg - INFO - Iter [3530/45000]\tlr: 5.529e-05, eta: 3:46:34, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0503, decode.loss_lovasz: 0.4334, decode.acc_seg: 97.9486, loss: 0.4837\n","2022-10-08 12:51:23,892 - mmseg - INFO - Iter [3540/45000]\tlr: 5.528e-05, eta: 3:46:30, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1250, decode.loss_lovasz: 0.5982, decode.acc_seg: 94.8278, loss: 0.7232\n","2022-10-08 12:51:27,088 - mmseg - INFO - Iter [3550/45000]\tlr: 5.527e-05, eta: 3:46:26, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1226, decode.loss_lovasz: 0.5369, decode.acc_seg: 94.9102, loss: 0.6595\n","2022-10-08 12:51:30,297 - mmseg - INFO - Iter [3560/45000]\tlr: 5.525e-05, eta: 3:46:22, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1099, decode.loss_lovasz: 0.5737, decode.acc_seg: 95.0181, loss: 0.6836\n","2022-10-08 12:51:33,506 - mmseg - INFO - Iter [3570/45000]\tlr: 5.524e-05, eta: 3:46:18, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1053, decode.loss_lovasz: 0.4822, decode.acc_seg: 96.0508, loss: 0.5874\n","2022-10-08 12:51:36,760 - mmseg - INFO - Iter [3580/45000]\tlr: 5.523e-05, eta: 3:46:15, time: 0.325, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1010, decode.loss_lovasz: 0.5667, decode.acc_seg: 95.4490, loss: 0.6677\n","2022-10-08 12:51:39,978 - mmseg - INFO - Iter [3590/45000]\tlr: 5.521e-05, eta: 3:46:11, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0775, decode.loss_lovasz: 0.3864, decode.acc_seg: 96.4965, loss: 0.4639\n","2022-10-08 12:51:43,188 - mmseg - INFO - Iter [3600/45000]\tlr: 5.520e-05, eta: 3:46:07, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0753, decode.loss_lovasz: 0.3685, decode.acc_seg: 96.3093, loss: 0.4438\n","2022-10-08 12:51:46,390 - mmseg - INFO - Iter [3610/45000]\tlr: 5.519e-05, eta: 3:46:02, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0951, decode.loss_lovasz: 0.4030, decode.acc_seg: 96.0436, loss: 0.4980\n","2022-10-08 12:51:49,600 - mmseg - INFO - Iter [3620/45000]\tlr: 5.517e-05, eta: 3:45:58, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1038, decode.loss_lovasz: 0.3928, decode.acc_seg: 96.3164, loss: 0.4965\n","2022-10-08 12:51:52,796 - mmseg - INFO - Iter [3630/45000]\tlr: 5.516e-05, eta: 3:45:54, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0665, decode.loss_lovasz: 0.4274, decode.acc_seg: 96.9430, loss: 0.4938\n","2022-10-08 12:51:55,996 - mmseg - INFO - Iter [3640/45000]\tlr: 5.515e-05, eta: 3:45:50, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0837, decode.loss_lovasz: 0.4662, decode.acc_seg: 96.0910, loss: 0.5499\n","2022-10-08 12:51:59,189 - mmseg - INFO - Iter [3650/45000]\tlr: 5.513e-05, eta: 3:45:46, time: 0.319, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0938, decode.loss_lovasz: 0.5487, decode.acc_seg: 96.0868, loss: 0.6425\n","2022-10-08 12:52:02,573 - mmseg - INFO - Iter [3660/45000]\tlr: 5.512e-05, eta: 3:45:44, time: 0.338, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0911, decode.loss_lovasz: 0.4092, decode.acc_seg: 96.5888, loss: 0.5002\n","2022-10-08 12:52:05,773 - mmseg - INFO - Iter [3670/45000]\tlr: 5.511e-05, eta: 3:45:40, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1057, decode.loss_lovasz: 0.5644, decode.acc_seg: 95.2807, loss: 0.6701\n","2022-10-08 12:52:08,978 - mmseg - INFO - Iter [3680/45000]\tlr: 5.509e-05, eta: 3:45:35, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0924, decode.loss_lovasz: 0.4094, decode.acc_seg: 95.6655, loss: 0.5018\n","2022-10-08 12:52:12,200 - mmseg - INFO - Iter [3690/45000]\tlr: 5.508e-05, eta: 3:45:32, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1433, decode.loss_lovasz: 0.6095, decode.acc_seg: 93.5229, loss: 0.7528\n","2022-10-08 12:52:15,441 - mmseg - INFO - Iter [3700/45000]\tlr: 5.507e-05, eta: 3:45:28, time: 0.324, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0645, decode.loss_lovasz: 0.3666, decode.acc_seg: 96.5490, loss: 0.4311\n","2022-10-08 12:52:18,659 - mmseg - INFO - Iter [3710/45000]\tlr: 5.505e-05, eta: 3:45:24, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1354, decode.loss_lovasz: 0.5105, decode.acc_seg: 94.6719, loss: 0.6459\n","2022-10-08 12:52:21,873 - mmseg - INFO - Iter [3720/45000]\tlr: 5.504e-05, eta: 3:45:20, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1077, decode.loss_lovasz: 0.5921, decode.acc_seg: 94.9820, loss: 0.6998\n","2022-10-08 12:52:25,076 - mmseg - INFO - Iter [3730/45000]\tlr: 5.503e-05, eta: 3:45:16, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1192, decode.loss_lovasz: 0.4812, decode.acc_seg: 95.0726, loss: 0.6004\n","2022-10-08 12:52:28,270 - mmseg - INFO - Iter [3740/45000]\tlr: 5.501e-05, eta: 3:45:12, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1450, decode.loss_lovasz: 0.5009, decode.acc_seg: 94.3837, loss: 0.6460\n","2022-10-08 12:52:31,480 - mmseg - INFO - Iter [3750/45000]\tlr: 5.500e-05, eta: 3:45:08, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1444, decode.loss_lovasz: 0.5168, decode.acc_seg: 94.7988, loss: 0.6612\n","2022-10-08 12:52:34,693 - mmseg - INFO - Iter [3760/45000]\tlr: 5.499e-05, eta: 3:45:04, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1913, decode.loss_lovasz: 0.6864, decode.acc_seg: 92.1238, loss: 0.8778\n","2022-10-08 12:52:37,905 - mmseg - INFO - Iter [3770/45000]\tlr: 5.497e-05, eta: 3:45:00, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1007, decode.loss_lovasz: 0.5609, decode.acc_seg: 94.7295, loss: 0.6616\n","2022-10-08 12:52:41,111 - mmseg - INFO - Iter [3780/45000]\tlr: 5.496e-05, eta: 3:44:56, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1214, decode.loss_lovasz: 0.6964, decode.acc_seg: 94.1811, loss: 0.8179\n","2022-10-08 12:52:44,329 - mmseg - INFO - Iter [3790/45000]\tlr: 5.495e-05, eta: 3:44:52, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.2182, decode.loss_lovasz: 0.8233, decode.acc_seg: 92.0354, loss: 1.0415\n","2022-10-08 12:52:47,542 - mmseg - INFO - Iter [3800/45000]\tlr: 5.493e-05, eta: 3:44:48, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0756, decode.loss_lovasz: 0.4595, decode.acc_seg: 95.9074, loss: 0.5350\n","2022-10-08 12:52:50,756 - mmseg - INFO - Iter [3810/45000]\tlr: 5.492e-05, eta: 3:44:44, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1442, decode.loss_lovasz: 0.6502, decode.acc_seg: 93.3959, loss: 0.7944\n","2022-10-08 12:52:53,980 - mmseg - INFO - Iter [3820/45000]\tlr: 5.491e-05, eta: 3:44:40, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0638, decode.loss_lovasz: 0.3877, decode.acc_seg: 97.2078, loss: 0.4516\n","2022-10-08 12:52:57,201 - mmseg - INFO - Iter [3830/45000]\tlr: 5.489e-05, eta: 3:44:37, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1364, decode.loss_lovasz: 0.5752, decode.acc_seg: 94.3968, loss: 0.7117\n","2022-10-08 12:53:00,425 - mmseg - INFO - Iter [3840/45000]\tlr: 5.488e-05, eta: 3:44:33, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1057, decode.loss_lovasz: 0.4952, decode.acc_seg: 95.1532, loss: 0.6009\n","2022-10-08 12:53:03,672 - mmseg - INFO - Iter [3850/45000]\tlr: 5.487e-05, eta: 3:44:29, time: 0.325, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0575, decode.loss_lovasz: 0.3370, decode.acc_seg: 97.2773, loss: 0.3945\n","2022-10-08 12:53:06,880 - mmseg - INFO - Iter [3860/45000]\tlr: 5.485e-05, eta: 3:44:25, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1495, decode.loss_lovasz: 0.5409, decode.acc_seg: 94.5152, loss: 0.6903\n","2022-10-08 12:53:10,090 - mmseg - INFO - Iter [3870/45000]\tlr: 5.484e-05, eta: 3:44:21, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0793, decode.loss_lovasz: 0.6160, decode.acc_seg: 96.1068, loss: 0.6954\n","2022-10-08 12:53:13,324 - mmseg - INFO - Iter [3880/45000]\tlr: 5.483e-05, eta: 3:44:18, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0736, decode.loss_lovasz: 0.3919, decode.acc_seg: 97.4487, loss: 0.4655\n","2022-10-08 12:53:16,540 - mmseg - INFO - Iter [3890/45000]\tlr: 5.481e-05, eta: 3:44:14, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0763, decode.loss_lovasz: 0.3947, decode.acc_seg: 96.9650, loss: 0.4709\n","2022-10-08 12:53:19,746 - mmseg - INFO - Iter [3900/45000]\tlr: 5.480e-05, eta: 3:44:10, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1043, decode.loss_lovasz: 0.5924, decode.acc_seg: 94.9436, loss: 0.6967\n","2022-10-08 12:53:22,946 - mmseg - INFO - Iter [3910/45000]\tlr: 5.479e-05, eta: 3:44:06, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1832, decode.loss_lovasz: 0.6383, decode.acc_seg: 93.3292, loss: 0.8215\n","2022-10-08 12:53:26,162 - mmseg - INFO - Iter [3920/45000]\tlr: 5.477e-05, eta: 3:44:02, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1173, decode.loss_lovasz: 0.4691, decode.acc_seg: 95.9017, loss: 0.5864\n","2022-10-08 12:53:29,395 - mmseg - INFO - Iter [3930/45000]\tlr: 5.476e-05, eta: 3:43:58, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0873, decode.loss_lovasz: 0.6153, decode.acc_seg: 96.6402, loss: 0.7026\n","2022-10-08 12:53:32,603 - mmseg - INFO - Iter [3940/45000]\tlr: 5.475e-05, eta: 3:43:54, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0731, decode.loss_lovasz: 0.5165, decode.acc_seg: 96.2750, loss: 0.5896\n","2022-10-08 12:53:35,815 - mmseg - INFO - Iter [3950/45000]\tlr: 5.473e-05, eta: 3:43:50, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.3203, decode.loss_lovasz: 0.6349, decode.acc_seg: 90.6564, loss: 0.9552\n","2022-10-08 12:53:39,047 - mmseg - INFO - Iter [3960/45000]\tlr: 5.472e-05, eta: 3:43:47, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0856, decode.loss_lovasz: 0.5482, decode.acc_seg: 95.6900, loss: 0.6338\n","2022-10-08 12:53:42,258 - mmseg - INFO - Iter [3970/45000]\tlr: 5.471e-05, eta: 3:43:43, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0810, decode.loss_lovasz: 0.3652, decode.acc_seg: 96.3705, loss: 0.4462\n","2022-10-08 12:53:45,469 - mmseg - INFO - Iter [3980/45000]\tlr: 5.469e-05, eta: 3:43:39, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1045, decode.loss_lovasz: 0.4843, decode.acc_seg: 96.0034, loss: 0.5888\n","2022-10-08 12:53:48,688 - mmseg - INFO - Iter [3990/45000]\tlr: 5.468e-05, eta: 3:43:35, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0485, decode.loss_lovasz: 0.3680, decode.acc_seg: 97.3904, loss: 0.4166\n","2022-10-08 12:53:51,878 - mmseg - INFO - Exp name: segformer_mit-b4_960.py\n","2022-10-08 12:53:51,878 - mmseg - INFO - Iter [4000/45000]\tlr: 5.467e-05, eta: 3:43:31, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1010, decode.loss_lovasz: 0.6230, decode.acc_seg: 94.5018, loss: 0.7240\n","2022-10-08 12:53:55,090 - mmseg - INFO - Iter [4010/45000]\tlr: 5.465e-05, eta: 3:43:27, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1809, decode.loss_lovasz: 0.5788, decode.acc_seg: 93.0677, loss: 0.7597\n","2022-10-08 12:53:58,287 - mmseg - INFO - Iter [4020/45000]\tlr: 5.464e-05, eta: 3:43:23, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1720, decode.loss_lovasz: 0.5131, decode.acc_seg: 93.6221, loss: 0.6851\n","2022-10-08 12:54:01,515 - mmseg - INFO - Iter [4030/45000]\tlr: 5.463e-05, eta: 3:43:19, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0895, decode.loss_lovasz: 0.7195, decode.acc_seg: 95.7145, loss: 0.8090\n","2022-10-08 12:54:04,715 - mmseg - INFO - Iter [4040/45000]\tlr: 5.461e-05, eta: 3:43:15, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0884, decode.loss_lovasz: 0.3713, decode.acc_seg: 96.2429, loss: 0.4597\n","2022-10-08 12:54:10,424 - mmseg - INFO - Iter [4050/45000]\tlr: 5.460e-05, eta: 3:43:37, time: 0.571, data_time: 0.256, memory: 24005, decode.loss_ce: 0.1467, decode.loss_lovasz: 0.6115, decode.acc_seg: 94.4801, loss: 0.7582\n","2022-10-08 12:54:13,653 - mmseg - INFO - Iter [4060/45000]\tlr: 5.459e-05, eta: 3:43:33, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0697, decode.loss_lovasz: 0.4195, decode.acc_seg: 96.1791, loss: 0.4893\n","2022-10-08 12:54:16,890 - mmseg - INFO - Iter [4070/45000]\tlr: 5.457e-05, eta: 3:43:29, time: 0.324, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1549, decode.loss_lovasz: 0.7069, decode.acc_seg: 94.3470, loss: 0.8619\n","2022-10-08 12:54:20,122 - mmseg - INFO - Iter [4080/45000]\tlr: 5.456e-05, eta: 3:43:26, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1515, decode.loss_lovasz: 0.6832, decode.acc_seg: 93.7416, loss: 0.8347\n","2022-10-08 12:54:23,335 - mmseg - INFO - Iter [4090/45000]\tlr: 5.455e-05, eta: 3:43:22, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1020, decode.loss_lovasz: 0.4110, decode.acc_seg: 95.7681, loss: 0.5130\n","2022-10-08 12:54:26,544 - mmseg - INFO - Iter [4100/45000]\tlr: 5.453e-05, eta: 3:43:18, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0754, decode.loss_lovasz: 0.4286, decode.acc_seg: 95.8127, loss: 0.5041\n","2022-10-08 12:54:29,738 - mmseg - INFO - Iter [4110/45000]\tlr: 5.452e-05, eta: 3:43:14, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1006, decode.loss_lovasz: 0.4343, decode.acc_seg: 95.8787, loss: 0.5348\n","2022-10-08 12:54:32,937 - mmseg - INFO - Iter [4120/45000]\tlr: 5.451e-05, eta: 3:43:10, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1124, decode.loss_lovasz: 0.4862, decode.acc_seg: 95.9782, loss: 0.5986\n","2022-10-08 12:54:36,131 - mmseg - INFO - Iter [4130/45000]\tlr: 5.449e-05, eta: 3:43:05, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0957, decode.loss_lovasz: 0.5066, decode.acc_seg: 95.6132, loss: 0.6023\n","2022-10-08 12:54:39,370 - mmseg - INFO - Iter [4140/45000]\tlr: 5.448e-05, eta: 3:43:02, time: 0.324, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1239, decode.loss_lovasz: 0.5953, decode.acc_seg: 95.6910, loss: 0.7192\n","2022-10-08 12:54:42,590 - mmseg - INFO - Iter [4150/45000]\tlr: 5.447e-05, eta: 3:42:58, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0784, decode.loss_lovasz: 0.4581, decode.acc_seg: 95.8074, loss: 0.5366\n","2022-10-08 12:54:45,826 - mmseg - INFO - Iter [4160/45000]\tlr: 5.445e-05, eta: 3:42:54, time: 0.324, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1214, decode.loss_lovasz: 0.5727, decode.acc_seg: 93.9033, loss: 0.6941\n","2022-10-08 12:54:49,024 - mmseg - INFO - Iter [4170/45000]\tlr: 5.444e-05, eta: 3:42:50, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1730, decode.loss_lovasz: 0.6084, decode.acc_seg: 93.3687, loss: 0.7815\n","2022-10-08 12:54:52,217 - mmseg - INFO - Iter [4180/45000]\tlr: 5.443e-05, eta: 3:42:46, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0745, decode.loss_lovasz: 0.4953, decode.acc_seg: 96.3594, loss: 0.5698\n","2022-10-08 12:54:55,415 - mmseg - INFO - Iter [4190/45000]\tlr: 5.441e-05, eta: 3:42:42, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1067, decode.loss_lovasz: 0.4928, decode.acc_seg: 95.0423, loss: 0.5995\n","2022-10-08 12:54:58,626 - mmseg - INFO - Iter [4200/45000]\tlr: 5.440e-05, eta: 3:42:38, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1546, decode.loss_lovasz: 0.5549, decode.acc_seg: 92.5478, loss: 0.7096\n","2022-10-08 12:55:01,853 - mmseg - INFO - Iter [4210/45000]\tlr: 5.439e-05, eta: 3:42:35, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0871, decode.loss_lovasz: 0.3842, decode.acc_seg: 95.9817, loss: 0.4712\n","2022-10-08 12:55:05,065 - mmseg - INFO - Iter [4220/45000]\tlr: 5.437e-05, eta: 3:42:31, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0874, decode.loss_lovasz: 0.6294, decode.acc_seg: 95.3992, loss: 0.7168\n","2022-10-08 12:55:08,259 - mmseg - INFO - Iter [4230/45000]\tlr: 5.436e-05, eta: 3:42:27, time: 0.319, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1135, decode.loss_lovasz: 0.4984, decode.acc_seg: 95.2122, loss: 0.6119\n","2022-10-08 12:55:11,461 - mmseg - INFO - Iter [4240/45000]\tlr: 5.435e-05, eta: 3:42:23, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1324, decode.loss_lovasz: 0.6713, decode.acc_seg: 92.9620, loss: 0.8036\n","2022-10-08 12:55:14,688 - mmseg - INFO - Iter [4250/45000]\tlr: 5.433e-05, eta: 3:42:19, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1068, decode.loss_lovasz: 0.5317, decode.acc_seg: 95.4198, loss: 0.6385\n","2022-10-08 12:55:17,897 - mmseg - INFO - Iter [4260/45000]\tlr: 5.432e-05, eta: 3:42:15, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1013, decode.loss_lovasz: 0.5265, decode.acc_seg: 94.9592, loss: 0.6277\n","2022-10-08 12:55:21,120 - mmseg - INFO - Iter [4270/45000]\tlr: 5.431e-05, eta: 3:42:11, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0725, decode.loss_lovasz: 0.4930, decode.acc_seg: 96.0162, loss: 0.5655\n","2022-10-08 12:55:24,333 - mmseg - INFO - Iter [4280/45000]\tlr: 5.429e-05, eta: 3:42:07, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1149, decode.loss_lovasz: 0.6650, decode.acc_seg: 93.2027, loss: 0.7799\n","2022-10-08 12:55:27,547 - mmseg - INFO - Iter [4290/45000]\tlr: 5.428e-05, eta: 3:42:04, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1059, decode.loss_lovasz: 0.6648, decode.acc_seg: 94.3040, loss: 0.7707\n","2022-10-08 12:55:30,737 - mmseg - INFO - Iter [4300/45000]\tlr: 5.427e-05, eta: 3:42:00, time: 0.319, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1074, decode.loss_lovasz: 0.3953, decode.acc_seg: 95.8287, loss: 0.5027\n","2022-10-08 12:55:33,932 - mmseg - INFO - Iter [4310/45000]\tlr: 5.425e-05, eta: 3:41:56, time: 0.319, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1146, decode.loss_lovasz: 0.5372, decode.acc_seg: 93.7061, loss: 0.6518\n","2022-10-08 12:55:37,137 - mmseg - INFO - Iter [4320/45000]\tlr: 5.424e-05, eta: 3:41:52, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1458, decode.loss_lovasz: 0.7425, decode.acc_seg: 94.1997, loss: 0.8882\n","2022-10-08 12:55:40,336 - mmseg - INFO - Iter [4330/45000]\tlr: 5.423e-05, eta: 3:41:48, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0851, decode.loss_lovasz: 0.6511, decode.acc_seg: 95.3701, loss: 0.7362\n","2022-10-08 12:55:43,549 - mmseg - INFO - Iter [4340/45000]\tlr: 5.421e-05, eta: 3:41:44, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0886, decode.loss_lovasz: 0.4236, decode.acc_seg: 95.2135, loss: 0.5122\n","2022-10-08 12:55:46,766 - mmseg - INFO - Iter [4350/45000]\tlr: 5.420e-05, eta: 3:41:40, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1168, decode.loss_lovasz: 0.7662, decode.acc_seg: 93.2267, loss: 0.8830\n","2022-10-08 12:55:49,978 - mmseg - INFO - Iter [4360/45000]\tlr: 5.419e-05, eta: 3:41:36, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1333, decode.loss_lovasz: 0.5078, decode.acc_seg: 94.6598, loss: 0.6411\n","2022-10-08 12:55:53,178 - mmseg - INFO - Iter [4370/45000]\tlr: 5.417e-05, eta: 3:41:32, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1958, decode.loss_lovasz: 0.5960, decode.acc_seg: 93.1297, loss: 0.7918\n","2022-10-08 12:55:56,396 - mmseg - INFO - Iter [4380/45000]\tlr: 5.416e-05, eta: 3:41:29, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0935, decode.loss_lovasz: 0.3784, decode.acc_seg: 96.3258, loss: 0.4719\n","2022-10-08 12:55:59,599 - mmseg - INFO - Iter [4390/45000]\tlr: 5.415e-05, eta: 3:41:25, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0784, decode.loss_lovasz: 0.4645, decode.acc_seg: 95.8970, loss: 0.5429\n","2022-10-08 12:56:02,802 - mmseg - INFO - Iter [4400/45000]\tlr: 5.413e-05, eta: 3:41:21, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0980, decode.loss_lovasz: 0.4783, decode.acc_seg: 95.4155, loss: 0.5762\n","2022-10-08 12:56:06,048 - mmseg - INFO - Iter [4410/45000]\tlr: 5.412e-05, eta: 3:41:17, time: 0.325, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1522, decode.loss_lovasz: 0.7456, decode.acc_seg: 92.5776, loss: 0.8978\n","2022-10-08 12:56:09,249 - mmseg - INFO - Iter [4420/45000]\tlr: 5.411e-05, eta: 3:41:13, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1185, decode.loss_lovasz: 0.5481, decode.acc_seg: 95.1559, loss: 0.6667\n","2022-10-08 12:56:12,457 - mmseg - INFO - Iter [4430/45000]\tlr: 5.409e-05, eta: 3:41:09, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1059, decode.loss_lovasz: 0.5698, decode.acc_seg: 96.2278, loss: 0.6757\n","2022-10-08 12:56:15,649 - mmseg - INFO - Iter [4440/45000]\tlr: 5.408e-05, eta: 3:41:06, time: 0.319, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1119, decode.loss_lovasz: 0.5905, decode.acc_seg: 94.3777, loss: 0.7024\n","2022-10-08 12:56:18,873 - mmseg - INFO - Iter [4450/45000]\tlr: 5.407e-05, eta: 3:41:02, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1025, decode.loss_lovasz: 0.4086, decode.acc_seg: 96.5428, loss: 0.5111\n","2022-10-08 12:56:22,087 - mmseg - INFO - Iter [4460/45000]\tlr: 5.405e-05, eta: 3:40:58, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1149, decode.loss_lovasz: 0.6189, decode.acc_seg: 95.2384, loss: 0.7338\n","2022-10-08 12:56:25,307 - mmseg - INFO - Iter [4470/45000]\tlr: 5.404e-05, eta: 3:40:54, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0752, decode.loss_lovasz: 0.3566, decode.acc_seg: 96.6206, loss: 0.4318\n","2022-10-08 12:56:28,521 - mmseg - INFO - Iter [4480/45000]\tlr: 5.403e-05, eta: 3:40:51, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1013, decode.loss_lovasz: 0.5229, decode.acc_seg: 95.2516, loss: 0.6241\n","2022-10-08 12:56:31,780 - mmseg - INFO - Iter [4490/45000]\tlr: 5.401e-05, eta: 3:40:47, time: 0.326, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1178, decode.loss_lovasz: 0.4910, decode.acc_seg: 95.0945, loss: 0.6088\n","2022-10-08 12:56:35,000 - mmseg - INFO - Iter [4500/45000]\tlr: 5.400e-05, eta: 3:40:43, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0825, decode.loss_lovasz: 0.3437, decode.acc_seg: 96.6594, loss: 0.4262\n","2022-10-08 12:56:38,205 - mmseg - INFO - Iter [4510/45000]\tlr: 5.399e-05, eta: 3:40:40, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0977, decode.loss_lovasz: 0.6146, decode.acc_seg: 95.3502, loss: 0.7123\n","2022-10-08 12:56:41,412 - mmseg - INFO - Iter [4520/45000]\tlr: 5.397e-05, eta: 3:40:36, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1307, decode.loss_lovasz: 0.7454, decode.acc_seg: 93.8799, loss: 0.8761\n","2022-10-08 12:56:44,620 - mmseg - INFO - Iter [4530/45000]\tlr: 5.396e-05, eta: 3:40:32, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1129, decode.loss_lovasz: 0.4440, decode.acc_seg: 95.4947, loss: 0.5570\n","2022-10-08 12:56:47,815 - mmseg - INFO - Iter [4540/45000]\tlr: 5.395e-05, eta: 3:40:28, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1259, decode.loss_lovasz: 0.5685, decode.acc_seg: 94.6041, loss: 0.6944\n","2022-10-08 12:56:51,039 - mmseg - INFO - Iter [4550/45000]\tlr: 5.393e-05, eta: 3:40:24, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0696, decode.loss_lovasz: 0.4141, decode.acc_seg: 96.3228, loss: 0.4838\n","2022-10-08 12:56:54,257 - mmseg - INFO - Iter [4560/45000]\tlr: 5.392e-05, eta: 3:40:21, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1028, decode.loss_lovasz: 0.6230, decode.acc_seg: 95.0802, loss: 0.7259\n","2022-10-08 12:56:57,469 - mmseg - INFO - Iter [4570/45000]\tlr: 5.391e-05, eta: 3:40:17, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0859, decode.loss_lovasz: 0.3673, decode.acc_seg: 97.2120, loss: 0.4532\n","2022-10-08 12:57:00,689 - mmseg - INFO - Iter [4580/45000]\tlr: 5.389e-05, eta: 3:40:13, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1078, decode.loss_lovasz: 0.5072, decode.acc_seg: 96.1243, loss: 0.6149\n","2022-10-08 12:57:03,904 - mmseg - INFO - Iter [4590/45000]\tlr: 5.388e-05, eta: 3:40:09, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0606, decode.loss_lovasz: 0.5557, decode.acc_seg: 96.9465, loss: 0.6163\n","2022-10-08 12:57:07,121 - mmseg - INFO - Iter [4600/45000]\tlr: 5.387e-05, eta: 3:40:06, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0633, decode.loss_lovasz: 0.3526, decode.acc_seg: 97.5299, loss: 0.4158\n","2022-10-08 12:57:10,324 - mmseg - INFO - Iter [4610/45000]\tlr: 5.385e-05, eta: 3:40:02, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0921, decode.loss_lovasz: 0.4222, decode.acc_seg: 96.1661, loss: 0.5143\n","2022-10-08 12:57:13,528 - mmseg - INFO - Iter [4620/45000]\tlr: 5.384e-05, eta: 3:39:58, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1471, decode.loss_lovasz: 0.5176, decode.acc_seg: 95.1203, loss: 0.6647\n","2022-10-08 12:57:16,736 - mmseg - INFO - Iter [4630/45000]\tlr: 5.383e-05, eta: 3:39:54, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1514, decode.loss_lovasz: 0.5910, decode.acc_seg: 94.1788, loss: 0.7424\n","2022-10-08 12:57:20,002 - mmseg - INFO - Iter [4640/45000]\tlr: 5.381e-05, eta: 3:39:51, time: 0.327, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0938, decode.loss_lovasz: 0.4562, decode.acc_seg: 95.7939, loss: 0.5500\n","2022-10-08 12:57:23,232 - mmseg - INFO - Iter [4650/45000]\tlr: 5.380e-05, eta: 3:39:47, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0654, decode.loss_lovasz: 0.3203, decode.acc_seg: 97.5276, loss: 0.3857\n","2022-10-08 12:57:26,451 - mmseg - INFO - Iter [4660/45000]\tlr: 5.379e-05, eta: 3:39:44, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1048, decode.loss_lovasz: 0.5106, decode.acc_seg: 95.6748, loss: 0.6154\n","2022-10-08 12:57:29,658 - mmseg - INFO - Iter [4670/45000]\tlr: 5.377e-05, eta: 3:39:40, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1192, decode.loss_lovasz: 0.6523, decode.acc_seg: 94.2549, loss: 0.7715\n","2022-10-08 12:57:32,876 - mmseg - INFO - Iter [4680/45000]\tlr: 5.376e-05, eta: 3:39:36, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0676, decode.loss_lovasz: 0.5080, decode.acc_seg: 96.5092, loss: 0.5757\n","2022-10-08 12:57:36,110 - mmseg - INFO - Iter [4690/45000]\tlr: 5.375e-05, eta: 3:39:32, time: 0.323, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0553, decode.loss_lovasz: 0.3898, decode.acc_seg: 96.1321, loss: 0.4451\n","2022-10-08 12:57:39,314 - mmseg - INFO - Iter [4700/45000]\tlr: 5.373e-05, eta: 3:39:29, time: 0.320, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1281, decode.loss_lovasz: 0.5973, decode.acc_seg: 93.2769, loss: 0.7254\n","2022-10-08 12:57:42,521 - mmseg - INFO - Iter [4710/45000]\tlr: 5.372e-05, eta: 3:39:25, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1038, decode.loss_lovasz: 0.3748, decode.acc_seg: 96.1199, loss: 0.4786\n","2022-10-08 12:57:45,731 - mmseg - INFO - Iter [4720/45000]\tlr: 5.371e-05, eta: 3:39:21, time: 0.321, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0837, decode.loss_lovasz: 0.4020, decode.acc_seg: 96.7361, loss: 0.4857\n","2022-10-08 12:57:49,017 - mmseg - INFO - Iter [4730/45000]\tlr: 5.369e-05, eta: 3:39:18, time: 0.329, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0932, decode.loss_lovasz: 0.4503, decode.acc_seg: 96.3231, loss: 0.5436\n","2022-10-08 12:57:52,226 - mmseg - INFO - Iter [4740/45000]\tlr: 5.368e-05, eta: 3:39:14, time: 0.321, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1403, decode.loss_lovasz: 0.4347, decode.acc_seg: 94.7780, loss: 0.5750\n","2022-10-08 12:57:55,471 - mmseg - INFO - Iter [4750/45000]\tlr: 5.367e-05, eta: 3:39:11, time: 0.325, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0854, decode.loss_lovasz: 0.4901, decode.acc_seg: 96.2639, loss: 0.5755\n","2022-10-08 12:57:58,695 - mmseg - INFO - Iter [4760/45000]\tlr: 5.365e-05, eta: 3:39:07, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1034, decode.loss_lovasz: 0.4946, decode.acc_seg: 95.1270, loss: 0.5980\n","2022-10-08 12:58:01,949 - mmseg - INFO - Iter [4770/45000]\tlr: 5.364e-05, eta: 3:39:04, time: 0.325, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0760, decode.loss_lovasz: 0.5293, decode.acc_seg: 95.9986, loss: 0.6053\n","2022-10-08 12:58:05,173 - mmseg - INFO - Iter [4780/45000]\tlr: 5.363e-05, eta: 3:39:00, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1136, decode.loss_lovasz: 0.4754, decode.acc_seg: 95.4865, loss: 0.5890\n","2022-10-08 12:58:08,390 - mmseg - INFO - Iter [4790/45000]\tlr: 5.361e-05, eta: 3:38:56, time: 0.322, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0789, decode.loss_lovasz: 0.4579, decode.acc_seg: 96.9499, loss: 0.5368\n","2022-10-08 12:58:11,620 - mmseg - INFO - Iter [4800/45000]\tlr: 5.360e-05, eta: 3:38:53, time: 0.323, data_time: 0.007, memory: 24005, decode.loss_ce: 0.0638, decode.loss_lovasz: 0.3843, decode.acc_seg: 97.5932, loss: 0.4481\n","2022-10-08 12:58:14,822 - mmseg - INFO - Iter [4810/45000]\tlr: 5.359e-05, eta: 3:38:49, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0747, decode.loss_lovasz: 0.5833, decode.acc_seg: 95.8486, loss: 0.6580\n","2022-10-08 12:58:18,026 - mmseg - INFO - Iter [4820/45000]\tlr: 5.357e-05, eta: 3:38:45, time: 0.320, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0920, decode.loss_lovasz: 0.3788, decode.acc_seg: 97.1438, loss: 0.4708\n","2022-10-08 12:58:21,215 - mmseg - INFO - Iter [4830/45000]\tlr: 5.356e-05, eta: 3:38:41, time: 0.319, data_time: 0.006, memory: 24005, decode.loss_ce: 0.0979, decode.loss_lovasz: 0.4078, decode.acc_seg: 96.0685, loss: 0.5057\n","2022-10-08 12:58:24,439 - mmseg - INFO - Iter [4840/45000]\tlr: 5.355e-05, eta: 3:38:38, time: 0.322, data_time: 0.006, memory: 24005, decode.loss_ce: 0.1217, decode.loss_lovasz: 0.5746, decode.acc_seg: 94.3323, loss: 0.6962\n","2022-10-08 12:58:27,716 - mmseg - INFO - Iter [4850/45000]\tlr: 5.353e-05, eta: 3:38:35, time: 0.328, data_time: 0.007, memory: 24005, decode.loss_ce: 0.1095, decode.loss_lovasz: 0.3873, decode.acc_seg: 95.8860, loss: 0.4968\n"]}],"source":["%cd /content/mmsegmentation\n","\n","config_list={\n","    \"MODEL_1\": \"/content/training_configs/segformer_mit-b3_1024.py\",\n","    \"MODEL_2\": \"/content/training_configs/segformer_mit-b4_960.py\",\n","    \"MODEL_3\": \"/content/training_configs/segformer_mit-b4_960_2.py\",\n","    \"MODEL_4\": \"/content/training_configs/segformer_mit-b5_928.py\",\n","    \"MODEL_5\": \"/content/training_configs/segformer_mit-b5_960.py\",\n","    \"MODEL_6\": \"/content/training_configs/segformer_mit-b5_960_2.py\",\n","}\n","\n","# Specify a model listed above.\n","model='MODEL_2'\n","\n","config=config_list[model]\n","!rm -r /content/overlay\n","!python tools/train.py {config}"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":["D8ZWOUR2Yb_2","x-EnYSaKKVIU"],"machine_shape":"hm","provenance":[{"file_id":"https://github.com/open-mmlab/mmsegmentation/blob/master/demo/MMSegmentation_Tutorial.ipynb","timestamp":1652616460602}]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}}},"nbformat":4,"nbformat_minor":0}